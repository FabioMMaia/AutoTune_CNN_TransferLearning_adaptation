{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FabioMMaia/AutoTune_CNN_TransferLearning_adaptation/blob/main/AutoTune_VGG16_CompleteArc_WithFCLayers_random.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DWfGrjXCbyCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !sudo apt-get update -y\n",
        "# !sudo apt-get install python3.9 -y\n",
        "# !echo 2 | sudo update-alternatives --config python3 #'echo 2' auto-inputs '2' so that it doesn't have to be done manually"
      ],
      "metadata": {
        "id": "mS_54k7JcKI0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnJm9eK9b6n4",
        "outputId": "e0c1c11f-4607-4c58-933d-153bd8692ea4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jv_3XDyEeznN",
        "outputId": "269e295a-09c2-40d6-8b65-3ac6cd1330ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: GPyOpt in /usr/local/lib/python3.10/dist-packages (1.2.6)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from GPyOpt) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.10/dist-packages (from GPyOpt) (1.11.3)\n",
            "Requirement already satisfied: GPy>=1.8 in /usr/local/lib/python3.10/dist-packages (from GPyOpt) (1.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from GPy>=1.8->GPyOpt) (1.16.0)\n",
            "Requirement already satisfied: paramz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from GPy>=1.8->GPyOpt) (0.9.5)\n",
            "Requirement already satisfied: cython>=0.29 in /usr/local/lib/python3.10/dist-packages (from GPy>=1.8->GPyOpt) (3.0.5)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from paramz>=0.9.0->GPy>=1.8->GPyOpt) (4.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install GPyOpt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install keras==2.2.5"
      ],
      "metadata": {
        "id": "9OE-DRR7PsGx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.13.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLDuwdaOe1oA",
        "outputId": "72f221e3-4145-424a-8836-5ae585195f73"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.13.0 in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.59.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.34.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KnQpWADexZd",
        "outputId": "3d1492ba-ca7d-49f9-f0f5-6ca5e9dc44ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tLYcj1AGerAw"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import GPyOpt\n",
        "import keras\n",
        "import random\n",
        "import math\n",
        "from itertools import product, combinations\n",
        "from collections import OrderedDict\n",
        "from keras.preprocessing import image\n",
        "from keras import layers, models, optimizers, callbacks, initializers, activations\n",
        "from keras.applications import VGG16, ResNet50, DenseNet121\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FDFuKlf1fUom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4a3e93-6e54-4545-a678-6b22aa0f2808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Study neural net architectures"
      ],
      "metadata": {
        "id": "Rqq7nCPegPaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16  = VGG16(input_shape=(224, 224, 3), weights='imagenet', include_top=True)\n",
        "vgg16.summary()\n",
        "del vgg16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPyZsku-fgdz",
        "outputId": "18a0015a-b477-4732-bbde-9c93bacbc744"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138357544 (527.79 MB)\n",
            "Trainable params: 138357544 (527.79 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50  = ResNet50(input_shape=(224, 224, 3), weights='imagenet', include_top=True)\n",
        "resnet50.summary()\n",
        "del resnet50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Orz1NBTGgKC9",
        "outputId": "af5bd333-5892-44cd-e946-3c5ed11a6ac9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)   (None, 230, 230, 3)          0         ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)         (None, 112, 112, 64)         9472      ['conv1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalizati  (None, 112, 112, 64)         256       ['conv1_conv[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)     (None, 112, 112, 64)         0         ['conv1_bn[0][0]']            \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)   (None, 114, 114, 64)         0         ['conv1_relu[0][0]']          \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)   (None, 56, 56, 64)           0         ['pool1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2  (None, 56, 56, 64)           4160      ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2  (None, 56, 56, 256)          16640     ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)      (None, 56, 56, 256)          0         ['conv2_block1_0_bn[0][0]',   \n",
            "                                                                     'conv2_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activati  (None, 56, 56, 256)          0         ['conv2_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2  (None, 56, 56, 64)           16448     ['conv2_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)      (None, 56, 56, 256)          0         ['conv2_block1_out[0][0]',    \n",
            "                                                                     'conv2_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activati  (None, 56, 56, 256)          0         ['conv2_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2  (None, 56, 56, 64)           16448     ['conv2_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)      (None, 56, 56, 256)          0         ['conv2_block2_out[0][0]',    \n",
            "                                                                     'conv2_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activati  (None, 56, 56, 256)          0         ['conv2_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2  (None, 28, 28, 128)          32896     ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2  (None, 28, 28, 512)          131584    ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)      (None, 28, 28, 512)          0         ['conv3_block1_0_bn[0][0]',   \n",
            "                                                                     'conv3_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activati  (None, 28, 28, 512)          0         ['conv3_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)      (None, 28, 28, 512)          0         ['conv3_block1_out[0][0]',    \n",
            "                                                                     'conv3_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activati  (None, 28, 28, 512)          0         ['conv3_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)      (None, 28, 28, 512)          0         ['conv3_block2_out[0][0]',    \n",
            "                                                                     'conv3_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activati  (None, 28, 28, 512)          0         ['conv3_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)      (None, 28, 28, 512)          0         ['conv3_block3_out[0][0]',    \n",
            "                                                                     'conv3_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activati  (None, 28, 28, 512)          0         ['conv3_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2  (None, 14, 14, 256)          131328    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2  (None, 14, 14, 1024)         525312    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_0_bn[0][0]',   \n",
            "                                                                     'conv4_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_out[0][0]',    \n",
            "                                                                     'conv4_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block2_out[0][0]',    \n",
            "                                                                     'conv4_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block3_out[0][0]',    \n",
            "                                                                     'conv4_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block5_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block5_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block5_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block4_out[0][0]',    \n",
            "                                                                     'conv4_block5_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block5_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block5_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block6_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block6_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block6_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block6_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block6_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block6_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block6_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block5_out[0][0]',    \n",
            "                                                                     'conv4_block6_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block6_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2  (None, 7, 7, 512)            524800    ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2  (None, 7, 7, 2048)           2099200   ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_0_bn[0][0]',   \n",
            "                                                                     'conv5_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2  (None, 7, 7, 512)            1049088   ['conv5_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_out[0][0]',    \n",
            "                                                                     'conv5_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2  (None, 7, 7, 512)            1049088   ['conv5_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block2_out[0][0]',    \n",
            "                                                                     'conv5_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePoo  (None, 2048)                 0         ['conv5_block3_out[0][0]']    \n",
            " ling2D)                                                                                          \n",
            "                                                                                                  \n",
            " predictions (Dense)         (None, 1000)                 2049000   ['avg_pool[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25636712 (97.80 MB)\n",
            "Trainable params: 25583592 (97.59 MB)\n",
            "Non-trainable params: 53120 (207.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "densenet121  = DenseNet121(input_shape=(224, 224, 3), weights='imagenet', include_top=True)\n",
        "densenet121.summary()\n",
        "del densenet121"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKcnw3kqgK7K",
        "outputId": "c2516814-ec36-498b-a1b7-c0624a8e4f98"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"densenet121\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPaddin  (None, 230, 230, 3)          0         ['input_3[0][0]']             \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv1/conv (Conv2D)         (None, 112, 112, 64)         9408      ['zero_padding2d[0][0]']      \n",
            "                                                                                                  \n",
            " conv1/bn (BatchNormalizati  (None, 112, 112, 64)         256       ['conv1/conv[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv1/relu (Activation)     (None, 112, 112, 64)         0         ['conv1/bn[0][0]']            \n",
            "                                                                                                  \n",
            " zero_padding2d_1 (ZeroPadd  (None, 114, 114, 64)         0         ['conv1/relu[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " pool1 (MaxPooling2D)        (None, 56, 56, 64)           0         ['zero_padding2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNo  (None, 56, 56, 64)           256       ['pool1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_0_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2  (None, 56, 56, 128)          8192      ['conv2_block1_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNo  (None, 56, 56, 128)          512       ['conv2_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activ  (None, 56, 56, 128)          0         ['conv2_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2  (None, 56, 56, 32)           36864     ['conv2_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_concat (Conca  (None, 56, 56, 96)           0         ['pool1[0][0]',               \n",
            " tenate)                                                             'conv2_block1_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv2_block2_0_bn (BatchNo  (None, 56, 56, 96)           384       ['conv2_block1_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_0_relu (Activ  (None, 56, 56, 96)           0         ['conv2_block2_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2  (None, 56, 56, 128)          12288     ['conv2_block2_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNo  (None, 56, 56, 128)          512       ['conv2_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activ  (None, 56, 56, 128)          0         ['conv2_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2  (None, 56, 56, 32)           36864     ['conv2_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_concat (Conca  (None, 56, 56, 128)          0         ['conv2_block1_concat[0][0]', \n",
            " tenate)                                                             'conv2_block2_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv2_block3_0_bn (BatchNo  (None, 56, 56, 128)          512       ['conv2_block2_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_0_relu (Activ  (None, 56, 56, 128)          0         ['conv2_block3_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2  (None, 56, 56, 128)          16384     ['conv2_block3_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNo  (None, 56, 56, 128)          512       ['conv2_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activ  (None, 56, 56, 128)          0         ['conv2_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2  (None, 56, 56, 32)           36864     ['conv2_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_concat (Conca  (None, 56, 56, 160)          0         ['conv2_block2_concat[0][0]', \n",
            " tenate)                                                             'conv2_block3_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv2_block4_0_bn (BatchNo  (None, 56, 56, 160)          640       ['conv2_block3_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block4_0_relu (Activ  (None, 56, 56, 160)          0         ['conv2_block4_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block4_1_conv (Conv2  (None, 56, 56, 128)          20480     ['conv2_block4_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_1_bn (BatchNo  (None, 56, 56, 128)          512       ['conv2_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block4_1_relu (Activ  (None, 56, 56, 128)          0         ['conv2_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block4_2_conv (Conv2  (None, 56, 56, 32)           36864     ['conv2_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_concat (Conca  (None, 56, 56, 192)          0         ['conv2_block3_concat[0][0]', \n",
            " tenate)                                                             'conv2_block4_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv2_block5_0_bn (BatchNo  (None, 56, 56, 192)          768       ['conv2_block4_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block5_0_relu (Activ  (None, 56, 56, 192)          0         ['conv2_block5_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block5_1_conv (Conv2  (None, 56, 56, 128)          24576     ['conv2_block5_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_1_bn (BatchNo  (None, 56, 56, 128)          512       ['conv2_block5_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block5_1_relu (Activ  (None, 56, 56, 128)          0         ['conv2_block5_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block5_2_conv (Conv2  (None, 56, 56, 32)           36864     ['conv2_block5_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_concat (Conca  (None, 56, 56, 224)          0         ['conv2_block4_concat[0][0]', \n",
            " tenate)                                                             'conv2_block5_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv2_block6_0_bn (BatchNo  (None, 56, 56, 224)          896       ['conv2_block5_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block6_0_relu (Activ  (None, 56, 56, 224)          0         ['conv2_block6_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block6_1_conv (Conv2  (None, 56, 56, 128)          28672     ['conv2_block6_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_1_bn (BatchNo  (None, 56, 56, 128)          512       ['conv2_block6_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block6_1_relu (Activ  (None, 56, 56, 128)          0         ['conv2_block6_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block6_2_conv (Conv2  (None, 56, 56, 32)           36864     ['conv2_block6_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_concat (Conca  (None, 56, 56, 256)          0         ['conv2_block5_concat[0][0]', \n",
            " tenate)                                                             'conv2_block6_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " pool2_bn (BatchNormalizati  (None, 56, 56, 256)          1024      ['conv2_block6_concat[0][0]'] \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " pool2_relu (Activation)     (None, 56, 56, 256)          0         ['pool2_bn[0][0]']            \n",
            "                                                                                                  \n",
            " pool2_conv (Conv2D)         (None, 56, 56, 128)          32768     ['pool2_relu[0][0]']          \n",
            "                                                                                                  \n",
            " pool2_pool (AveragePooling  (None, 28, 28, 128)          0         ['pool2_conv[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNo  (None, 28, 28, 128)          512       ['pool2_pool[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_0_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2  (None, 28, 28, 128)          16384     ['conv3_block1_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2  (None, 28, 28, 32)           36864     ['conv3_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_concat (Conca  (None, 28, 28, 160)          0         ['pool2_pool[0][0]',          \n",
            " tenate)                                                             'conv3_block1_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block2_0_bn (BatchNo  (None, 28, 28, 160)          640       ['conv3_block1_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_0_relu (Activ  (None, 28, 28, 160)          0         ['conv3_block2_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2  (None, 28, 28, 128)          20480     ['conv3_block2_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2  (None, 28, 28, 32)           36864     ['conv3_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_concat (Conca  (None, 28, 28, 192)          0         ['conv3_block1_concat[0][0]', \n",
            " tenate)                                                             'conv3_block2_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block3_0_bn (BatchNo  (None, 28, 28, 192)          768       ['conv3_block2_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_0_relu (Activ  (None, 28, 28, 192)          0         ['conv3_block3_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2  (None, 28, 28, 128)          24576     ['conv3_block3_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2  (None, 28, 28, 32)           36864     ['conv3_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_concat (Conca  (None, 28, 28, 224)          0         ['conv3_block2_concat[0][0]', \n",
            " tenate)                                                             'conv3_block3_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block4_0_bn (BatchNo  (None, 28, 28, 224)          896       ['conv3_block3_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_0_relu (Activ  (None, 28, 28, 224)          0         ['conv3_block4_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2  (None, 28, 28, 128)          28672     ['conv3_block4_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2  (None, 28, 28, 32)           36864     ['conv3_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_concat (Conca  (None, 28, 28, 256)          0         ['conv3_block3_concat[0][0]', \n",
            " tenate)                                                             'conv3_block4_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block5_0_bn (BatchNo  (None, 28, 28, 256)          1024      ['conv3_block4_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block5_0_relu (Activ  (None, 28, 28, 256)          0         ['conv3_block5_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block5_1_conv (Conv2  (None, 28, 28, 128)          32768     ['conv3_block5_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block5_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block5_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block5_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block5_2_conv (Conv2  (None, 28, 28, 32)           36864     ['conv3_block5_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_concat (Conca  (None, 28, 28, 288)          0         ['conv3_block4_concat[0][0]', \n",
            " tenate)                                                             'conv3_block5_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block6_0_bn (BatchNo  (None, 28, 28, 288)          1152      ['conv3_block5_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block6_0_relu (Activ  (None, 28, 28, 288)          0         ['conv3_block6_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block6_1_conv (Conv2  (None, 28, 28, 128)          36864     ['conv3_block6_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block6_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block6_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block6_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block6_2_conv (Conv2  (None, 28, 28, 32)           36864     ['conv3_block6_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_concat (Conca  (None, 28, 28, 320)          0         ['conv3_block5_concat[0][0]', \n",
            " tenate)                                                             'conv3_block6_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block7_0_bn (BatchNo  (None, 28, 28, 320)          1280      ['conv3_block6_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block7_0_relu (Activ  (None, 28, 28, 320)          0         ['conv3_block7_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block7_1_conv (Conv2  (None, 28, 28, 128)          40960     ['conv3_block7_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block7_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block7_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block7_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block7_2_conv (Conv2  (None, 28, 28, 32)           36864     ['conv3_block7_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_concat (Conca  (None, 28, 28, 352)          0         ['conv3_block6_concat[0][0]', \n",
            " tenate)                                                             'conv3_block7_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block8_0_bn (BatchNo  (None, 28, 28, 352)          1408      ['conv3_block7_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block8_0_relu (Activ  (None, 28, 28, 352)          0         ['conv3_block8_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block8_1_conv (Conv2  (None, 28, 28, 128)          45056     ['conv3_block8_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block8_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block8_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block8_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block8_2_conv (Conv2  (None, 28, 28, 32)           36864     ['conv3_block8_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_concat (Conca  (None, 28, 28, 384)          0         ['conv3_block7_concat[0][0]', \n",
            " tenate)                                                             'conv3_block8_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block9_0_bn (BatchNo  (None, 28, 28, 384)          1536      ['conv3_block8_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block9_0_relu (Activ  (None, 28, 28, 384)          0         ['conv3_block9_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block9_1_conv (Conv2  (None, 28, 28, 128)          49152     ['conv3_block9_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block9_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block9_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block9_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block9_2_conv (Conv2  (None, 28, 28, 32)           36864     ['conv3_block9_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_concat (Conca  (None, 28, 28, 416)          0         ['conv3_block8_concat[0][0]', \n",
            " tenate)                                                             'conv3_block9_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block10_0_bn (BatchN  (None, 28, 28, 416)          1664      ['conv3_block9_concat[0][0]'] \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block10_0_relu (Acti  (None, 28, 28, 416)          0         ['conv3_block10_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block10_1_conv (Conv  (None, 28, 28, 128)          53248     ['conv3_block10_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_1_bn (BatchN  (None, 28, 28, 128)          512       ['conv3_block10_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block10_1_relu (Acti  (None, 28, 28, 128)          0         ['conv3_block10_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block10_2_conv (Conv  (None, 28, 28, 32)           36864     ['conv3_block10_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_concat (Conc  (None, 28, 28, 448)          0         ['conv3_block9_concat[0][0]', \n",
            " atenate)                                                            'conv3_block10_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv3_block11_0_bn (BatchN  (None, 28, 28, 448)          1792      ['conv3_block10_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block11_0_relu (Acti  (None, 28, 28, 448)          0         ['conv3_block11_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block11_1_conv (Conv  (None, 28, 28, 128)          57344     ['conv3_block11_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_1_bn (BatchN  (None, 28, 28, 128)          512       ['conv3_block11_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block11_1_relu (Acti  (None, 28, 28, 128)          0         ['conv3_block11_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block11_2_conv (Conv  (None, 28, 28, 32)           36864     ['conv3_block11_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_concat (Conc  (None, 28, 28, 480)          0         ['conv3_block10_concat[0][0]',\n",
            " atenate)                                                            'conv3_block11_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv3_block12_0_bn (BatchN  (None, 28, 28, 480)          1920      ['conv3_block11_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block12_0_relu (Acti  (None, 28, 28, 480)          0         ['conv3_block12_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block12_1_conv (Conv  (None, 28, 28, 128)          61440     ['conv3_block12_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_1_bn (BatchN  (None, 28, 28, 128)          512       ['conv3_block12_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block12_1_relu (Acti  (None, 28, 28, 128)          0         ['conv3_block12_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block12_2_conv (Conv  (None, 28, 28, 32)           36864     ['conv3_block12_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_concat (Conc  (None, 28, 28, 512)          0         ['conv3_block11_concat[0][0]',\n",
            " atenate)                                                            'conv3_block12_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " pool3_bn (BatchNormalizati  (None, 28, 28, 512)          2048      ['conv3_block12_concat[0][0]']\n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " pool3_relu (Activation)     (None, 28, 28, 512)          0         ['pool3_bn[0][0]']            \n",
            "                                                                                                  \n",
            " pool3_conv (Conv2D)         (None, 28, 28, 256)          131072    ['pool3_relu[0][0]']          \n",
            "                                                                                                  \n",
            " pool3_pool (AveragePooling  (None, 14, 14, 256)          0         ['pool3_conv[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNo  (None, 14, 14, 256)          1024      ['pool3_pool[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_0_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2  (None, 14, 14, 128)          32768     ['conv4_block1_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNo  (None, 14, 14, 128)          512       ['conv4_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activ  (None, 14, 14, 128)          0         ['conv4_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2  (None, 14, 14, 32)           36864     ['conv4_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_concat (Conca  (None, 14, 14, 288)          0         ['pool3_pool[0][0]',          \n",
            " tenate)                                                             'conv4_block1_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block2_0_bn (BatchNo  (None, 14, 14, 288)          1152      ['conv4_block1_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_0_relu (Activ  (None, 14, 14, 288)          0         ['conv4_block2_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2  (None, 14, 14, 128)          36864     ['conv4_block2_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNo  (None, 14, 14, 128)          512       ['conv4_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activ  (None, 14, 14, 128)          0         ['conv4_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2  (None, 14, 14, 32)           36864     ['conv4_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_concat (Conca  (None, 14, 14, 320)          0         ['conv4_block1_concat[0][0]', \n",
            " tenate)                                                             'conv4_block2_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block3_0_bn (BatchNo  (None, 14, 14, 320)          1280      ['conv4_block2_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_0_relu (Activ  (None, 14, 14, 320)          0         ['conv4_block3_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2  (None, 14, 14, 128)          40960     ['conv4_block3_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNo  (None, 14, 14, 128)          512       ['conv4_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activ  (None, 14, 14, 128)          0         ['conv4_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2  (None, 14, 14, 32)           36864     ['conv4_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_concat (Conca  (None, 14, 14, 352)          0         ['conv4_block2_concat[0][0]', \n",
            " tenate)                                                             'conv4_block3_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block4_0_bn (BatchNo  (None, 14, 14, 352)          1408      ['conv4_block3_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_0_relu (Activ  (None, 14, 14, 352)          0         ['conv4_block4_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2  (None, 14, 14, 128)          45056     ['conv4_block4_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNo  (None, 14, 14, 128)          512       ['conv4_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activ  (None, 14, 14, 128)          0         ['conv4_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2  (None, 14, 14, 32)           36864     ['conv4_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_concat (Conca  (None, 14, 14, 384)          0         ['conv4_block3_concat[0][0]', \n",
            " tenate)                                                             'conv4_block4_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block5_0_bn (BatchNo  (None, 14, 14, 384)          1536      ['conv4_block4_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_0_relu (Activ  (None, 14, 14, 384)          0         ['conv4_block5_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2  (None, 14, 14, 128)          49152     ['conv4_block5_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNo  (None, 14, 14, 128)          512       ['conv4_block5_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activ  (None, 14, 14, 128)          0         ['conv4_block5_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2  (None, 14, 14, 32)           36864     ['conv4_block5_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_concat (Conca  (None, 14, 14, 416)          0         ['conv4_block4_concat[0][0]', \n",
            " tenate)                                                             'conv4_block5_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block6_0_bn (BatchNo  (None, 14, 14, 416)          1664      ['conv4_block5_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_0_relu (Activ  (None, 14, 14, 416)          0         ['conv4_block6_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2  (None, 14, 14, 128)          53248     ['conv4_block6_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNo  (None, 14, 14, 128)          512       ['conv4_block6_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activ  (None, 14, 14, 128)          0         ['conv4_block6_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2  (None, 14, 14, 32)           36864     ['conv4_block6_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_concat (Conca  (None, 14, 14, 448)          0         ['conv4_block5_concat[0][0]', \n",
            " tenate)                                                             'conv4_block6_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block7_0_bn (BatchNo  (None, 14, 14, 448)          1792      ['conv4_block6_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block7_0_relu (Activ  (None, 14, 14, 448)          0         ['conv4_block7_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block7_1_conv (Conv2  (None, 14, 14, 128)          57344     ['conv4_block7_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_1_bn (BatchNo  (None, 14, 14, 128)          512       ['conv4_block7_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block7_1_relu (Activ  (None, 14, 14, 128)          0         ['conv4_block7_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block7_2_conv (Conv2  (None, 14, 14, 32)           36864     ['conv4_block7_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_concat (Conca  (None, 14, 14, 480)          0         ['conv4_block6_concat[0][0]', \n",
            " tenate)                                                             'conv4_block7_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block8_0_bn (BatchNo  (None, 14, 14, 480)          1920      ['conv4_block7_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block8_0_relu (Activ  (None, 14, 14, 480)          0         ['conv4_block8_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block8_1_conv (Conv2  (None, 14, 14, 128)          61440     ['conv4_block8_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_1_bn (BatchNo  (None, 14, 14, 128)          512       ['conv4_block8_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block8_1_relu (Activ  (None, 14, 14, 128)          0         ['conv4_block8_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block8_2_conv (Conv2  (None, 14, 14, 32)           36864     ['conv4_block8_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_concat (Conca  (None, 14, 14, 512)          0         ['conv4_block7_concat[0][0]', \n",
            " tenate)                                                             'conv4_block8_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block9_0_bn (BatchNo  (None, 14, 14, 512)          2048      ['conv4_block8_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block9_0_relu (Activ  (None, 14, 14, 512)          0         ['conv4_block9_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block9_1_conv (Conv2  (None, 14, 14, 128)          65536     ['conv4_block9_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_1_bn (BatchNo  (None, 14, 14, 128)          512       ['conv4_block9_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block9_1_relu (Activ  (None, 14, 14, 128)          0         ['conv4_block9_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block9_2_conv (Conv2  (None, 14, 14, 32)           36864     ['conv4_block9_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_concat (Conca  (None, 14, 14, 544)          0         ['conv4_block8_concat[0][0]', \n",
            " tenate)                                                             'conv4_block9_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block10_0_bn (BatchN  (None, 14, 14, 544)          2176      ['conv4_block9_concat[0][0]'] \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block10_0_relu (Acti  (None, 14, 14, 544)          0         ['conv4_block10_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block10_1_conv (Conv  (None, 14, 14, 128)          69632     ['conv4_block10_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_1_bn (BatchN  (None, 14, 14, 128)          512       ['conv4_block10_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block10_1_relu (Acti  (None, 14, 14, 128)          0         ['conv4_block10_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block10_2_conv (Conv  (None, 14, 14, 32)           36864     ['conv4_block10_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_concat (Conc  (None, 14, 14, 576)          0         ['conv4_block9_concat[0][0]', \n",
            " atenate)                                                            'conv4_block10_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv4_block11_0_bn (BatchN  (None, 14, 14, 576)          2304      ['conv4_block10_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block11_0_relu (Acti  (None, 14, 14, 576)          0         ['conv4_block11_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block11_1_conv (Conv  (None, 14, 14, 128)          73728     ['conv4_block11_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_1_bn (BatchN  (None, 14, 14, 128)          512       ['conv4_block11_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block11_1_relu (Acti  (None, 14, 14, 128)          0         ['conv4_block11_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block11_2_conv (Conv  (None, 14, 14, 32)           36864     ['conv4_block11_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_concat (Conc  (None, 14, 14, 608)          0         ['conv4_block10_concat[0][0]',\n",
            " atenate)                                                            'conv4_block11_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv4_block12_0_bn (BatchN  (None, 14, 14, 608)          2432      ['conv4_block11_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block12_0_relu (Acti  (None, 14, 14, 608)          0         ['conv4_block12_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block12_1_conv (Conv  (None, 14, 14, 128)          77824     ['conv4_block12_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_1_bn (BatchN  (None, 14, 14, 128)          512       ['conv4_block12_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block12_1_relu (Acti  (None, 14, 14, 128)          0         ['conv4_block12_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block12_2_conv (Conv  (None, 14, 14, 32)           36864     ['conv4_block12_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_concat (Conc  (None, 14, 14, 640)          0         ['conv4_block11_concat[0][0]',\n",
            " atenate)                                                            'conv4_block12_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv4_block13_0_bn (BatchN  (None, 14, 14, 640)          2560      ['conv4_block12_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block13_0_relu (Acti  (None, 14, 14, 640)          0         ['conv4_block13_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block13_1_conv (Conv  (None, 14, 14, 128)          81920     ['conv4_block13_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_1_bn (BatchN  (None, 14, 14, 128)          512       ['conv4_block13_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block13_1_relu (Acti  (None, 14, 14, 128)          0         ['conv4_block13_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block13_2_conv (Conv  (None, 14, 14, 32)           36864     ['conv4_block13_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_concat (Conc  (None, 14, 14, 672)          0         ['conv4_block12_concat[0][0]',\n",
            " atenate)                                                            'conv4_block13_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv4_block14_0_bn (BatchN  (None, 14, 14, 672)          2688      ['conv4_block13_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block14_0_relu (Acti  (None, 14, 14, 672)          0         ['conv4_block14_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block14_1_conv (Conv  (None, 14, 14, 128)          86016     ['conv4_block14_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_1_bn (BatchN  (None, 14, 14, 128)          512       ['conv4_block14_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block14_1_relu (Acti  (None, 14, 14, 128)          0         ['conv4_block14_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block14_2_conv (Conv  (None, 14, 14, 32)           36864     ['conv4_block14_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_concat (Conc  (None, 14, 14, 704)          0         ['conv4_block13_concat[0][0]',\n",
            " atenate)                                                            'conv4_block14_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv4_block15_0_bn (BatchN  (None, 14, 14, 704)          2816      ['conv4_block14_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block15_0_relu (Acti  (None, 14, 14, 704)          0         ['conv4_block15_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block15_1_conv (Conv  (None, 14, 14, 128)          90112     ['conv4_block15_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_1_bn (BatchN  (None, 14, 14, 128)          512       ['conv4_block15_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block15_1_relu (Acti  (None, 14, 14, 128)          0         ['conv4_block15_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block15_2_conv (Conv  (None, 14, 14, 32)           36864     ['conv4_block15_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_concat (Conc  (None, 14, 14, 736)          0         ['conv4_block14_concat[0][0]',\n",
            " atenate)                                                            'conv4_block15_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv4_block16_0_bn (BatchN  (None, 14, 14, 736)          2944      ['conv4_block15_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block16_0_relu (Acti  (None, 14, 14, 736)          0         ['conv4_block16_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block16_1_conv (Conv  (None, 14, 14, 128)          94208     ['conv4_block16_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_1_bn (BatchN  (None, 14, 14, 128)          512       ['conv4_block16_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block16_1_relu (Acti  (None, 14, 14, 128)          0         ['conv4_block16_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block16_2_conv (Conv  (None, 14, 14, 32)           36864     ['conv4_block16_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_concat (Conc  (None, 14, 14, 768)          0         ['conv4_block15_concat[0][0]',\n",
            " atenate)                                                            'conv4_block16_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv4_block17_0_bn (BatchN  (None, 14, 14, 768)          3072      ['conv4_block16_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block17_0_relu (Acti  (None, 14, 14, 768)          0         ['conv4_block17_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block17_1_conv (Conv  (None, 14, 14, 128)          98304     ['conv4_block17_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_1_bn (BatchN  (None, 14, 14, 128)          512       ['conv4_block17_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block17_1_relu (Acti  (None, 14, 14, 128)          0         ['conv4_block17_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block17_2_conv (Conv  (None, 14, 14, 32)           36864     ['conv4_block17_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_concat (Conc  (None, 14, 14, 800)          0         ['conv4_block16_concat[0][0]',\n",
            " atenate)                                                            'conv4_block17_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv4_block18_0_bn (BatchN  (None, 14, 14, 800)          3200      ['conv4_block17_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block18_0_relu (Acti  (None, 14, 14, 800)          0         ['conv4_block18_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block18_1_conv (Conv  (None, 14, 14, 128)          102400    ['conv4_block18_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_1_bn (BatchN  (None, 14, 14, 128)          512       ['conv4_block18_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block18_1_relu (Acti  (None, 14, 14, 128)          0         ['conv4_block18_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block18_2_conv (Conv  (None, 14, 14, 32)           36864     ['conv4_block18_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_concat (Conc  (None, 14, 14, 832)          0         ['conv4_block17_concat[0][0]',\n",
            " atenate)                                                            'conv4_block18_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv4_block19_0_bn (BatchN  (None, 14, 14, 832)          3328      ['conv4_block18_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block19_0_relu (Acti  (None, 14, 14, 832)          0         ['conv4_block19_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block19_1_conv (Conv  (None, 14, 14, 128)          106496    ['conv4_block19_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_1_bn (BatchN  (None, 14, 14, 128)          512       ['conv4_block19_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block19_1_relu (Acti  (None, 14, 14, 128)          0         ['conv4_block19_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block19_2_conv (Conv  (None, 14, 14, 32)           36864     ['conv4_block19_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_concat (Conc  (None, 14, 14, 864)          0         ['conv4_block18_concat[0][0]',\n",
            " atenate)                                                            'conv4_block19_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv4_block20_0_bn (BatchN  (None, 14, 14, 864)          3456      ['conv4_block19_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block20_0_relu (Acti  (None, 14, 14, 864)          0         ['conv4_block20_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block20_1_conv (Conv  (None, 14, 14, 128)          110592    ['conv4_block20_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_1_bn (BatchN  (None, 14, 14, 128)          512       ['conv4_block20_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block20_1_relu (Acti  (None, 14, 14, 128)          0         ['conv4_block20_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block20_2_conv (Conv  (None, 14, 14, 32)           36864     ['conv4_block20_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_concat (Conc  (None, 14, 14, 896)          0         ['conv4_block19_concat[0][0]',\n",
            " atenate)                                                            'conv4_block20_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv4_block21_0_bn (BatchN  (None, 14, 14, 896)          3584      ['conv4_block20_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block21_0_relu (Acti  (None, 14, 14, 896)          0         ['conv4_block21_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block21_1_conv (Conv  (None, 14, 14, 128)          114688    ['conv4_block21_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_1_bn (BatchN  (None, 14, 14, 128)          512       ['conv4_block21_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block21_1_relu (Acti  (None, 14, 14, 128)          0         ['conv4_block21_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block21_2_conv (Conv  (None, 14, 14, 32)           36864     ['conv4_block21_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_concat (Conc  (None, 14, 14, 928)          0         ['conv4_block20_concat[0][0]',\n",
            " atenate)                                                            'conv4_block21_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv4_block22_0_bn (BatchN  (None, 14, 14, 928)          3712      ['conv4_block21_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block22_0_relu (Acti  (None, 14, 14, 928)          0         ['conv4_block22_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block22_1_conv (Conv  (None, 14, 14, 128)          118784    ['conv4_block22_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_1_bn (BatchN  (None, 14, 14, 128)          512       ['conv4_block22_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block22_1_relu (Acti  (None, 14, 14, 128)          0         ['conv4_block22_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block22_2_conv (Conv  (None, 14, 14, 32)           36864     ['conv4_block22_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_concat (Conc  (None, 14, 14, 960)          0         ['conv4_block21_concat[0][0]',\n",
            " atenate)                                                            'conv4_block22_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv4_block23_0_bn (BatchN  (None, 14, 14, 960)          3840      ['conv4_block22_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block23_0_relu (Acti  (None, 14, 14, 960)          0         ['conv4_block23_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block23_1_conv (Conv  (None, 14, 14, 128)          122880    ['conv4_block23_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_1_bn (BatchN  (None, 14, 14, 128)          512       ['conv4_block23_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block23_1_relu (Acti  (None, 14, 14, 128)          0         ['conv4_block23_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block23_2_conv (Conv  (None, 14, 14, 32)           36864     ['conv4_block23_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_concat (Conc  (None, 14, 14, 992)          0         ['conv4_block22_concat[0][0]',\n",
            " atenate)                                                            'conv4_block23_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv4_block24_0_bn (BatchN  (None, 14, 14, 992)          3968      ['conv4_block23_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block24_0_relu (Acti  (None, 14, 14, 992)          0         ['conv4_block24_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block24_1_conv (Conv  (None, 14, 14, 128)          126976    ['conv4_block24_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_1_bn (BatchN  (None, 14, 14, 128)          512       ['conv4_block24_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block24_1_relu (Acti  (None, 14, 14, 128)          0         ['conv4_block24_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block24_2_conv (Conv  (None, 14, 14, 32)           36864     ['conv4_block24_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_concat (Conc  (None, 14, 14, 1024)         0         ['conv4_block23_concat[0][0]',\n",
            " atenate)                                                            'conv4_block24_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " pool4_bn (BatchNormalizati  (None, 14, 14, 1024)         4096      ['conv4_block24_concat[0][0]']\n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " pool4_relu (Activation)     (None, 14, 14, 1024)         0         ['pool4_bn[0][0]']            \n",
            "                                                                                                  \n",
            " pool4_conv (Conv2D)         (None, 14, 14, 512)          524288    ['pool4_relu[0][0]']          \n",
            "                                                                                                  \n",
            " pool4_pool (AveragePooling  (None, 7, 7, 512)            0         ['pool4_conv[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNo  (None, 7, 7, 512)            2048      ['pool4_pool[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_0_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2  (None, 7, 7, 128)            65536     ['conv5_block1_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNo  (None, 7, 7, 128)            512       ['conv5_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activ  (None, 7, 7, 128)            0         ['conv5_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2  (None, 7, 7, 32)             36864     ['conv5_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_concat (Conca  (None, 7, 7, 544)            0         ['pool4_pool[0][0]',          \n",
            " tenate)                                                             'conv5_block1_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block2_0_bn (BatchNo  (None, 7, 7, 544)            2176      ['conv5_block1_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_0_relu (Activ  (None, 7, 7, 544)            0         ['conv5_block2_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2  (None, 7, 7, 128)            69632     ['conv5_block2_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNo  (None, 7, 7, 128)            512       ['conv5_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activ  (None, 7, 7, 128)            0         ['conv5_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2  (None, 7, 7, 32)             36864     ['conv5_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_concat (Conca  (None, 7, 7, 576)            0         ['conv5_block1_concat[0][0]', \n",
            " tenate)                                                             'conv5_block2_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block3_0_bn (BatchNo  (None, 7, 7, 576)            2304      ['conv5_block2_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_0_relu (Activ  (None, 7, 7, 576)            0         ['conv5_block3_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2  (None, 7, 7, 128)            73728     ['conv5_block3_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNo  (None, 7, 7, 128)            512       ['conv5_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activ  (None, 7, 7, 128)            0         ['conv5_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2  (None, 7, 7, 32)             36864     ['conv5_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_concat (Conca  (None, 7, 7, 608)            0         ['conv5_block2_concat[0][0]', \n",
            " tenate)                                                             'conv5_block3_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block4_0_bn (BatchNo  (None, 7, 7, 608)            2432      ['conv5_block3_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block4_0_relu (Activ  (None, 7, 7, 608)            0         ['conv5_block4_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block4_1_conv (Conv2  (None, 7, 7, 128)            77824     ['conv5_block4_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_1_bn (BatchNo  (None, 7, 7, 128)            512       ['conv5_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block4_1_relu (Activ  (None, 7, 7, 128)            0         ['conv5_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block4_2_conv (Conv2  (None, 7, 7, 32)             36864     ['conv5_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_concat (Conca  (None, 7, 7, 640)            0         ['conv5_block3_concat[0][0]', \n",
            " tenate)                                                             'conv5_block4_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block5_0_bn (BatchNo  (None, 7, 7, 640)            2560      ['conv5_block4_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block5_0_relu (Activ  (None, 7, 7, 640)            0         ['conv5_block5_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block5_1_conv (Conv2  (None, 7, 7, 128)            81920     ['conv5_block5_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_1_bn (BatchNo  (None, 7, 7, 128)            512       ['conv5_block5_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block5_1_relu (Activ  (None, 7, 7, 128)            0         ['conv5_block5_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block5_2_conv (Conv2  (None, 7, 7, 32)             36864     ['conv5_block5_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_concat (Conca  (None, 7, 7, 672)            0         ['conv5_block4_concat[0][0]', \n",
            " tenate)                                                             'conv5_block5_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block6_0_bn (BatchNo  (None, 7, 7, 672)            2688      ['conv5_block5_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block6_0_relu (Activ  (None, 7, 7, 672)            0         ['conv5_block6_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block6_1_conv (Conv2  (None, 7, 7, 128)            86016     ['conv5_block6_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_1_bn (BatchNo  (None, 7, 7, 128)            512       ['conv5_block6_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block6_1_relu (Activ  (None, 7, 7, 128)            0         ['conv5_block6_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block6_2_conv (Conv2  (None, 7, 7, 32)             36864     ['conv5_block6_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_concat (Conca  (None, 7, 7, 704)            0         ['conv5_block5_concat[0][0]', \n",
            " tenate)                                                             'conv5_block6_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block7_0_bn (BatchNo  (None, 7, 7, 704)            2816      ['conv5_block6_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block7_0_relu (Activ  (None, 7, 7, 704)            0         ['conv5_block7_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block7_1_conv (Conv2  (None, 7, 7, 128)            90112     ['conv5_block7_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_1_bn (BatchNo  (None, 7, 7, 128)            512       ['conv5_block7_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block7_1_relu (Activ  (None, 7, 7, 128)            0         ['conv5_block7_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block7_2_conv (Conv2  (None, 7, 7, 32)             36864     ['conv5_block7_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_concat (Conca  (None, 7, 7, 736)            0         ['conv5_block6_concat[0][0]', \n",
            " tenate)                                                             'conv5_block7_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block8_0_bn (BatchNo  (None, 7, 7, 736)            2944      ['conv5_block7_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block8_0_relu (Activ  (None, 7, 7, 736)            0         ['conv5_block8_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block8_1_conv (Conv2  (None, 7, 7, 128)            94208     ['conv5_block8_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_1_bn (BatchNo  (None, 7, 7, 128)            512       ['conv5_block8_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block8_1_relu (Activ  (None, 7, 7, 128)            0         ['conv5_block8_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block8_2_conv (Conv2  (None, 7, 7, 32)             36864     ['conv5_block8_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_concat (Conca  (None, 7, 7, 768)            0         ['conv5_block7_concat[0][0]', \n",
            " tenate)                                                             'conv5_block8_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block9_0_bn (BatchNo  (None, 7, 7, 768)            3072      ['conv5_block8_concat[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block9_0_relu (Activ  (None, 7, 7, 768)            0         ['conv5_block9_0_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block9_1_conv (Conv2  (None, 7, 7, 128)            98304     ['conv5_block9_0_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_1_bn (BatchNo  (None, 7, 7, 128)            512       ['conv5_block9_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block9_1_relu (Activ  (None, 7, 7, 128)            0         ['conv5_block9_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block9_2_conv (Conv2  (None, 7, 7, 32)             36864     ['conv5_block9_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_concat (Conca  (None, 7, 7, 800)            0         ['conv5_block8_concat[0][0]', \n",
            " tenate)                                                             'conv5_block9_2_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block10_0_bn (BatchN  (None, 7, 7, 800)            3200      ['conv5_block9_concat[0][0]'] \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block10_0_relu (Acti  (None, 7, 7, 800)            0         ['conv5_block10_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block10_1_conv (Conv  (None, 7, 7, 128)            102400    ['conv5_block10_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_1_bn (BatchN  (None, 7, 7, 128)            512       ['conv5_block10_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block10_1_relu (Acti  (None, 7, 7, 128)            0         ['conv5_block10_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block10_2_conv (Conv  (None, 7, 7, 32)             36864     ['conv5_block10_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_concat (Conc  (None, 7, 7, 832)            0         ['conv5_block9_concat[0][0]', \n",
            " atenate)                                                            'conv5_block10_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv5_block11_0_bn (BatchN  (None, 7, 7, 832)            3328      ['conv5_block10_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block11_0_relu (Acti  (None, 7, 7, 832)            0         ['conv5_block11_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block11_1_conv (Conv  (None, 7, 7, 128)            106496    ['conv5_block11_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_1_bn (BatchN  (None, 7, 7, 128)            512       ['conv5_block11_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block11_1_relu (Acti  (None, 7, 7, 128)            0         ['conv5_block11_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block11_2_conv (Conv  (None, 7, 7, 32)             36864     ['conv5_block11_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_concat (Conc  (None, 7, 7, 864)            0         ['conv5_block10_concat[0][0]',\n",
            " atenate)                                                            'conv5_block11_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv5_block12_0_bn (BatchN  (None, 7, 7, 864)            3456      ['conv5_block11_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block12_0_relu (Acti  (None, 7, 7, 864)            0         ['conv5_block12_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block12_1_conv (Conv  (None, 7, 7, 128)            110592    ['conv5_block12_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_1_bn (BatchN  (None, 7, 7, 128)            512       ['conv5_block12_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block12_1_relu (Acti  (None, 7, 7, 128)            0         ['conv5_block12_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block12_2_conv (Conv  (None, 7, 7, 32)             36864     ['conv5_block12_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_concat (Conc  (None, 7, 7, 896)            0         ['conv5_block11_concat[0][0]',\n",
            " atenate)                                                            'conv5_block12_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv5_block13_0_bn (BatchN  (None, 7, 7, 896)            3584      ['conv5_block12_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block13_0_relu (Acti  (None, 7, 7, 896)            0         ['conv5_block13_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block13_1_conv (Conv  (None, 7, 7, 128)            114688    ['conv5_block13_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_1_bn (BatchN  (None, 7, 7, 128)            512       ['conv5_block13_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block13_1_relu (Acti  (None, 7, 7, 128)            0         ['conv5_block13_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block13_2_conv (Conv  (None, 7, 7, 32)             36864     ['conv5_block13_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_concat (Conc  (None, 7, 7, 928)            0         ['conv5_block12_concat[0][0]',\n",
            " atenate)                                                            'conv5_block13_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv5_block14_0_bn (BatchN  (None, 7, 7, 928)            3712      ['conv5_block13_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block14_0_relu (Acti  (None, 7, 7, 928)            0         ['conv5_block14_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block14_1_conv (Conv  (None, 7, 7, 128)            118784    ['conv5_block14_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_1_bn (BatchN  (None, 7, 7, 128)            512       ['conv5_block14_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block14_1_relu (Acti  (None, 7, 7, 128)            0         ['conv5_block14_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block14_2_conv (Conv  (None, 7, 7, 32)             36864     ['conv5_block14_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_concat (Conc  (None, 7, 7, 960)            0         ['conv5_block13_concat[0][0]',\n",
            " atenate)                                                            'conv5_block14_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv5_block15_0_bn (BatchN  (None, 7, 7, 960)            3840      ['conv5_block14_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block15_0_relu (Acti  (None, 7, 7, 960)            0         ['conv5_block15_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block15_1_conv (Conv  (None, 7, 7, 128)            122880    ['conv5_block15_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_1_bn (BatchN  (None, 7, 7, 128)            512       ['conv5_block15_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block15_1_relu (Acti  (None, 7, 7, 128)            0         ['conv5_block15_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block15_2_conv (Conv  (None, 7, 7, 32)             36864     ['conv5_block15_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_concat (Conc  (None, 7, 7, 992)            0         ['conv5_block14_concat[0][0]',\n",
            " atenate)                                                            'conv5_block15_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " conv5_block16_0_bn (BatchN  (None, 7, 7, 992)            3968      ['conv5_block15_concat[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block16_0_relu (Acti  (None, 7, 7, 992)            0         ['conv5_block16_0_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block16_1_conv (Conv  (None, 7, 7, 128)            126976    ['conv5_block16_0_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_1_bn (BatchN  (None, 7, 7, 128)            512       ['conv5_block16_1_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block16_1_relu (Acti  (None, 7, 7, 128)            0         ['conv5_block16_1_bn[0][0]']  \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block16_2_conv (Conv  (None, 7, 7, 32)             36864     ['conv5_block16_1_relu[0][0]']\n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_concat (Conc  (None, 7, 7, 1024)           0         ['conv5_block15_concat[0][0]',\n",
            " atenate)                                                            'conv5_block16_2_conv[0][0]']\n",
            "                                                                                                  \n",
            " bn (BatchNormalization)     (None, 7, 7, 1024)           4096      ['conv5_block16_concat[0][0]']\n",
            "                                                                                                  \n",
            " relu (Activation)           (None, 7, 7, 1024)           0         ['bn[0][0]']                  \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePoo  (None, 1024)                 0         ['relu[0][0]']                \n",
            " ling2D)                                                                                          \n",
            "                                                                                                  \n",
            " predictions (Dense)         (None, 1000)                 1025000   ['avg_pool[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8062504 (30.76 MB)\n",
            "Trainable params: 7978856 (30.44 MB)\n",
            "Non-trainable params: 83648 (326.75 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Application"
      ],
      "metadata": {
        "id": "n4_1BJ5-gL7p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VHvSfhOCdNBH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "681758bf-84e0-4bef-cb5e-8523dda4ca25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 303 images belonging to 101 classes.\n",
            "Found 303 images belonging to 101 classes.\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 7s 910ms/step - loss: 6.1939 - accuracy: 0.0250 - val_loss: 5.9271 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 5.6925 - accuracy: 0.0500 - val_loss: 5.6907 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 4.9541 - accuracy: 0.0256 - val_loss: 5.5296 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 4.9991 - accuracy: 0.0250 - val_loss: 5.3643 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 5.1917 - accuracy: 0.0500 - val_loss: 5.2181 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 4.5773 - accuracy: 0.0750 - val_loss: 5.0645 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 3.6763 - accuracy: 0.1750 - val_loss: 4.9535 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 577ms/step - loss: 4.4731 - accuracy: 0.1026 - val_loss: 4.7842 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 579ms/step - loss: 4.4555 - accuracy: 0.1500 - val_loss: 4.6494 - val_accuracy: 0.0594 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 583ms/step - loss: 3.5502 - accuracy: 0.1500 - val_loss: 4.5413 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 586ms/step - loss: 3.5845 - accuracy: 0.3000 - val_loss: 4.4210 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 583ms/step - loss: 3.2923 - accuracy: 0.3077 - val_loss: 4.2996 - val_accuracy: 0.0924 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 587ms/step - loss: 3.3181 - accuracy: 0.2250 - val_loss: 4.2040 - val_accuracy: 0.0924 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 581ms/step - loss: 3.3426 - accuracy: 0.3250 - val_loss: 4.1000 - val_accuracy: 0.1221 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 583ms/step - loss: 2.8668 - accuracy: 0.3750 - val_loss: 4.0060 - val_accuracy: 0.1386 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 582ms/step - loss: 2.9689 - accuracy: 0.4000 - val_loss: 3.9243 - val_accuracy: 0.1386 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 577ms/step - loss: 2.3699 - accuracy: 0.5250 - val_loss: 3.8516 - val_accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 2.4126 - accuracy: 0.5385 - val_loss: 3.7739 - val_accuracy: 0.1749 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 2.2467 - accuracy: 0.5000 - val_loss: 3.7038 - val_accuracy: 0.1716 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 2.2073 - accuracy: 0.5500 - val_loss: 3.6459 - val_accuracy: 0.1881 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 1.9939 - accuracy: 0.5750 - val_loss: 3.5907 - val_accuracy: 0.2013 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 2.0091 - accuracy: 0.5897 - val_loss: 3.5206 - val_accuracy: 0.2079 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 2.4926 - accuracy: 0.4500 - val_loss: 3.4549 - val_accuracy: 0.2310 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.4476 - accuracy: 0.7500 - val_loss: 3.4015 - val_accuracy: 0.2442 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.9123 - accuracy: 0.6000 - val_loss: 3.3491 - val_accuracy: 0.2508 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.2967 - accuracy: 0.8205 - val_loss: 3.3018 - val_accuracy: 0.2772 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.6489 - accuracy: 0.7000 - val_loss: 3.2651 - val_accuracy: 0.2739 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.8344 - accuracy: 0.7000 - val_loss: 3.2158 - val_accuracy: 0.2904 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.0782 - accuracy: 0.9250 - val_loss: 3.1812 - val_accuracy: 0.3168 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.1780 - accuracy: 0.8750 - val_loss: 3.1532 - val_accuracy: 0.3168 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 1.1525 - accuracy: 0.9250 - val_loss: 3.1236 - val_accuracy: 0.3168 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 1.1620 - accuracy: 0.8250 - val_loss: 3.0892 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.6551 - accuracy: 0.6750 - val_loss: 3.0451 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 1.0185 - accuracy: 0.8500 - val_loss: 3.0134 - val_accuracy: 0.3300 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 1.2366 - accuracy: 0.8000 - val_loss: 2.9797 - val_accuracy: 0.3531 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.9472 - accuracy: 0.8750 - val_loss: 2.9516 - val_accuracy: 0.3630 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.8220 - accuracy: 0.9500 - val_loss: 2.9277 - val_accuracy: 0.3762 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 0.7536 - accuracy: 0.9250 - val_loss: 2.9003 - val_accuracy: 0.3729 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.1312 - accuracy: 0.8750 - val_loss: 2.8684 - val_accuracy: 0.3729 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.0820 - accuracy: 0.8500 - val_loss: 2.8297 - val_accuracy: 0.3861 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.7894 - accuracy: 0.8750 - val_loss: 2.8103 - val_accuracy: 0.3828 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.6482 - accuracy: 0.9500 - val_loss: 2.7924 - val_accuracy: 0.3894 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.8708 - accuracy: 0.9250 - val_loss: 2.7752 - val_accuracy: 0.3927 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.6004 - accuracy: 0.9487 - val_loss: 2.7577 - val_accuracy: 0.3960 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 0.5510 - accuracy: 1.0000 - val_loss: 2.7468 - val_accuracy: 0.3960 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.5373 - accuracy: 1.0000 - val_loss: 2.7310 - val_accuracy: 0.4026 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.5595 - accuracy: 0.9750 - val_loss: 2.7144 - val_accuracy: 0.4191 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.4893 - accuracy: 0.9750 - val_loss: 2.6988 - val_accuracy: 0.4158 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 0.5579 - accuracy: 0.9750 - val_loss: 2.6873 - val_accuracy: 0.4224 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 0.7216 - accuracy: 0.9250 - val_loss: 2.6727 - val_accuracy: 0.4158 - lr: 0.0010\n"
          ]
        }
      ],
      "source": [
        "reverse_list = lambda l: list(reversed(l))\n",
        "\n",
        "DATA_FOLDER = r'/content/drive/MyDrive/Mestrado/SIN5006/Apresentacao II/Codigo/CalTech101'\n",
        "# DATA_FOLDER = \"CalTech101\"\n",
        "TRAIN_PATH = os.path.join(DATA_FOLDER, \"training\") # Path for training data\n",
        "VALID_PATH = os.path.join(DATA_FOLDER, \"validation\") # Path for validation data\n",
        "NUMBER_OF_CLASSES = len(os.listdir(TRAIN_PATH)) # Number of classes of the dataset\n",
        "EPOCHS = 50\n",
        "RESULTS_PATH = os.path.join(r'/content/drive/MyDrive/Mestrado/SIN5006/Apresentacao II/Codigo/', \"AutoConv_VGG16_randomsearch_log\" + \"_autoconv_v10.csv\") # The path to the results file\n",
        "# RESULTS_PATH = os.path.join(\"AutoConv_VGG16_new1\", \"AutoConv_VGG16_randomsearch_log_\" + DATA_FOLDER.split('/')[-1] + \"_autoconv_v10.csv\") # The path to the results file\n",
        "\n",
        "# Creating generators from training and validation data\n",
        "batch_size=8 # the mini-batch size to use for the dataset\n",
        "datagen = image.ImageDataGenerator(preprocessing_function=keras.applications.vgg16.preprocess_input) # creating an instance of the data generator\n",
        "train_generator = datagen.flow_from_directory(TRAIN_PATH, target_size=(224, 224), batch_size=batch_size) # creating the generator for training data\n",
        "valid_generator = datagen.flow_from_directory(VALID_PATH, target_size=(224, 224), batch_size=batch_size) # creating the generator for validation data\n",
        "\n",
        "# creating callbacks for the model -- ajusted (Fabio): monitor by val_accuracy\n",
        "reduce_LR = callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=np.sqrt(0.01), cooldown=0, patience=5, min_lr=0.5e-10)\n",
        "\n",
        "# Creating a CSV file if one does not exist\n",
        "try:\n",
        "    log_df = pd.read_csv(RESULTS_PATH, header=0, index_col=['index'])\n",
        "except FileNotFoundError:\n",
        "    # log_df = pd.DataFrame(columns=['index', 'activation', 'weight_initializer', 'num_layers_tuned', 'num_fc_layers', 'num_neurons', 'dropouts', 'filter_sizes', 'num_filters', 'stride_sizes', 'pool_sizes', 'train_loss', 'train_acc', 'val_loss', 'val_acc'])\n",
        "    log_df = pd.DataFrame(columns=['index', 'activation', 'weight_initializer', 'num_layers_tuned', 'num_fc_layers', 'num_neurons', 'dropouts', 'filter_sizes', 'num_filters', 'stride_sizes', 'pool_sizes', 'train_loss', 'train_acc', 'val_loss', 'val_acc', 'trainable_params', 'frozen_params', 'time'])\n",
        "    log_df = log_df.set_index('index')\n",
        "\n",
        "\n",
        "# utility function\n",
        "def upsample(shape, target_size=5):\n",
        "    upsampling_factor = math.ceil(target_size / shape[1])\n",
        "    return layers.UpSampling2D(size=(upsampling_factor, upsampling_factor))\n",
        "\n",
        "\n",
        "# function to modify architecture for current hyperparams\n",
        "# model: The original model to be modified.\n",
        "# index: The index of the layer in the model where modifications will start.\n",
        "# architecture: A list describing the desired architecture.\n",
        "# num_filters, filter_sizes, pool_sizes, acts: Lists of hyperparameters specific to each layer in the architecture.\n",
        "# zero_pads: Not used in this function.\n",
        "# optim_neurons, optim_dropouts: Lists of units and dropout rates for fully connected layers.\n",
        "\n",
        "def get_model_conv(model,\n",
        "                   index,\n",
        "                   architecture,\n",
        "                   num_filters,\n",
        "                   filter_sizes,\n",
        "                   pool_sizes,\n",
        "                   acts,\n",
        "                   zero_pads,\n",
        "                   optim_neurons,\n",
        "                   optim_dropouts):\n",
        "\n",
        "    X = model.layers[index - 1].output\n",
        "\n",
        "    for i in range(len(architecture)):\n",
        "        global_index = index + i\n",
        "        if architecture[i] == 'add':\n",
        "            continue\n",
        "\n",
        "        if architecture[i] == 'conv':\n",
        "            assert type(model.layers[global_index]) == layers.Conv2D\n",
        "            num_filter = num_filters.pop(0)\n",
        "            filter_size = filter_sizes.pop(0)\n",
        "            act = acts.pop(0)\n",
        "            try:\n",
        "                X = layers.Conv2D(filters=int(num_filter), kernel_size=(int(filter_size), int(filter_size)), kernel_initializer='he_normal', activation=act)(X)\n",
        "            except:\n",
        "                X = upsample(X.shape)(X)\n",
        "                X = layers.Conv2D(filters=int(num_filter), kernel_size=(int(filter_size), int(filter_size)), kernel_initializer='he_normal', activation=act)(X)\n",
        "        elif architecture[i] == 'maxpool':\n",
        "            assert type(model.layers[global_index]) == layers.MaxPooling2D\n",
        "            pool_size = pool_sizes.pop(0)\n",
        "            X = layers.MaxPooling2D(pool_size=int(pool_size))(X)\n",
        "        elif architecture[i] == 'globalavgpool':\n",
        "            assert type(model.layers[global_index]) == layers.GlobalAveragePooling2D\n",
        "            X = layers.GlobalAveragePooling2D()(X)\n",
        "        elif architecture[i] == 'batch':\n",
        "            assert type(model.layers[global_index]) == layers.BatchNormalization\n",
        "            X = layers.BatchNormalization()(X)\n",
        "        elif architecture[i] == 'activation':\n",
        "            assert type(model.layers[global_index]) == layers.Activation\n",
        "            X = layers.Activation(acts.pop(0))(X)\n",
        "        elif architecture[i] == 'flatten':\n",
        "            X = layers.Flatten()(X)\n",
        "\n",
        "    for units, dropout in zip(optim_neurons, optim_dropouts):\n",
        "        X = layers.Dense(units, kernel_initializer='he_normal', activation=acts.pop(0))(X)\n",
        "        X = layers.BatchNormalization()(X)\n",
        "        X = layers.Dropout(float(dropout))(X)\n",
        "\n",
        "    X = layers.Dense(NUMBER_OF_CLASSES, activation='softmax', kernel_initializer='he_normal')(X)\n",
        "    return models.Model(inputs=model.inputs, outputs=X)\n",
        "\n",
        "\n",
        "base_model = VGG16(input_shape=(224, 224, 3), weights='imagenet', include_top=True)\n",
        "for i in range(len(base_model.layers)):\n",
        "    base_model.layers[i].trainable = False\n",
        "\n",
        "# training original model\n",
        "X = base_model.layers[-2].output\n",
        "X = layers.Dense(NUMBER_OF_CLASSES, activation='softmax', kernel_initializer='he_normal')(X)\n",
        "to_train_model = models.Model(inputs=base_model.inputs, outputs=X)\n",
        "to_train_model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = to_train_model.fit_generator(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator, epochs=EPOCHS,\n",
        "    steps_per_epoch=len(train_generator) / batch_size,\n",
        "    validation_steps=len(valid_generator), callbacks=[reduce_LR]\n",
        ")\n",
        "\n",
        "# freezing the layers of the model\n",
        "base_model = VGG16(input_shape=(224, 224, 3), weights='imagenet', include_top=True)\n",
        "base_model = models.Model(inputs=base_model.inputs, outputs=base_model.layers[-2].output)\n",
        "for i in range(len(base_model.layers)):\n",
        "    base_model.layers[i].trainable = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "lHpiIy1iftGb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# optimize layers\n",
        "best_acc = 0\n",
        "\n",
        "# list of layers not considered in optimization\n",
        "meaningless = [\n",
        "    layers.Activation,\n",
        "    layers.GlobalAveragePooling2D,\n",
        "    layers.ZeroPadding2D,\n",
        "    layers.Add,\n",
        "    layers.Flatten\n",
        "]\n",
        "\n",
        "# search spaces for each kind of hyperparam\n",
        "filter_size_space = [1, 3]\n",
        "num_filter_space = [32, 64, 128, 256]\n",
        "pool_size_space = [2, 3]\n",
        "units_space = [2 ** j for j in range(6, 11)]\n",
        "dropouts_space = np.arange(0, 1, step=0.1).tolist()\n",
        "pad_size_space = list(range(1, 5))\n",
        "acts_space = [\n",
        "    activations.relu,\n",
        "    activations.sigmoid,\n",
        "    activations.tanh,\n",
        "    activations.elu,\n",
        "    activations.selu\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.utils.plot_model(\n",
        "    base_model, to_file='model.png', show_shapes=False, show_dtype=False,\n",
        "    show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96,\n",
        "    layer_range=None\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VtXqvpN8p4vq",
        "outputId": "9aa5c178-215d-43b7-b866-cd45dfdefa5d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAg4CAIAAABBY5QcAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzde1gTV94H8DPkShKSIDSCBoigFrCoCCjiWqH2KSjbLWpAEYtsa8X6Il7q4u66WhdtsYsVW8ULdddu8VkBwUdcXbWt1VoVUegFQQGlvip2MQqEcNPc5v1j3uZJAwkxDhnt+X3+InMm5/xmki8zJ5cJQZIkAgBjLkwXAADDIAMAd5ABgDvIAMAd2/lDJiYmOn9Q8KxYtWrV5MmTnTkiA8eB0tLS5uZm54/rZBcvXrx48SLTVTxjSktL79y54+RBGTgOIIRWrlyZlJTEyNBOQx3uDh48yHQhzxKCIJw/KMwHAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcPeUZuA///mPRCL597//zXQhaNOmTcQvvfDCC3R1fvHixaCgIBcXF4Ighg4dumnTJrp6tqasrMzf35/aEC8vrwULFgz2iE8/Zr4/MCBMrvgSGRl57dq1uLi4kydPNjQ0SKXSwR5xzpw5c+bMGTly5IMHD1paWgZ7uGfCU3ociI+P7+joePXVVwep/97e3qioKDtXLiwsJM3U1tYOUlWD5LE2FkNPaQYG29///neVSsV0FU6C1cY64GnMwLlz53x9fQmC2LFjB0Jo586dQqFQIBCUl5fPmDFDLBbL5fIDBw4ghD7++GM+ny+TyZYsWeLt7c3n86OioiorKxFCmZmZXC7Xy8uL6vN//ud/hEIhQRAPHjxYsWLFO++809TURBDEyJEjGdzSvp6Gjf3mm2+Cg4MlEgmfzw8JCTl58iRCaNGiRdQsIiAg4LvvvkMI/f73vxcIBBKJ5MiRIwaDYf369b6+vq6urmPHji0uLkYI/e1vfxMIBG5ubiqV6p133hk+fHhDQ8Mg7bcnQjodQqi4uNj2OtQXq7dv307dXLt2LULo1KlTHR0dKpVq6tSpQqFQq9WSJJmeni4UCq9evfrw4cO6urqIiAg3N7fbt2+TJJmSkjJ06FBTn7m5uQih+/fvkyQ5Z86cgIAAe6rduHGjXC6XSqUcDkehULz22muXLl2y545KpVKpVNqzZmxsLEKovb3daRsbEBAgkUis1XPw4MENGza0tbW1trZGRkZ6eHhQy+fMmcNise7evWtac/78+UeOHCFJcvXq1Twer7S0tL29/c9//rOLi8vly5dN27J8+fLt27fPnj372rVrtneFPc8N2j2NxwFroqKixGLxc889N2/evO7u7tu3b1PL2Wx2UFAQj8cLDg7euXNnZ2fnvn376Bp04cKFR44cuXPnTldX14EDB27fvj1t2rS6ujq6+reGkY2lKJXKd999193dfciQIb/73e9aW1vv37+PEHr77bcNBoNpOI1Gc/ny5ZkzZz58+HDnzp2zZs2aM2eOVCr9y1/+wuFwzKvavHlzRkZGWVlZYGAgvaXS4lnKgAmXy0UI6XS6vk3h4eECgaC+vp6usXx8fEJDQ0UiEZfLjYyM3LdvX29vb35+Pl39D8iZG9sXh8NBCBkMBoTQSy+9NHr06H/84x/UP+yioqJ58+axWKyGhoaenh7TS8aurq5eXl6DWhW9nskM2Mbj8aj/W4MhJCSExWI1NjYOUv+PazA29tixY9HR0c899xyPx8vKyjItJwhiyZIlP/7446lTpxBCn3322ZtvvokQ6u7uRgj95S9/Mb2FcuvWrZ6eHnqrGjy/tgzodDq1Wi2Xywepf6PRaDQaeTzeIPX/WOjd2LNnz+bl5d2+fXvWrFleXl6VlZUdHR0ffPCB+TppaWl8Pn/v3r0NDQ1isdjPzw8h9NxzzyGE8vLyzE+yKyoqaKnKCZ7S98gcdubMGZIkIyMjEUJsNrvfU4jHEhsbS70wQqGmek6+GKA19G5sdXW1UCi8cuWKTqdbunSpv78/6nPRK3d397lz5xYVFbm5ub311lvUQh8fHz6f//333z/J6Az6NRwHjEZje3u7Xq+vqalZsWKFr69vWloaQmjkyJFtbW2HDx/W6XT379+/deuW6S5Dhgz56aef/vd//7ezs9P2U+fu3btFRUVqtVqn01VUVCxatMjX1/ftt98e7I2yZjA2VqfT3bt378yZM0Kh0NfXFyH05ZdfPnz48Pr169Rrr+befvvtR48eHT161PQOJp/P//3vf3/gwIGdO3dqNBqDwdDc3Pzf//53kPYA/Zz8OhRpx+tf27dvp17qFggEv/vd7/Lz8wUCAUJo1KhRTU1NBQUFYrEYIeTn59fY2Jiens7hcIYPH85ms8VicUJCQlNTE9VPa2trTEwMn88fMWLEsmXL/vCHPyCERo4cefv27W+//dbPz8/V1fU3v/lNS0uLjWLeeeedgIAAoVDIZrPlcvlbb731008/2bOZ9rw2evHixTFjxri4uCCEvLy83nvvvcHe2F27dgUEBFh7Mhw6dIgkyTVr1gwZMkQqlSYmJlJv0QQEBFCvwFJCQ0P/9Kc/mW/Io0eP1qxZ4+vry2azn3vuuTlz5tTV1X3wwQeurq4IIR8fH4v32q0Z8LkxGJ7GDDyW9PT0IUOG0NUbjex/f8B+T8nGzpw588cffxyMnhnJwK/hXIh65Q4TTG2s6SSqpqaGOtowUsZg+DVk4EnU19cT1s2bN4/pAp8Wa9asuX79emNj4+9///uNGzcyXQ6dnu0M/PnPf963b19HR8eIESNKS0sd6CEwMNDGUbKoqIj2mh325Bv7JAQCQWBg4Msvv7xhw4bg4GAnjz6oCNLpn9QnCKK4uBh+fwD0xchz49k+DgDw5CADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOCOme/U5+Xl/eo/UHnx4kX086dHwdOMgQwolUrnD+p81OUeBnT27NmgoCDq8iRAqVT6+Pg4eVAGvj8AzGHybYqnGcwHAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDu4HdonC09Pb2hocF08/z5888//7ynpyd1k8Vi/fOf/5TL5QxVhyNmfpMPZzKZrKCgwHxJXV2d6e8RI0ZAAJwMzoWcLSUlxVoTl8tNS0tzYi0AITgXYsSYMWOuXbvW755vaGgYPXq080vCGRwHGJCamspisSwWEgQxduxYCIDzQQYYMH/+fIPBYLGQzWYvXLiQkXowB+dCzIiMjLx8+bLRaDQtIQjizp07w4cPZ7AqPMFxgBmpqakEQZhuuri4TJkyBQLACMgAMyx+mJ4giNTUVKaKwRxkgBmenp7Tp083nxnPnj2bwXpwBhlgzIIFC6jJGIvFiouL8/DwYLoiTEEGGJOQkMDhcBBCJEkuWLCA6XLwBRlgjJub26uvvooQ4nK51B+AEbR9Xqi5ufnChQt09YYJhUKBEJowYcKxY8eYruUZ4+PjM3nyZHr6ImlSXFxMT0EA2EGpVNL11KX5XIiusvDxzjvvPHr0yLH7Uv936K3nmaBUKml80sJ8gGEbN27kcrlMV4E1yADDXF1dmS4Bd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHDn1AxERESwWKzx48f3bdqyZYtMJiMIYvfu3Y51npOTI5FICIL4/vvvra1jNBrz8vKioqIcG2KwDWp5DQ0Ny5YtGzNmjJubG5vNlkgko0ePjo+Pr6ioGIzhsrOzg4ODxWIxj8cbOXJkVlZWV1cXQqisrMzf358ww+VyZTJZdHR0bm5ue3v7YBQzALo+0m3nZ9mnT58+bty4fpuuX7+OENq1a5fDNRw4cAAh9N133/Xb2tjYOGXKFISQtQKY5UB59n9/YO/evRwO58UXXzxx4kR7e/vDhw+bmpqKioqioqL27NnzBFVbNW3atPz8/NbWVo1GU1xczOFw4uLiTK0BAQESiYQkSaPR2N7efvr06bS0NIIgvL29L1++PGDnSqWSxu/QMHDtdfNrSznNDz/8kJ2d/fbbb3d3d5NP36X1BrW8ixcvpqenT5s27eTJk2z2/z/i/v7+/v7+UqmU+tdDO5FIlJ6eTl08JikpqaysrKSk5M6dOz4+PuarEQQhlUqjo6Ojo6Pj4+Pnzp0bHx/f2NgokUgGo6p+MTAfoC6m4GTjxo0rKytLSUnh8XjOH31Ag1repk2bDAZDTk6OKQAmsbGxGRkZtI+IEDp69Kj51ZOoHxnp6emxcRelUpmWlqZSqRw+H3YMAxm4ceNGYGCgUCh0dXWdOnXquXPn+l2NJMmtW7cGBQXxeDx3d/eEhIT6+npTa2FhYXh4OJ/PFwqFCoVi48aNFne/d++eQqFgs9lxcXFPUm2/A1mrbefOnUKhUCAQlJeXz5gxQywWy+Vy6gwtKCiIIAgXF5ewsDDqqZCVlSWRSPh8/qeffvokFdqm1WpPnTrl4eExceJEG6sN9hbdvXvX1dV1xIgRtqulfn7h+PHjjm+wA+g6qbJ/PuDv73/z5k2dTldbWztp0iQ+n9/Y2Ej2mQ+sX7+ey+UWFhaq1eqampoJEyZ4enq2tLSQJJmXl4cQysnJaW1tbWtr27NnT0pKCvnL+YBWq50zZ055eblFAZMmTbL/hNvaQDZqW7t2LULo1KlTHR0dKpVq6tSpQqFQq9Xq9XqFQuHr66vX6039r1y5Mi8vz+Hy7NnnjY2NCKHIyEjbqw3eFpEk2d3d7ebmlpmZaVpimg9Y0Gg0CCEfHx/b1dI7H2B4TlxTU4MQWr16NfnLDPT09IhEonnz5pnWvHTpEkIoOztbq9VKpdKYmBhTk16v37ZtG2mWAZ1Ol5ycfPz48b4F2P8kszaQjdrIn58xvb29VFN+fj5C6MaNG+TPiSopKaGauru7fX19Ozo6HCuPtG+fV1VVIYRefvllG+sM6hZRPYwePVqj0ZiWWMsASZLUDMH2RtGbAYbfHwgJCZFIJFQSzNXV1XV1dYWHh5uWREREcLncysrKmpoatVodGxtramKxWMuXLzfdNBgM8+fPl8lkT3gWZG0gG7X17YT6vrxOp0MILVq0SCKRbNu2jWrav39/QkKCWCx+kiIHJBKJ0EAn4oO6RYcOHSopKTl58qSbm9uA1VIvCQz2PrHA/HtkHA6H2qHm1Go1+vnxM5FKpZ2dndThUiqVWuswIyPj+vXru3fvvnr16pMUZm0gG7XZ7lAkEi1evPjChQvUf9ldu3ZlZmY+SYX2UCgU1NmmjXUGb4uKioo2b9585swZ6mpiA6LqDAwMtGdlujCcAb1e39bW5uvra7GceuZZPAZqtVoulw8bNgwh9ODBA2t9JiUlffHFF1KpNDU1Va/XO1ybtYFs1DZgn5mZmRwOJy8v7+zZsz4+PgEBAQ6XZycejxcbG/vgwYPz58/3bW1ra1u0aNEgbdH27dv379//1VdfUXvSHidOnEAIzZgxw871acFwBk6fPm00GidMmGCx/IUXXhCJRNS5LKWyslKr1YaFhSkUiiFDhnz++efW+oyJifH09CwoKKiurt60aZPDtVkbyEZtA/Ypl8uTkpJKS0vXrVu3YsUKh2t7LBs2bODxeKtWrert7bVoqq2tZbPZtG8RSZJr1qy5cuXK4cOHLQ4vNrS0tOTl5cnl8jfeeMPOu9CDromF/XPioKAgtVqt0+mqq6sDAwP9/PyoWZTF60Lvvvsuh8MpLCzs6OioqakJDQ319vbu6uoiSXLLli0IoWXLljU3NxsMBo1GU1dXR/Z5nzgtLY3NZldVVZkX8FiTTmsD2ajNYgb5ySefIISoX6GkfPvttwihkJCQfkekfU5MKS0tFQgEYWFhx44dU6vVWq32xx9/LCgoGDlyZEZGBu1bVFtb2++TLTc3l1ohICBALBZ3dnYaDAaj0ahSqYqKivz9/b28vCwer349268L7du3LyYmRiaTsdlsDw+P5OTkW7dukST54YcfDh06FCEkFApnz55NkqTRaMzNzR01ahSHw3F3d581a1ZDQ4Opnx07doSEhPD5fD6fHxoamp+fX1ZW5u7ujhBSKBQqlUqj0VBvSYpEos8++6yiomLKlCne3t7Ug+Hl5RUVFfX1118PWHDfgWzUlp+fLxAIEEKjRo1qamoqKCigpnd+fn7U67+UmJiYvXv3mo/iWHmPda3F27dvr169OiQkRCQSsVgsqVQaGhr65ptvnj9/nvYtunLlirUMHDlyZOzYsQKBgMvluri4oJ/fKp44cWJ2dnZra6s920JvBmj7Tb6SkpK5c+fS1RuwB7b7PDExESF08OBBWnpj/nUhAJiFdQbq6+sJ6+bNm8d0gcAZGPjc6NMjMDAQwxMJYAHr4wAACDIAAGQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANzR/NnpkpISejsENlCXTcdwnzc3N9tzzQt70fWlTOq7rQA4x9P4fWLgGIIgiouLk5KSmC4EXzAfALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4o/n3yMCADhw40NnZab7kyy+/VKvVppsJCQkymczpdeELfovJ2RYuXPjZZ59xOBzqptFoJAiCIAiEkMFgEAqF9+/f5/F4jNaIFzgXcrbk5GSEkO5nBoNBr9dTf7NYrMTERAiAk8FxwNn0ev3QoUPb2tr6bf3yyy+nT5/u5JIwB8cBZ2Oz2cnJyaZzIXMeHh7R0dFOrwh3kAEGJCcn63Q6i4VcLvf1119nsViMlIQzOBdiAEmScrn8p59+slheWVk5ceJERkrCGRwHGEAQRGpqqsXpkI+PT0REBFMl4QwywAyL0yEOh5OWlka9QgqcDM6FGBMYGNjQ0GC6WVtbO2bMGAbrwRYcBxjz+uuvm06HgoODIQBMgQwwJjk5Wa/XI4Q4HM7ChQuZLgdfcC7EpPDw8G+//RYhdPPmTT8/P6bLwRQcB5iUmppKkuTEiRMhAEwiaVJcXMz0pgCMKJVKup66NH92GpLwuHJycpYuXSqRSBy4b0VFxbZt2zDc53l5eTT2RnMGkpKS6O3wVy80NHTUqFEO333btm0Y7vODBw/S2BvMBxj2JAEAtIAMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAnVMzEBERwWKxxo8f37dpy5YtMpmMIIjdu3c71nlOTo5EIiEI4vvvv7e2jtFozMvLi4qKcmyIwZOdnR0cHCwWi3k83siRI7Oysrq6uugdoqGhYdmyZWPGjHFzc2Oz2RKJZPTo0fHx8RUVFfQORLG2RWVlZf7+/oQZLpcrk8mio6Nzc3Pb29sHo5gB0PVlHOqbHAOuNn369HHjxvXbdP36dYTQrl27HK7hwIEDCKHvvvuu39bGxsYpU6YghKwVwKBp06bl5+e3trZqNJri4mIOhxMXFzfgvezc5yRJ7t27l8PhvPjiiydOnGhvb3/48GFTU1NRUVFUVNSePXueuPx+2N6igIAAiURCkqTRaGxvbz99+jR1eSVvb+/Lly8P2LlSqXx6v0dmD0auJPXDDz9kZ2e//fbb3d3d5NN3GQGRSJSenk5dbDQpKamsrKykpOTOnTs+Pj5P3vnFixfT09OnTZt28uRJNvv/H3F/f39/f3+pVEr966GdnVtEEIRUKo2Ojo6Ojo6Pj587d258fHxjY6NjX6xzDAPzgX4vuTzYxo0bV1ZWlpKS8nRe3f/o0aPmV9v19PRECPX09NDS+aZNmwwGQ05OjikAJrGxsRkZGbSMYsGBLVIqlWlpaSqVyuHzYccwkIEbN24EBgYKhUJXV9epU6eeO3eu39VIkty6dWtQUBCPx3N3d09ISKivrze1FhYWhoeH8/l8oVCoUCg2btxocfd79+4pFAo2mx0XF/ck1fY7kLXadu7cKRQKBQJBeXn5jBkzxGKxXC6nztCCgoIIgnBxcQkLC6OeCllZWRKJhM/nf/rppxaD3r1719XVdcSIEU9SOUWr1Z46dcrDw8P21Xyfki1KS0tDCB0/ftzxDXYAXSdV9s8H/P39b968qdPpamtrJ02axOfzGxsbyT7zgfXr13O53MLCQrVaXVNTM2HCBE9Pz5aWFpIkqa9U5+TktLa2trW17dmzJyUlhfzlfECr1c6ZM6e8vNyigEmTJtk/H7A2kI3a1q5dixA6depUR0eHSqWaOnWqUCjUarV6vV6hUPj6+ur1elP/K1euzMvLsxi0u7vbzc0tMzNzwPLs2eeNjY0IocjISNurOXmLTPMBCxqNBiHk4+Nju1p65wMMz4lramoQQqtXryZ/mYGenh6RSDRv3jzTmpcuXUIIZWdna7VaqVQaExNjatLr9du2bSPNMqDT6ZKTk48fP963APszYG0gG7WRPz9jent7qab8/HyE0I0bN8ifE1VSUkI1dXd3+/r6dnR0WIy7du3a0aNHazSaASu0Z59XVVUhhF5++WUb6zh/i6xlgCRJaoZge6PozQDD7w+EhIRIJBIqCebq6uq6urrCw8NNSyIiIrhcbmVlZU1NjVqtjo2NNTWxWKzly5ebbhoMhvnz58tksic8C7I2kI3a+nbC5XIRQtQlphctWiSRSLZt20Y17d+/PyEhQSwWm69/6NChkpKSkydPurm5PUnxJiKRCA10Iv70bBH1ioVFD4ON+ffIOBxO3x9loX6rlHr8TKRSaWdnJ3W4lEql1jrMyMi4fv367t27r169+iSFWRvIRm22OxSJRIsXL75w4QL1X3bXrl2ZmZnmKxQVFW3evPnMmTMKheJJKjenUCios00b6zw9W0TVGRgYaM/KdGE4A3q9vq2tzdfX12I59cyzeAzUarVcLh82bBhC6MGDB9b6TEpK+uKLL6RSaWpqKnVRW8dYG8hGbQP2mZmZyeFw8vLyzp496+PjExAQYGravn37/v37v/rqK2pcuvB4vNjY2AcPHpw/f75va1tb26JFi56eLTpx4gRCaMaMGXauTwuGM3D69Gmj0ThhwgSL5S+88IJIJKLOZSmVlZVarTYsLEyhUAwZMuTzzz+31mdMTIynp2dBQUF1dfWmTZscrs3aQDZqG7BPuVyelJRUWlq6bt26FStWUAtJklyzZs2VK1cOHz5s8c+YFhs2bODxeKtWrert7bVoqq2tZbPZT8kWtbS05OXlyeXyN954w8670IOuiYX9c+KgoCC1Wq3T6aqrqwMDA/38/KhZlMXrQu+++y6HwyksLOzo6KipqQkNDfX29u7q6iJJcsuWLQihZcuWNTc3GwwGjUZTV1dH9nmfOC0tjc1mV1VVmRfwWK8LWRvIRm0WM8hPPvkEIXTt2jVTn9SFpkNCQkxLamtr+31ocnNzbZdn//vEpaWlAoEgLCzs2LFjarVaq9X++OOPBQUFI0eOzMjIcP4WBQQEiMXizs5Og8FgNBpVKlVRUZG/v7+Xl5fF49WvZ/t1oX379sXExMhkMjab7eHhkZycfOvWLZIkP/zww6FDhyKEhELh7NmzSZI0Go25ubmjRo3icDju7u6zZs1qaGgw9bNjx46QkBA+n8/n80NDQ/Pz88vKytzd3RFCCoVCpVJpNBrqLUmRSPTZZ59VVFRMmTLF29ubejC8vLyioqK+/vrrAQvuO5CN2vLz8wUCAUJo1KhRTU1NBQUF1PTOz8+Pev2XEhMTs3fvXtPNK1euDHYGSJK8ffv26tWrQ0JCRCIRi8WSSqWhoaFvvvnm+fPnnblFR44cGTt2rEAg4HK5Li4u6Oe3iidOnJidnd3a2mrPttCbAdp+f6CkpGTu3Ll09Qbsge0+T0xMRPRddZT514UAYBbWGaivryesmzdvHtMFAmdg4HOjT4/AwEAMTySABayPAwAgyAAAkAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcEfzZ6cZuZ4u5vDc50qlkq6uaPsuZXNz84ULF2jpCitz585dsWLF5MmTmS7kGePj40PXTqMtA8AxBEEUFxcnJSUxXQi+YD4AcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4I7m32ICA1Kr1Ra/e9Ld3d3e3m66KRKJOByO0+vCF/wOjbPFxMScOXPGWiuLxWpubvby8nJiRbiDcyFnS05OtvYrei4uLi+++CIEwMkgA86WmJjIYrH6bSIIIjU11cn1AMiAs7m7u7/yyiv9xsDFxSUhIcH5JWEOMsCABQsWGI1Gi4VsNnvmzJlSqZSRknAGGWDAa6+9xuPxLBYajcYFCxYwUg/mIAMMEAgECQkJFi+A8ni8+Ph4pkrCGWSAGSkpKTqdznSTw+EkJia6uroyWBK2IAPMiI2NFYvFpps6nW7+/PkM1oMzyAAzOBxOcnIyl8ulbkql0unTpzNbErYgA4xJTk7WarUIIQ6Hk5KSwmbD51aYAZ+VYIzRaBw2bNi9e/cQQt98881vfvMbpivCFBwHGOPi4kK9GOrt7T1lyhSmy8HXL46/FRUVW7duZaoUDFEfFxWLxUlJSUzXgpHJkyevWrXKdPMXx4E7d+6UlpY6vaRfrebmZtv7093dXSwW+/r6Oq0kcPHixYqKCvMl/czDDh486Kx6fuVKSvHOEtwAACAASURBVErmzp1re3+WlJTAQcCZEhMTLZbAfIBhEADGQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAODusTMQERHBYrHGjx/ft2nLli0ymYwgiN27dztWTU5OjkQiIQji+++/t7aO0WjMy8uLiopybIgn9OTbaKGsrMzf358gCIIg1q1b1+86W7duJQjCxcUlMDDw7NmzTzgKQRAcDmf48OEpKSnXrl1zuPK+u+I///mPRCL597//7XCfCKHs7Ozg4GCxWMzj8UaOHJmVldXV1dV3EwiC4HK5MpksOjo6NzfX/OL1j400U1xcbLGkX9OnTx83bly/TdevX0cI7dq1a8BOrDlw4ABC6Lvvvuu3tbGxkfraobUCnMD+bbRzf5IkGRAQgBDy8vLSarUWTXq93s/PDyE0ffp0R8r95SgSiYQkya6uriNHjvj6+opEovr6eoc7tNgVR48eFYvFR44ceZIip02blp+f39raqtFoiouLORxOXFxc300wGo3t7e2nT59OS0sjCMLb2/vy5cv29K9UKpVKpfkSB8+FrF09fFD98MMPf/zjH99+++1+j0LPurCwsJaWlsOHD1ssLysrGz58OL1jCYXCV1999aOPPurq6tq+fTtd3cbHx3d0dLz66qtP0olIJEpPTx8yZIibm1tSUtKsWbNOnDhx584di9UIgpBKpdHR0fv27SspKbl37x41ugMjOpgBRn4oZdy4cWVlZSkpKX0v1vkrsHTpUoTQrl27LJZv3br1nXfeGYwRJ06ciBCqra0djM4fC0mSBw8eLCgoQAgdPXrU/KLcnp6eCKGenh4bd1cqlWlpaSqVyrETVAczcOPGjcDAQKFQ6OrqOnXq1HPnzvW7GkmSW7duDQoK4vF47u7uCQkJ9fX1ptbCwsLw8HA+ny8UChUKxcaNGy3ufu/ePYVCwWaz4+LiHKvz448/5vP5MplsyZIl3t7efD4/KiqqsrJywPJsVz4YXnrppaCgoNOnTzc0NJgWnj9/vqen55VXXrFY+ZtvvgkODpZIJHw+PyQk5OTJkwihTz/9VCQSEQTh7u5++PDhqqoqPz8/Fotl7Qp2er0eIUT9Q3nyXXHu3DlfX1+CIHbs2IEQ2rlzp1AoFAgE5eXlM2bMEIvFcrmcOtFFCBkMhvfff//55593dXX19PQcMWLE+++/3+9X6u7evevq6jpixAjbey8tLQ0hdPz4cdur9c/8xMj++YC/v//Nmzd1Ol1tbe2kSZP4fH5jYyPZ5wRx/fr1XC63sLBQrVbX1NRMmDDB09OzpaWFJMm8vDyEUE5OTmtra1tb2549e1JSUshfzge0Wu2cOXPKy8stCpg0aZL984H09HShUHj16tWHDx/W1dVFRES4ubndvn3bdnk2mgZpPnDz5s2PPvoIIbRixQrT8lmzZu3bt6+zsxP9cj5w8ODBDRs2tLW1tba2RkZGenh4UMuvXr0qEAgWLlxI3fzTn/60d+9e81Gok2lKYWEhQugPf/gDXbuCOmPZvn07dXPt2rUIoVOnTnV0dKhUqqlTpwqFQmrC895777FYrPLy8p6enurq6qFDh0ZHR/fdLd3d3W5ubpmZmdY2wUSj0SCEfHx8BtzVfecDNMyJa2pqEEKrV68mf7lTenp6RCLRvHnzTGteunQJIZSdna3VaqVSaUxMjKlJr9dv27aNNMuATqdLTk4+fvx43wIeNwPme+3y5csIob/+9a82yrPRRA5mBtRqtVAodHd37+npIUmyqalJLpc/evSobwbMvf/++wghlUpF3dyzZw9CaP/+/f/6179WrVplMYppTlxaWjp06FCZTNbc3EzXrug3A729vdTN/Px8hNCNGzdIkoyIiJg4caKpz8WLF7u4uDx69Mhi09auXTt69GiNRtN3E/qiZgj9NpmjbU5sLiQkRCKRUEkwV1dX19XVFR4ebloSERHB5XIrKytramrUanVsbKypicViLV++3HTTYDDMnz9fJpM5fBZkTXh4uEAgqK+vt1GejSZ6i7EgkUjmz5/f3t5eVFSEEMrLy1u6dKnpmqTWUHMzg8FA3Vy8eLFSqVyyZElJScnf/vY3i5U7OjoIgpBIJMuXL585c+alS5eGDx/unF1BbQh1te2HDx+SZhc4NBgMHA7H4rd5Dh06VFJScvLkSTc3twE77+7uJknS/DLG9qPnPTIOh2N+JXGKWq1GCIlEIvOFUqm0s7OTOnLZ+M2VjIyM69ev7969++rVq7RUaI7H492/f99GeTaaaC/GAjUz3r17t1qtPnjw4JIlS/pd7dixY9HR0c899xyPx8vKyrJofe+997q6ulQqVd87Uv9E9Xp9c3PzP/7xD+pVV+fvipkzZ1ZXV5eXl/f29lZVVR0+fPi3v/2teQaKioo2b9585swZhUJhT4eNjY0IocDAQAeKoSEDer2+ra2t74WiqKe4xc5Sq9VyuXzYsGEIoQcPHljrMykp6YsvvpBKpampqdTUjS46nY6qwUZ5NpporKRf48ePj4yMvHTpUnp6emJioru7e991bt++PWvWLC8vr8rKyo6Ojg8++MC8VafTLV++fOvWrRUVFZs2bbJnUOfvig0bNrz00ktpaWlisXj27NlJSUmffPKJqXX79u379+//6quvqOeJPU6cOIEQmjFjhgPF0JCB06dPG43GCRMmWCx/4YUXRCJRVVWVaUllZaVWqw0LC1MoFEOGDPn888+t9RkTE+Pp6VlQUFBdXW3nA2mnM2fOkCQZGRlpozwbTTRWYg11KCgtLV25cmW/K1y5ckWn0y1dutTf35/P51u8V7Ns2bK33npr5cqVq1at2rhxo8U11frl/F1RV1fX1NR0//59nU53+/btnTt3UmknSXLNmjVXrlw5fPiwxcHHhpaWlry8PLlc/sYbbzhSjfnkwP45cVBQkFqt1ul01dXVgYGBfn5+HR0dZJ9J0rvvvsvhcAoLCzs6OmpqakJDQ729vbu6ukiS3LJlC0Jo2bJlzc3NBoNBo9HU1dWRfd4nTktLY7PZVVVV5gU87pzYzc2tra1Np9P98MMPwcHBvr6+1PmojfJsNA3enJj6++HDh56ennPmzDG1WsyJqanXunXrent7GxsblUolQui///0vSZI7duygZqskST569CgkJGTEiBHUQ0PanFDSsitsz4mp//TXrl0jSTIyMnLatGnt7e0WZVh7syI3N9e0CWKxuLOz02AwGI1GlUpVVFTk7+/v5eVl8SSxhp7Xhfbt2xcTEyOTydhstoeHR3Jy8q1bt0iS/PDDD4cOHYoQEgqFs2fPJknSaDTm5uaOGjWKw+G4u7vPmjWroaHB1M+OHTtCQkL4fD6fzw8NDc3Pzy8rK6P+HygUCpVKpdFofHx8EEIikeizzz6rqKiYMmWKt7c3tV+8vLyioqK+/vpr29Wmp6dTH49hs9lisTghIaGpqYlqslGetaa+22iDPfvz0KFD1AclPD09MzIyqIVZWVkXLlyg/v7LX/5C/Wq3i4tLcHDwN998Q5LkmjVrhgwZIpVKExMTqdfjAwICxo8fTxDEkCFDqPuuXLnSxcUFISSRSD7++OPRo0dT+83b2zsxMdGijCffFdu3b6fqFAgEv/vd7/Lz8wUCAUJo1KhRTU1NBQUF1ITVz8+vsbHxq6++8vDwMD3FORxOUFBQWVnZlStXrGXgyJEjY8eOFQgEXC6X2i7qhaCJEydmZ2e3trba3s8m9GTg2UK98c7I0L/K/UmL/Px887dBHj16tHLlSh6PR70oPKj6ZgCL3z4xvW4IngYtLS2ZmZnmHw3mcrm+vr46nU6n0zn/hwmf+e8P1NfXE9bNmzeP6QKBJVdXVw6H8/e///3evXs6ne6nn37au3fv+vXr582b59gL/E/omc9AYGCgjQOfv7//vn37Ojo6RowYAT+t8JSQSCSff/55bW3t6NGjXV1dg4OD9+3bt3nz5n/+85+M1PMrPxd6//33qY8SgKfK1KlTv/jiC6ar+H/P/HEAgCcEGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd/18bjQxMdH5dfwqNTc3I9ifT5mLFy9GRkaaL/nFccDHx4f6gjaghVwuH3B/nj179v79+86pByCEIiMjJ0+ebL6EIM0u9wWcjyCI4uLifi83C5wD5gMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHfwOzTOlp6e3tDQYLp5/vz5559/3tPTk7rJYrH++c9/yuVyhqrDUT+/yQcGlUwmKygoMF9SV1dn+nvEiBEQACeDcyFnS0lJsdbE5XLT0tKcWAtACM6FGDFmzJhr1671u+cbGhpGjx7t/JJwBscBBqSmprJYLIuFBEGMHTsWAuB8kAEGzJ8/32AwWCxks9kLFy5kpB7MwbkQMyIjIy9fvmw0Gk1LCIK4c+fO8OHDGawKT3AcYEZqaipBEKabLi4uU6ZMgQAwAjLADIsfpicIIjU1laliMAcZYIanp+f06dPNZ8azZ89msB6cQQYYs2DBAmoyxmKx4uLiPDw8mK4IU5ABxiQkJHA4HIQQSZILFixguhx8QQYY4+bm9uqrryKEuFwu9QdgBG2fF2pubr5w4QJdvWFCoVAghCZMmHDs2DGma3nG+Pj4TJ48mZ6+SJoUFxfTUxAAdlAqlXQ9dWk+F6KrLHy88847jx49cuy+1P8deut5JiiVShqftDAfYNjGjRu5XC7TVWANMsAwV1dXpkvAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANw5NQMREREsFmv8+PF9m7Zs2SKTyQiC2L17t2Od5+TkSCQSgiC+//77vq3Z2dnBwcFisZjH440cOTIrK6urq8uxgQaP0WjMy8uLiooajM4bGhqWLVs2ZswYNzc3NpstkUhGjx4dHx9fUVExGMNZ2+FlZWX+/v6EGS6XK5PJoqOjc3Nz29vbB6OYAdD1kW47P8s+ffr0cePG9dt0/fp1hNCuXbscruHAgQMIoe+++65v07Rp0/Lz81tbWzUaTXFxMYfDiYuLc3igwdDY2DhlyhSEkLX905f93x/Yu3cvh8N58cUXT5w40d7e/vDhw6ampqKioqioqD179jxB1VbZ3uEBAQESiYQkSaPR2N7efvr06bS0NIIgvL29L1++PGDnSqWSxu/QMHDtdfNrSzmNSCRKT0+nrmWSlJRUVlZWUlJy584dHx8f5xfT1w8//JCdnf322293d3eTdF/57+LFi+np6dOmTTt58iSb/f+PuL+/v7+/v1Qqpf710M7OHU4QhFQqjY6Ojo6Ojo+Pnzt3bnx8fGNjo0QiGYyq+sXAfIC6mIKTHT161PxiPtRvXvT09Di/kn6NGzeurKwsJSWFx+PR3vmmTZsMBkNOTo4pACaxsbEZGRm0j4gc2uFKpTItLU2lUjl8PuwYBjJw48aNwMBAoVDo6uo6derUc+fO9bsaSZJbt24NCgri8Xju7u4JCQn19fWm1sLCwvDwcD6fLxQKFQrFxo0bLe5+7949hULBZrPj4uL6dn737l1XV9cRI0YMWG2/A1mrbefOnUKhUCAQlJeXz5gxQywWy+Vy6gwtKCiIIAgXF5ewsDDqqZCVlSWRSPh8/qeffmrnrnOAVqs9deqUh4fHxIkTbaw22Ftk5w6nfn7h+PHjjm+wA+g6qbJ/PuDv73/z5k2dTldbWztp0iQ+n9/Y2Ej2mQ+sX7+ey+UWFhaq1eqampoJEyZ4enq2tLSQJJmXl4cQysnJaW1tbWtr27NnT0pKCvnL+YBWq50zZ055eXnfGrq7u93c3DIzMwes1tpANmpbu3YtQujUqVMdHR0qlWrq1KlCoVCr1er1eoVC4evrq9frTf2vXLkyLy/PfMRJkybROx9obGxECEVGRtpebfC2iOxvh5vmAxY0Gg1CyMfHx3a19M4HGJ4T19TUIIRWr15N/jIDPT09IpFo3rx5pjUvXbqEEMrOztZqtVKpNCYmxtSk1+u3bdtGmmVAp9MlJycfP3683xrWrl07evRojUZju1RrA9mojfz5GdPb20s15efnI4Ru3LhB/pyokpISqqm7u9vX17ejo8N8UNozUFVVhRB6+eWXbawzqFtE9rfDrWWAJElqhmB7o+jNAMPvD4SEhEgkEioJ5urq6rq6usLDw01LIiIiuFxuZWVlTU2NWq2OjY01NbFYrOXLl5tuGgyG+fPny2Syfs+CDh06VFJScvLkSTc3N9u1WRvIRm19O6G+L6/T6RBCixYtkkgk27Zto5r279+fkJAgFottl/GERCIRGuhEfFC3yP4djhCiXhIY7H1igfn3yDgcDrVDzanVavTz42cilUo7Ozupw6VUKrXWYUZGxvXr13fv3n316lWLpqKios2bN585c4a6uJVt1gayUZvtDkUi0eLFiy9cuED9l921a1dmZuaAZTwhhUJBnW3aWGfwtuixdjhCiKozMDDQnpXpwnAG9Hp9W1ubr6+vxXLqmWfxGKjVarlcPmzYMITQgwcPrPWZlJT0xRdfSKXS1NRUvV5vWr59+/b9+/d/9dVXVA8DsjaQjdoG7DMzM5PD4eTl5Z09e9bHxycgIMCeSp4Ej8eLjY198ODB+fPn+7a2tbUtWrRokLbocXc4QujEiRMIoRkzZti5Pi0YzsDp06eNRuOECRMslr/wwgsikYg6l6VUVlZqtdqwsDCFQjFkyJDPP//cWp8xMTGenp4FBQXV1dWbNm1CCJEkuWbNmitXrhw+fNjiv50N1gayUduAfcrl8qSkpNLS0nXr1q1YscLOSp7Qhg0beDzeqlWrent7LZpqa2vZbDbtW+TYDm9pacnLy5PL5W+88Yadd6EHXRML++fEQUFBarVap9NVV1cHBgb6+flRsyiL14XeffddDodTWFjY0dFRU1MTGhrq7e3d1dVFkuSWLVsQQsuWLWtubjYYDBqNpq6ujuzzPnFaWhqbza6qqqqtre1323Nzc21Xa20gG7VZzCA/+eQThBD1K5SUb7/9FiEUEhLS74i0z4kppaWlAoEgLCzs2LFjarVaq9X++OOPBQUFI0eOzMjIoH2LBtzhAQEBYrG4s7PTYDAYjUaVSlVUVOTv7+/l5VVVVTXg5jzbrwvt27cvJiZGJpOx2WwPD4/k5ORbt26RJPnhhx8OHToUISQUCmfPnk2SpNFozM3NHTVqFIfDcXd3nzVrVkNDg6mfHTt2hISE8Pl8Pp8fGhqan59fVlbm7u6OEFIoFCqVSqPRUG9JikSirKwsxzLQ70A2asvPzxcIBAihUaNGNTU1FRQUUNM7Pz8/6vVfSkxMzN69e81HqaiomDJlire3N1WYl5dXVFTU119/Tcs+p9y+fXv16tUhISEikYjFYkml0tDQ0DfffPP8+fO0b9GVK1es7fAjR46MHTtWIBBwuVwXFxf081vFEydOzM7Obm1ttWdb6M0Abb/JV1JSMnfuXLp6A/bAdp8nJiYihA4ePEhLb8y/LgQAs7DOQH19PWHdvHnzmC4QOAMDnxt9egQGBmJ4IgEsYH0cAABBBgCADADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO5o/O11SUkJvh8AG6rLpGO7z5uZme655YS+6vpRJfbcVAOd4Gr9PDBxDEERxcXFSUhLTheAL5gMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHc0/x4ZGNCBAwc6OzvNl3z55Zdqtdp0MyEhQSaTOb0ufMFvMTnbwoULP/vsMw6HQ900Go0EQRAEgRAyGAxCofD+/fs8Ho/RGvEC50LOlpycjBDS/cxgMOj1eupvFouVmJgIAXAyOA44m16vHzp0aFtbW7+tX3755fTp051cEubgOOBsbDY7OTnZdC5kzsPDIzo62ukV4Q4ywIDk5GSdTmexkMvlvv766ywWi5GScAbnQgwgSVIul//0008WyysrKydOnMhISTiD4wADCIJITU21OB3y8fGJiIhgqiScQQaYYXE6xOFw0tLSqFdIgZPBuRBjAgMDGxoaTDdra2vHjBnDYD3YguMAY15//XXT6VBwcDAEgCmQAcYkJyfr9XqEEIfDWbhwIdPl4AvOhZgUHh7+7bffIoRu3rzp5+fHdDmYguMAk1JTU0mSnDhxIgSASSRNiouLmd4UgBGlUknXU5fmz05DEh5XTk7O0qVLJRKJA/etqKjYtm0bhvs8Ly+Pxt5ozkBSUhK9Hf7qhYaGjho1yuG7b9u2DcN9fvDgQRp7g/kAw54kAIAWkAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALhzagYiIiJYLNb48eP7Nm3ZskUmkxEEsXv3bsc6z8nJkUgkBEF8//33fVuzs7ODg4PFYjGPxxs5cmRWVlZXV5djAw0GJ5TX0NCwbNmyMWPGuLm5sdlsiUQyevTo+Pj4iooKegeiWNuisrIyf39/wgyXy5XJZNHR0bm5ue3t7YNRzADo+jIO9U2OAVebPn36uHHj+m26fv06QmjXrl0O13DgwAGE0Hfffde3adq0afn5+a2trRqNpri4mMPhxMXFOTwQ7Rwrz859TpLk3r17ORzOiy++eOLEifb29ocPHzY1NRUVFUVFRe3Zs+eJy++H7S0KCAiQSCQkSRqNxvb29tOnT1OXV/L29r58+fKAnSuVShq/R8ZABsaPH99v06BmID4+Xq/Xm25S3zu5ffu2w2PRy7Hy7NznFRUVLBbrpZde0ul0Fk0nTpzYvn27AwUPyPYWmTJg7uDBgy4uLjKZTK1W2+6c3gwwMB/o95LLg+3o0aPml7P19PRECPX09Di/kn4NanmbNm0yGAw5OTlstuXXBmNjYzMyMmgZxYIDW6RUKtPS0lQqlcPnw45hIAM3btwIDAwUCoWurq5Tp049d+5cv6uRJLl169agoCAej+fu7p6QkFBfX29qLSwsDA8P5/P5QqFQoVBs3LjR4u737t1TKBRsNjsuLq5v53fv3nV1dR0xYsSA1fY7kLXadu7cKRQKBQJBeXn5jBkzxGKxXC6njk5BQUEEQbi4uISFhVFPhaysLIlEwufzP/30U4fLG5BWqz116pSHh4ftq/k+JVuUlpaGEDp+/LjjG+wAug4o9p8L+fv737x5U6fT1dbWTpo0ic/nNzY2kn3OhdavX8/lcgsLC9VqdU1NzYQJEzw9PVtaWkiSpL5SnZOT09ra2tbWtmfPnpSUFPKX50JarXbOnDnl5eV9a+ju7nZzc8vMzBywWmsD2aht7dq1CKFTp051dHSoVKqpU6cKhUKtVqvX6xUKha+vr/kZwsqVK/Py8hwuz5593tjYiBCKjIy0vZqTt6jfcyGSJDUaDULIx8fHdrXP/HzAfE5cU1ODEFq9ejX5ywz09PSIRKJ58+aZ1rx06RJCKDs7W6vVSqXSmJgYU5Ner9+2bRtplgGdTpecnHz8+PF+a1i7du3o0aM1Go3tUq0NZKM28udnTG9vL9WUn5+PELpx4wb5c6JKSkqopu7ubl9f346ODsfKI+3b51VVVQihl19+2cY6zt8iaxkgSZIgCKlUanujnvn5gLmQkBCJREIlwVxdXV1XV1d4eLhpSUREBJfLraysrKmpUavVsbGxpiYWi7V8+XLTTYPBMH/+fJlM1u9Z0KFDh0pKSk6ePOnm5ma7NmsD2aitbydcLhchRF1ietGiRRKJZNu2bVTT/v37ExISxGKxY+XZSSQSoYFOxJ+eLeru7iZJ0qKHwcb8e2QcDqfvj7JQv1VKPX4mUqm0s7OTOlxKpVJrHWZkZFy/fn337t1Xr161aCoqKtq8efOZM2cUCsWAhVkbyEZttjsUiUSLFy++cOEC9V92165dmZmZDpdnJ4VCQZ1t2ljn6dkiqs7AwEB7VqYLwxnQ6/VtbW2+vr4Wy6lnnsVjoFar5XL5sGHDEEIPHjyw1mdSUtIXX3whlUpTU1Opi9pStm/fvn///q+++orqYUDWBrJR24B9ZmZmcjicvLy8s2fP+vj4BAQEOFyenXg8Xmxs7IMHD86fP9+3ta2tbdGiRU/PFp04cQIhNGPGDDvXpwXDGTh9+rTRaJwwYYLF8hdeeEEkElHnspTKykqtVhsWFqZQKIYMGfL5559b6zMmJsbT07OgoKC6unrTpk0IIZIk16xZc+XKlcOHD1v8t7PB2kA2ahuwT7lcnpSUVFpaum7duhUrVlALHSvPfhs2bODxeKtWrert7bVoqq2tZbPZT8kWtbS05OXlyeXyN954w8670IOuiYX9c+KgoCC1Wq3T6aqrqwMDA/38/KhZlMXrQu+++y6HwyksLOzo6KipqQkNDfX29u7q6iJJcsuWLQihZcuWNTc3GwwGjUZTV1dH9nmPLC0tjc1mV1VV1dbW9rvtubm5tqu1NpCN2ixmkJ988glC6Nq1a6Y+qQtNh4SEmJY4XJ797xOXlpYKBIKwsLBjx46p1WqtVvvjjz8WFBSMHDkyIyPD+VsUEBAgFos7OzsNBoPRaFSpVEVFRf7+/l5eXlVVVQNuzrP9utC+fftiYmJkMhmbzfbw8EhOTr516xZJkh9++OHQoUMRQkKhcPbs2SRJGo3GlW76zAAAIABJREFU3NzcUaNGcTgcd3f3WbNmNTQ0mPrZsWNHSEgIn8/n8/mhoaH5+fllZWXu7u4IIYVCoVKpNBqNj48PQkgkEmVlZTn2JOt3IBu15efnCwQChNCoUaOampoKCgqo6Z2fnx/1+i8lJiZm7969pptXrlwZ7AyQJHn79u3Vq1eHhISIRCIWiyWVSkNDQ998883z5887c4uOHDkyduxYgUDA5XJdXFwQQtQLQRMnTszOzm5tbbVnW+jNAG2/P1BSUjJ37ly6egP2wHafJyYmIvquOsr860IAMAvrDNTX1xPWzZs3j+kCgTPQfO31Z0tgYCCGJxLAAtbHAQAQZAAAyADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuKP5s9MEQdDbIRgQnvtcqVTS1RVt36Vsbm6+cOECLV1hZe7cuStWrJg8eTLThTxjfHx86NpptGUAOIYgiOLiYurS5IARMB8AuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcEfzbzGBAanVaovfPenu7m5vbzfdFIlEHA7H6XXhC36HxtliYmLOnDljrZXFYjU3N3t5eTmxItzBuZCzJScnW/sVPRcXlxdffBEC4GSQAWdLTExksVj9NhEEkZqa6uR6AGTA2dzd3V955ZV+Y+Di4pKQkOD8kjAHGWDAggULjEajxUI2mz1z5kypVMpISTiDDDDgtdde4/F4FguNRuOCBQsYqQdzkAEGCASChIQEixdAeTxefHw8UyXhDDLAjJSUFJ1OZ7rJ4XASExNdXV0ZLAlbkAFmxMbGisVi002dTjd//nwG68EZZIAZHA4nOTmZy+VSN6VS6fTp05ktCVuQAcYkJydrtVqEEIfDSUlJYbPhcyvMgM9KMMZoNA4bNuzevXsIoW+++eY3v/kN0xVhCo4DjHFxcaFeDPX29p4yZQrT5eDrF8ffioqKrVu3MlUKhqiPi4rF4qSkJKZrwcjkyZNXrVpluvmL48CdO3dKS0udXtKvVnNzs+396e7uLhaLfX19nVYSuHjxYkVFhfmSfuZhBw8edFY9v3IlJSVz5861vT9LSkrgIOBMiYmJFktgPsAwCADjIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHD32BmIiIhgsVjjx4/v27RlyxaZTEYQxO7dux2rJicnRyKREATx/fff923Nzs4ODg4Wi8U8Hm/kyJFZWVldXV2ODeSwJ99GC2VlZf7+/gRBEASxbt26ftfZunUrQRAuLi6BgYFnz559wlEIguBwOMOHD09JSbl27ZrDlffdFf/5z38kEsm///1vh/tE1h9li00gCILL5cpksujo6NzcXPOL1z820kxxcbHFkn5Nnz593Lhx/TZdv34dIbRr164BO7HmwIEDCKHvvvuub9O0adPy8/NbW1s1Gk1xcTGHw4mLi3N4IIfZv4127k+SJAMCAhBCXl5eWq3Wokmv1/v5+SGEpk+f7ki5vxxFIpGQJNnV1XXkyBFfX1+RSFRfX+9whxa74ujRo2Kx+MiRI09SpO1H2bQJRqOxvb399OnTaWlpBEF4e3tfvnzZnv6VSqVSqTRf4uC5kLWrhw8qkUiUnp4+ZMgQNze3pKSkWbNmnThx4s6dO86vZDCEhYW1tLQcPnzYYnlZWdnw4cPpHUsoFL766qsfffRRV1fX9u3b6eo2Pj6+o6Pj1VdffZJO7HyUCYKQSqXR0dH79u0rKSm5d+8eNboDIzqYAUZ+KOXo0aPml2v29PRECPX09Di/ksGwdOlShNCuXbsslm/duvWdd94ZjBEnTpyIEKqtrR2Mzh8LSZIHDx4sKChADj3KSqUyLS1NpVI5doLqYAZu3LgRGBgoFApdXV2nTp167ty5flcjSXLr1q1BQUE8Hs/d3T0hIaG+vt7UWlhYGB4ezufzhUKhQqHYuHGjxd3v3bunUCjYbHZcXFzfzu/evevq6jpixAgbdX788cd8Pl8mky1ZssTb25vP50dFRVVWVg5Ynu3KB8NLL70UFBR0+vTphoYG08Lz58/39PS88sorFit/8803wcHBEomEz+eHhIScPHkSIfTpp5+KRCKCINzd3Q8fPlxVVeXn58disaxdwU6v1yOEqKv/PvmuOHfunK+vL0EQO3bsQAjt3LlTKBQKBILy8vIZM2aIxWK5XE6d6CKEDAbD+++///zzz7u6unp6eo4YMeL999/v9yt19jzKCKG0tDSE0PHjx22v1j/zEyP75wP+/v43b97U6XS1tbWTJk3i8/mNjY1knxPE9evXc7ncwsJCtVpdU1MzYcIET0/PlpYWkiTz8vIQQjk5Oa2trW1tbXv27ElJSSF/OR/QarVz5swpLy/vW0N3d7ebm1tmZuaA1aanpwuFwqtXrz58+LCuri4iIsLNze327du2y7PRNEjzgZs3b3700UcIoRUrVpiWz5o1a9++fZ2dneiX84GDBw9u2LChra2ttbU1MjLSw8ODWn716lWBQLBw4ULq5p/+9Ke9e/eaj0KdTFMKCwsRQn/4wx/o2hXUGcv27dupm2vXrkUInTp1qqOjQ6VSTZ06VSgUUhOe9957j8VilZeX9/T0VFdXDx06NDo6uu9u6fsoW2yCiUajQQj5+PgMuKv7zgdomBPX1NQghFavXk3+cqf09PSIRKJ58+aZ1rx06RJCKDs7W6vVSqXSmJgYU5Ner9+2bRtplgGdTpecnHz8+PF+a1i7du3o0aM1Gs2A1aanp5vvtcuXLyOE/vrXv9ooz0YTOZgZUKvVQqHQ3d29p6eHJMmmpia5XP7o0aO+GTD3/vvvI4RUKhV1c8+ePQih/fv3/+tf/1q1apXFKKY5cWlp6dChQ2UyWXNzM127ot8M9Pb2Ujfz8/MRQjdu3CBJMiIiYuLEiaY+Fy9e7OLi8ujRI4tN6/soW8sASZLUDKHfJnO0zYnNhYSESCQSKgnm6urqurq6wsPDTUsiIiK4XG5lZWVNTY1arY6NjTU1sVis5cuXm24aDIb58+fLZLJ+z4IOHTpUUlJy8uRJNze3x602PDxcIBDU19fbKM9G0+MO91gkEsn8+fPb29uLiooQQnl5eUuXLjVdk9Qaam5mMBiom4sXL1YqlUuWLCkpKfnb3/5msXJHRwdBEBKJZPny5TNnzrx06dLw4cOdsyuoDaGutv3w4UPS7AKHBoOBw+FY/DbPYz3K3d3dJEmaX8bYfvS8R8bhcMyvJE5Rq9UIIZFIZL5QKpV2dnZSRy4bv7mSkZFx/fr13bt3X7161aKpqKho8+bNZ86cUSgUjlXL4/Hu379vozwbTY6NaD9qZrx79261Wn3w4MElS5b0u9qxY8eio6Ofe+45Ho+XlZVl0free+91dXWpVKq+d6T+ier1+ubm5n/84x/Uq67O3xUzZ86srq4uLy/v7e2tqqo6fPjwb3/7W/MMPO6j3NjYiBAKDAx0oBgaMqDX69va2vpeKIp6ilvsLLVaLZfLhw0bhhB68OCBtT6TkpK++OILqVSamppKTd0o27dv379//1dffUX14ACdTkfVYKM8G02ODWq/8ePHR0ZGXrp0KT09PTEx0d3dve86t2/fnjVrlpeXV2VlZUdHxwcffGDeqtPpli9fvnXr1oqKik2bNtkzqPN3xYYNG1566aW0tDSxWDx79uykpKRPPvnE1OrAo3zixAmE0IwZMxwohoZrHZ8+fdpoNE6YMMFi+QsvvCASiaqqqkxLKisrtVptWFiYQqEYMmTI559/Tp0y9hUTE+Pp6VlQUPDaa69t2rRpw4YNJEn+8Y9/bG9vP3z48JNcovnMmTMkSUZGRtooz0aTw+Pab+nSpRcvXiwtLaXOtvu6cuWKTqdbunSpv78/6vNezbJly956663Zs2ffvXt348aNr7zyyuTJk22P6PxdUVdX19TUdP/+fYuH0rFHuaWlJS8vTy6Xv/HGG45UYz45sH9OHBQUpFardTpddXV1YGCgn59fR0cH2WeS9O6773I4nMLCwo6OjpqamtDQUG9v766uLpIkt2zZghBatmxZc3OzwWDQaDR1dXVkn/eJ09LS2Gx2VVWVtZexc3NzbVebnp7u5ubW1tam0+l++OGH4OBgX19f6nzURnk2mgZvTkz9/fDhQ09Pzzlz5phaLebE1NRr3bp1vb29jY2NSqUSIfTf//6XJMkdO3ZQs1WSJB89ehQSEjJixAjqoSFtTihp2RW258TUf/pr166RJBkZGTlt2rT29naLMgZ8lAMCAsRicWdnp8FgMBqNKpWqqKjI39/fy8urqqrKnl1Nz+tC+/bti4mJkclkbDbbw8MjOTn51q1bJEl++OGHQ4cORQgJhcLZs2eTJGk0GnNzc0eNGsXhcNzd3WfNmtXQ0GDqZ8eOHSEhIXw+n8/nh4aG5ufnl5WVUUd/hUKhUqk0Go2Pjw9CSCQS9T3rtT8D1Mdj2Gy2WCxOSEhoamqimmyUZ62p7zbaYM/+PHToEPVBCU9Pz4yMDGph1v+xd+9xTdz5/vg/QzJJIIEEwSgaIIDSoEVFLqKuCrUtWk5dVEAQizxaj+y2iJe6+til2h60YhcqdJGq1B6reCpE8aGeut7qZa2KKGqXixXQ+q3SVqNACDeb2/z+mNP80kBCGodM7ef9/IvMTD6f90zyYuYzSWbWrLl06RL99zvvvEPftdvFxWXMmDFfffUVRVFr164dMmSIRCJJSkqiz8cHBQVNmDCBIIghQ4bQz125cqWLiwtCSCwW/+Mf/wgODqa3mI+PT1JSkkUZT78piouL6Trd3NzmzJlTUlLi5uaGEBo9evSdO3dKS0vpAau/v39TU9OZM2e8vLxMLyJJkiEhIZWVlXV1ddZe5SNHjowbN87NzY3H49HrRZ8IioqKys3NbW1ttb2dTZjJwLOF/uCdla5/l9uTESUlJeYfg/z0008rV67k8/n0SeFB1TcDWNz7xHTeEPwWPHjwIDs72/yrwTwez8/PT6fT6XQ659+Y8Jn//cCtW7cI61JSUtguEFhydXUlSfLTTz99+PChTqf74Ycfdu7cuX79+pSUFMdO8D+lZz4DCoXCxo4vMDBw165dHR0dAQEBcGuF3wixWHzy5Mn6+vrg4GBXV9cxY8bs2rVr8+bNu3fvZqWe3/mx0KZNm+ivEoDflGnTpp06dYrtKv7PM78fAOApQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwF0/3xtNSkpyfh2/Sy0tLQi252/M5cuXo6Ojzaf8Yj/g6+tL/0AbMEImkw24Pc+fP//o0SPn1AMQQtHR0RYX2iAos8t9AecjCKKioqLfy80C54DxAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHdyHxtkyMzMbGxtNDy9evPjcc895e3vTDzkczu7du2UyGUvV4aife/KBQSWVSktLS82nNDQ0mP4OCAiAADgZHAs5W1pamrVZPB4vIyPDibUAhOBYiBVjx4795ptv+t3yjY2NwcHBzi8JZ7AfYEF6ejqHw7GYSBDEuHHjIADOBxlgwcKFCw0Gg8VELpe7ePFiVurBHBwLsSM6Ovrq1atGo9E0hSCI+/fvjxw5ksWq8AT7AXakp6cTBGF66OLiMnXqVAgAKyAD7LC4MT1BEOnp6WwVgznIADu8vb1nzpxpPjKeN28ei/XgDDLAmkWLFtGDMQ6HM2vWLC8vL7YrwhRkgDUJCQkkSSKEKIpatGgR2+XgCzLAGnd391dffRUhxOPx6D8AKxj7vlBLS8ulS5eYag0TcrkcITRx4sSjR4+yXcszxtfXd/Lkycy0RTGkoqKCmYIAsENiYiJTb12Gj4WYKgsfb7/99k8//eTYc+n/O8zW80xITExk8E0L4wGWbdiwgcfjsV0F1iADLHN1dWW7BNxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAnVMzEBkZyeFwJkyY0HdWQUGBVColCGL79u2ONZ6XlycWiwmC+Prrr/vO/eCDDxQKhaurq1AoVCgU69at02g0jnU0eIxGY2Fh4ZQpUwaj8cbGxmXLlo0dO9bd3Z3L5YrF4uDg4Pj4+KqqqsHoLjc3d8yYMR4eHnw+f9SoUWvWrOnq6kIIVVZWBgYGEmZ4PJ5UKo2JicnPz29vbx+MYgbA1Fe67fwu+8yZM8ePH9/vrObmZoTQtm3bHK5h3759CKEbN270nRUfH19QUKBSqTo7O5VKJUmSL730ksMdDYampqapU6cihKxtn77s//3Azp07SZKcPn368ePH29vbnzx5cufOnfLy8ilTpuzYseMpqrZqxowZJSUlra2tGo2moqKCJMlZs2aZ5gYFBYnFYoqijEZje3v72bNnMzIyCILw8fG5evXqgI0nJiYy+BsaFq69bn5tKafh8XhvvfWWQCBACCUlJe3fv3///v0//vijj4+P84vp69///ndubu6f//zn7u5uiukr/12+fDkzM3PGjBknTpzgcv/vFQ8MDAwMDJRIJPS/HsaJRKLMzEz64jHJycmVlZVKpfL+/fu+vr7mixEEIZFIYmJiYmJi4uPjFyxYEB8f39TUJBaLB6OqfrEwHqAvpuBkBw8epANAo6/oRu+dfwvGjx9fWVmZlpbG5/MZb3zjxo0GgyEvL88UAJO4uLisrCzGe0QIffHFF+ZXT6JvMtLT02PjKYmJiRkZGSqVyuHjYcewkIHbt28rFAqhUOjq6jpt2rQLFy70uxhFUVu2bAkJCeHz+Z6engkJCbdu3TLNLSsri4iIEAgEQqFQLpdv2LDB4ukPHz6Uy+VcLnfWrFl9G29ubpZIJP7+/gNW229H1mr7+OOPhUKhm5vb4cOHZ8+e7eHhIZPJ6CO0kJAQgiBcXFzCw8Ppt8KaNWvEYrFAIPjss8/s3HQO0Gq1p0+f9vLyioqKsrHYYK/R999/7+rqGhAQYLta+vYLx44dc3yFHcDUQZX944HAwMC7d+/qdLr6+vpJkyYJBIKmpiaqz3hg/fr1PB6vrKxMrVbX1tZOnDjR29v7wYMHFEUVFhYihPLy8lpbW9va2nbs2JGWlkb9cjyg1Wrnz59/+PBh8961Wm1LS0txcTGfzy8rKxuwWmsd2agtJycHIXT69OmOjg6VSjVt2jShUKjVavV6vVwu9/Pz0+v1pvZXrlxZWFho3uOkSZOYHQ80NTUhhKKjo20vNnhrRFFUd3e3u7t7dna2aYppPGCBPlHh6+tru1pmxwMsj4lra2sRQqtXr6Z+mYGenh6RSJSSkmJa8sqVKwih3NxcrVYrkUhiY2NNs/R6fVFREWWWAZ1Ol5qaeuzYMYvehw0bhhDy8vL66KOPtFqt7VKtdWSjNurnd0xvby89q6SkBCF0+/Zt6udEKZVKelZ3d7efn19HR4d5p4xnoKamBiH04osv2lhmUNeIbiE4OFij0ZimWMsARVH0CMH2SjGbAZY/HwgNDRWLxXQSzDU0NHR1dUVERJimREZG8ni86urq2tpatVodFxdnmsXhcJYvX256aDAYFi5cKJVK+x4F3b9/X6VSff7557t37w4LC1OpVDZqs9aRjdr6NkL/Xl6n0yGElixZIhaLi4qK6Fl79+5NSEjw8PCwUcPTE4lEaKAD8UFdo4MHDyqVyhMnTri7uw9YLX1KYLC3iQX2PyMjSZLeoObUajX6+fUzkUgknZ2d9O5SIpFYazArK6u5uXn79u03b97s29fQoUNffvnl8vLyhoaGTZs22SjMWkc2arPRGv2UpUuXXrp0if4vu23btuzsbNtPeXpyuZw+2rSxzOCtUXl5+ebNm8+dO0dfTWxAdJ0KhcKehZnCcgb0en1bW5ufn5/FdPqdZ/EaqNVqmUw2YsQIhNDjx4+ttZmcnHzq1CmJRJKenq7X6/tdZtSoURwOx/yGkH1Z68hGbTZao2VnZ5MkWVhYeP78eV9f36CgoAGf8pT4fH5cXNzjx48vXrzYd25bW9uSJUsGaY2Ki4v37t175swZekva4/jx4wih2bNn27k8I1jOwNmzZ41G48SJEy2mP//88yKRiD6WpVVXV2u12vDwcLlcPmTIkJMnT1prMzY21tvbu7S09Nq1axs3bkQItba2Lly40HyZ5uZmg8Fgca7agrWObNQ20OoimUyWnJx84MCBdevWrVixYsDlGfHee+/x+fxVq1b19vZazKqvr+dyuYyvEUVRa9euraurO3TokMXuxYYHDx4UFhbKZLLXX3/dzqcwg6mBhf1j4pCQELVardPprl27plAo/P396VGUxXmhd999lyTJsrKyjo6O2trasLAwHx+frq4uiqIKCgoQQsuWLWtpaTEYDBqNpqGhgerzOXFGRgaXy62pqent7fXy8qLPbGi12uvXr0dHRwuFwrq6OtvVWuvIRm0WI8hPPvkEIUTfhZJ2/fp1hFBoaGi/PTI+JqYdOHDAzc0tPDz86NGjarVaq9V+++23paWlo0aNysrKYnyN6uvr+32z5efn0wsEBQV5eHh0dnYaDAaj0ahSqcrLywMDA4cPH15TUzPg6jzb54V27doVGxsrlUq5XK6Xl1dqaup3331HUdSHH35In7QRCoXz5s2jKMpoNObn548ePZokSU9Pz7lz5zY2Npra2bp1a2hoqEAgEAgEYWFhJSUllZWVnp6eCCG5XK5SqTQaDf1vXiQS7dmzZ86cOQEBASKRiM/nBwUFpaSkDBgAax3ZqK2kpMTNzQ0hNHr06Dt37pSWltLDO39/f/r8Ly02Nnbnzp3mvVRVVU2dOtX0ofXw4cOnTJnyr3/9i5FtTrt3797q1atDQ0NFIhGHw5FIJGFhYW+88cbFixcZX6O6ujprGThy5Mi4cePc3Nx4PJ6Liwv6+aPiqKio3Nzc1tZWe9aF2Qwwdk8+pVK5YMECploD9sB2myclJSGE9u/fz0hr7J8XAoBdWGfg1q1bhHUpKSlsFwicgYXvjf52KBQKDA8kgAWs9wMAIMgAAJABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHDH8HenlUolsw0CG+jLpmO4zVtaWuy55oW9mPpRJv3bVgCc47f4e2LgGIIgKioqkpOT2S4EXzAeALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4Y/h+ZGBA+/bt6+zsNJ/y5ZdfqtVq08OEhASpVOr0uvAF92JytsWLF+/Zs4ckSfqh0WgkCIIgCISQwWAQCoWPHj3i8/ms1ogXOBZyttTUVISQ7mcGg0Gv19N/czicpKQkCICTwX7A2fR6/bBhw9ra2vqd++WXX86cOdPJJWEO9gPOxuVyU1NTTcdC5ry8vGJiYpxeEe4gAyxITU3V6XQWE3k83muvvcbhcFgpCWdwLMQCiqJkMtkPP/xgMb26ujoqKoqVknAG+wEWEASRnp5ucTjk6+sbGRnJVkk4gwyww+JwiCTJjIwM+gwpcDI4FmKNQqFobGw0Payvrx87diyL9WAL9gOsee2110yHQ2PGjIEAsAUywJrU1FS9Xo8QIkly8eLFbJeDLzgWYlNERMT169cRQnfv3vX392e7HEzBfoBN6enpFEVFRUVBANhEMaSiooLtVQEYSUxMZOqty/B3pyEJv1ZeXt6bb74pFosdeG5VVVVRURGG27ywsJDB1hjOQHJyMrMN/u6FhYWNHj3a4acXFRVhuM3379/PYGswHmDZ0wQAMAIyAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd07NQGRkJIfDmTBhQt9ZBQUFUqmUIIjt27c71nheXp5YLCYI4uuvv+4794MPPlAoFK6urkKhUKFQrFu3TqPRONbRYMjNzR0zZoyHhwefzx81atSaNWu6urqY7aKxsXHZsmVjx451d3fncrlisTg4ODg+Pr6qqorZjmjW1qiysjIwMJAww+PxpFJpTExMfn5+e3v7YBQzAKZ+jEP/kmPAxWbOnDl+/Ph+ZzU3NyOEtm3b5nAN+/btQwjduHGj76z4+PiCggKVStXZ2alUKkmSfOmllxzuiHEzZswoKSlpbW3VaDQVFRUkSc6aNWvAZ9m5zSmK2rlzJ0mS06dPP378eHt7+5MnT+7cuVNeXj5lypQdO3Y8dfn9sL1GQUFBYrGYoiij0dje3n727Fn68ko+Pj5Xr14dsPHExEQGf0fGQgYmTJjQ76xBzcDcuXN7e3tND5OSkhBCP/zwg8N9MSs+Pl6v15se0j+LuXfvnu1n2bnNq6qqOBzOCy+8oNPpLGYdP368uLjYgYIHZHuNTBkwt3//fhcXF6lUqlarbTfObAZYGA/0e8nlwXbw4EGBQGB6OHLkSIQQ48cbDvviiy/Mr7br7e2NEOrp6WGk8Y0bNxoMhry8PC7X8meDcXFxWVlZjPRiwYE1SkxMzMjIUKlUDh8PO4aFDNy+fVuhUAiFQldX12nTpl24cKHfxSiK2rJlS0hRGrM+AAAgAElEQVRICJ/P9/T0TEhIuHXrlmluWVlZRESEQCAQCoVyuXzDhg0WT3/48KFcLudyubNmzerbeHNzs0QisedqDv12ZK22jz/+WCgUurm5HT58ePbs2R4eHjKZjN47hYSEEATh4uISHh5OvxXWrFkjFosFAsFnn31m0en333/v6uoaEBAwYHkD0mq1p0+f9vLysn0139/IGmVkZCCEjh075vgKO4CpHYr9x0KBgYF3797V6XT19fWTJk0SCARNTU1Un2Oh9evX83i8srIytVpdW1s7ceJEb2/vBw8eUBRF/6Q6Ly+vtbW1ra1tx44daWlp1C+PhbRa7fz58w8fPmzeu1arbWlpKS4u5vP5ZWVlA1ZrrSMbteXk5CCETp8+3dHRoVKppk2bJhQKtVqtXq+Xy+V+fn7mRwgrV64sLCy06LS7u9vd3T07O3vA8uzZ5k1NTQih6Oho24s5eY36PRaiKIo+UeHr62u72md+PGA+Jq6trUUIrV69mvplBnp6ekQiUUpKimnJK1euIIRyc3O1Wq1EIomNjTXN0uv1RUVFlFkGdDpdamrqsWPHLHofNmwYQsjLy+ujjz7SarW2S7XWkY3aqJ/fMaaxR0lJCULo9u3b1M+JUiqV9Kzu7m4/P7+Ojg6LfnNycoKDgzUaje3yKPu2eU1NDULoxRdftLGM89fIWgYoiiIIQiKR2F6pZ348YC40NFQsFtNJMNfQ0NDV1RUREWGaEhkZyePxqqura2tr1Wp1XFycaRaHw1m+fLnpocFgWLhwoVQq7XsUdP/+fZVK9fnnn+/evTssLEylUtmozVpHNmrr2wiPx0MI0ZeYXrJkiVgsLioqomft3bs3ISHBw8PDfPmDBw8qlcoTJ064u7vbqM1+IpEIDXQg/ttZo+7uboqiLFoYbOx/RkaSZN+bstD3KqVfPxOJRNLZ2UnvLiUSibUGs7Kympubt2/ffvPmzb59DR069OWXXy4vL29oaNi0aZONwqx1ZKM2G63RT1m6dOmlS5fo/7Lbtm3Lzs42X6C8vHzz5s3nzp2Ty+W2m7KfXC6njzZtLPPbWSO6ToVCYc/CTGE5A3q9vq2tzc/Pz2I6/c6zeA3UarVMJhsxYgRC6PHjx9baTE5OPnXqlEQiSU9Ppy9q29eoUaM4HE5DQ4ON2qx1ZKM2G63RsrOzSZIsLCw8f/68r69vUFCQaVZxcfHevXvPnDlD98sUPp8fFxf3+PHjixcv9p3b1ta2ZMmS384aHT9+HCE0e/ZsO5dnBMsZOHv2rNFonDhxosX0559/XiQS0ceytOrqaq1WGx4eLpfLhwwZcvLkSWttxsbGent7l5aWXrt2bePGjQih1tbWhQsXmi/T3NxsMBh8fX1t1GatIxu1DbS6SCaTJScnHzhwYN26dStWrKAnUhS1du3aurq6Q4cOWfwzZsR7773H5/NXrVrV29trMau+vp7L5f5G1ujBgweFhYUymez111+38ynMYGpgYf+YOCQkRK1W63S6a9euKRQKf39/ehRlcV7o3XffJUmyrKyso6OjtrY2LCzMx8enq6uLoqiCggKE0LJly1paWgwGg0ajaWhooPp8RpaRkcHlcmtqanp7e728vOgzG1qt9vr169HR0UKhsK6uzna11jqyUZvFCPKTTz5BCH3zzTemNukLTYeGhpqm1NfX9/vS5OfnM7LNKYo6cOCAm5tbeHj40aNH1Wq1Vqv99ttvS0tLR40alZWV5fw1CgoK8vDw6OzsNBgMRqNRpVKVl5cHBgYOHz68pqZmwNV5ts8L7dq1KzY2ViqVcrlcLy+v1NTU7777jqKoDz/8kD5pIxQK582bR1GU0WjMz88fPXo0SZKenp5z585tbGw0tbN169bQ0FCBQCAQCMLCwkpKSiorKz09PRFCcrlcpVJpNBr637xIJNqzZ8+cOXMCAgJEIhGfzw8KCkpJSRkwANY6slFbSUmJm5sbQmj06NF37twpLS2lh3f+/v70+V9abGzszp07TQ/r6uoGOwMURd27d2/16tWhoaEikYjD4UgkkrCwsDfeeOPixYvOXKMjR46MGzfOzc2Nx+O5uLgghOgTQVFRUbm5ua2trfasC7MZYOz+A0qlcsGCBUy1BuyB7Tanv+rC1FVH2T8vBAC7sM7ArVu3COtSUlLYLhA4A8PXXn+2KBQKDA8kgAWs9wMAIMgAAJABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHDH8HenCYJgtkEwIDy3eWJiIlNNMfZbypaWlkuXLjHSFFYWLFiwYsWKyZMns13IM8bX15epjcZYBoBjCIKoqKigL00OWAHjAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3DN+LCQxIrVZb3Peku7u7vb3d9FAkEpEk6fS68AX3oXG22NjYc+fOWZvL4XBaWlqGDx/uxIpwB8dCzpaammrtLnouLi7Tp0+HADgZZMDZkpKSOBxOv7MIgkhPT3dyPQAy4Gyenp4vv/xyvzFwcXFJSEhwfkmYgwywYNGiRUaj0WIil8t95ZVXJBIJKyXhDDLAgj/+8Y98Pt9iotFoXLRoESv1YA4ywAI3N7eEhASLE6B8Pj8+Pp6tknAGGWBHWlqaTqczPSRJMikpydXVlcWSsAUZYEdcXJyHh4fpoU6nW7hwIYv14AwywA6SJFNTU3k8Hv1QIpHMnDmT3ZKwBRlgTWpqqlarRQiRJJmWlsblwvdW2AHflWCN0WgcMWLEw4cPEUJfffXVH/7wB7YrwhTsB1jj4uJCnwz18fGZOnUq2+Xgi7H9b1VV1ZYtW5hqDRP010U9PDySk5PZruUZM3ny5FWrVjHSFGP7gfv37x84cICp1jDh6enp4eHh5+fn2NNbWlrw3OaXL1+uqqpiqjWGx2H79+9ntsHfPaVS6fBOQKlULliwAMNtnpSUxGBrMB5gGRwFsQ4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd07NQGRkJIfDmTBhQt9ZBQUFUqmUIIjt27c71nheXp5YLCYI4uuvv+4794MPPlAoFK6urkKhUKFQrFu3TqPRONbRYHBCeY2NjcuWLRs7dqy7uzuXyxWLxcHBwfHx8Qx+Ed9cbm7umDFjPDw8+Hz+qFGj1qxZ09XVhRCqrKwMDAwkzPB4PKlUGhMTk5+fb34NeuehGFJRUWFPazNnzhw/fny/s5qbmxFC27Ztc7iGffv2IYRu3LjRd1Z8fHxBQYFKpers7FQqlSRJvvTSSw53xDjHyrNzm1MUtXPnTpIkp0+ffvz48fb29idPnty5c6e8vHzKlCk7dux46vL7MWPGjJKSktbWVo1GU1FRQZLkrFmzTHODgoLEYjFFUUajsb29/ezZsxkZGQRB+Pj4XL16dcDGExMTExMTmSqVhQxMmDCh31mDmoG5c+f29vaaHtI/wvjhhx8c7otZjpVn5zavqqricDgvvPCCTqezmHX8+PHi4mIHCh5QfHy8Xq83PaR/JnHv3j36oSkD5vbv3+/i4iKVSunblNjAbAZYGA+wcpOVgwcPCgQC08ORI0cihOi982/BoJa3ceNGg8GQl5fX9/ItcXFxWVlZjPRi4YsvvjC/tra3tzdCqKenx8ZTEhMTMzIyVCqVw8fDjmEhA7dv31YoFEKh0NXVddq0aRcuXOh3MYqitmzZEhISwufzPT09ExISbt26ZZpbVlYWEREhEAiEQqFcLt+wYYPF0x8+fCiXy7lc7qxZs/o23tzcLJFI/P39B6y2346s1fbxxx8LhUI3N7fDhw/Pnj3bw8NDJpPRe6eQkBCCIFxcXMLDw+m3wpo1a8RisUAg+Oyzzxwub0Barfb06dNeXl5RUVE2FhvsNfr+++9dXV0DAgJsV5uRkYEQOnbsmOMr7ACmdij2HwsFBgbevXtXp9PV19dPmjRJIBA0NTVRfY6F1q9fz+PxysrK1Gp1bW3txIkTvb29Hzx4QFFUYWEhQigvL6+1tbWtrW3Hjh1paWnUL4+FtFrt/PnzDx8+bN67VqttaWkpLi7m8/llZWUDVmutIxu15eTkIIROnz7d0dGhUqmmTZsmFAq1Wq1er5fL5X5+fuZHCCtXriwsLHS4PHu2eVNTE0IoOjra9mKDtEa07u5ud3f37Oxs05R+j4UoiqLPBPj6+tqu9pkfD5iPiWtraxFCq1evpn6ZgZ6eHpFIlJKSYlryypUrCKHc3FytViuRSGJjY02z9Hp9UVERZZYBnU6Xmpp67Ngxi96HDRuGEPLy8vroo4+0Wq3tUq11ZKM26ud3jOngvqSkBCF0+/Zt6udEKZVKelZ3d7efn19HR4dj5VH2bfOamhqE0IsvvmhjmcFbI1pOTk5wcLBGozFNsZYBiqIIgpBIJLZX6pkfD5gLDQ0Vi8V0Esw1NDR0dXVFRESYpkRGRvJ4vOrq6traWrVaHRcXZ5rF4XCWL19uemgwGBYuXCiVSvseBd2/f1+lUn3++ee7d+8OCwtTqVQ2arPWkY3a+jZCX1GUvsT0kiVLxGJxUVERPWvv3r0JCQnmV979VeXZSSQSoYEOxAdvjRBCBw8eVCqVJ06ccHd3H7Da7u5uiqIsWhhs7H9GRpKk+VXIaWq1Gv38+plIJJLOzk56d2njfi1ZWVnNzc3bt2+/efNm376GDh368ssvl5eXNzQ0bNq0yUZh1jqyUZuN1uinLF269NKlS/R/2W3btmVnZztcnp3kcjl9tGljmcFbo/Ly8s2bN587d04ul9tTLV2nQqGwZ2GmsJwBvV7f1tbW9yJT9DvP4jVQq9UymWzEiBEIocePH1trMzk5+dSpUxKJJD09Xa/X97vMqFGjOBxOQ0ODjdqsdWSjNhut0bKzs0mSLCwsPH/+vK+vb1BQkMPl2YnP58fFxT1+/PjixYt957a1tS1ZsmSQ1qi4uHjv3r1nzpyht6Q9jh8/jhCaPXu2ncszguUMnD171mg0Tpw40WL6888/LxKJ6GNZWnV1tVarDQ8Pl8vlQ4YMOXnypLU2Y2Njvb29S0tLr127tnHjRoRQa2urxdX9m5ubDQaDr6+vjdqsdWSjtoFWF8lksuTk5AMHDqxbt27FihX0RMfKs997773H5/NXrVrV29trMau+vp7L5TK+RhRFrV27tq6u7tChQxa7FxsePHhQWFgok8lef/11O5/CDKYGFvaPiUNCQtRqtU6nu3btmkKh8Pf3p0dRFueF3n33XZIky8rKOjo6amtrw8LCfHx8urq6KIoqKChACC1btqylpcVgMGg0moaGBqrPZ2QZGRlcLrempqa3t9fLy4s+s6HVaq9fvx4dHS0UCuvq6mxXa60jG7VZjCA/+eQThNA333xjavP69esIodDQUNMUh8uz/3PiAwcOuLm5hYeHHz16VK1Wa7Xab7/9trS0dNSoUVlZWYyvUX19fb9vtvz8fHqBoKAgDw+Pzs5Og8FgNBpVKlV5eXlgYODw4cNramoGXJ1n+7zQrl27YmNjpVIpl8v18vJKTU397rvvKIr68MMP6bMiQqFw3rx5FEUZjcb8/PzRo0eTJOnp6Tl37tzGxkZTO1u3bg0NDRUIBAKBICwsrKSkpLKy0tPTEyEkl8tVKpVGo6H/j4pEoj179syZMycgIEAkEvH5/KCgoJSUlAHfYdY6slFbSUmJm5sbQmj06NF37twpLS2lh3f+/v70+V9abGzszp07zXtxrDz7M0BR1L1791avXh0aGioSiTgcjkQiCQsLe+ONNy5evMj4GtXV1VnLwJEjR8aNG+fm5sbj8VxcXBBC9ImgqKio3Nzc1tZWe9aF2Qwwdv8B+tqXTLUG7IHtNqe/S8LUhVbZPy8EALuwzsCtW7cI61JSUtguEDgD1vfAUigUGB5IAAtY7wcAQJABACADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOCO4e9O0z/wAc7R0tKCsNzmly9fjo6OZqo1xvYDvr6+iYmJTLWGj/Pnzz969Mix58pkMjy3eXR09OTJk5lqjbHfEwPHEARRUVFBX5ocsALGAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd3AfGmfLzMxsbGw0Pbx48eJzzz3n7e1NP+RwOLt375bJZCxVhyOG78kHBiSVSktLS82nNDQ0mP4OCAiAADgZHAs5W1pamrVZPB4vIyPDibUAhOBYiBVjx4795ptv+t3yjY2NwcHBzi8JZ7AfYEF6ejqHw7GYSBDEuHHjIADOBxlgwcKFCw0Gg8VELpe7ePFiVurBHBwLsSM6Ovrq1atGo9E0hSCI+/fvjxw5ksWq8AT7AXakp6cTBGF66OLiMnXqVAgAKyAD7LC4MT1BEOnp6WwVgznIADu8vb1nzpxpPjKeN28ei/XgDDLAmkWLFtGDMQ6HM2vWLC8vL7YrwhRkgDUJCQkkSSKEKIpatGgR2+XgCzLAGnd391dffRUhxOPx6D8AK37xfaGWlpZLly6xVQqG5HI5QmjixIlHjx5luxaM+Pr6Tp48+f9/TJmpqKhgrzAAnCQxMdH8bd/P90bhUzOmKJXKBQsW2N6eq1ev3rRpE4/Hc1pVmEtKSrKYAuMBlm3YsAECwC7IAMtcXV3ZLgF3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcPerMxAZGcnhcCZMmNB3VkFBgVQqJQhi+/btjlWTl5cnFosJgvj666/7zv3ggw8UCoWrq6tQKFQoFOvWrdNoNI515LCnX0cLlZWVgYGBBEEQBLFu3bp+l9myZQtBEC4uLgqF4vz580/ZC0EQJEmOHDkyLS3tm2++cbjyvpvin//8p1gs/t///V+H20QI5ebmjhkzxsPDg8/njxo1as2aNV1dXX1XgSAIHo8nlUpjYmLy8/Pb29sd77Lvb2iogcycOXP8+PH9zmpubkYIbdu2bcBGrNm3bx9C6MaNG31nxcfHFxQUqFSqzs5OpVJJkuRLL73kcEcOs38d7dyeFEUFBQUhhIYPH67Vai1m6fV6f39/hNDMmTMdKfeXvYjFYoqiurq6jhw54ufnJxKJbt265XCDFpviiy++8PDwOHLkyNMUOWPGjJKSktbWVo1GU1FRQZLkrFmz+q6C0Whsb28/e/ZsRkYGQRA+Pj5Xr161p/3ExESL39A4eCxkfn0op+HxeG+99dbQoUNFIlFSUlJCQsKpU6d+/PFH51cyGMLDwx88eHDo0CGL6ZWVlYxfe0soFL766qsfffRRV1dXcXExU83Gx8d3dHQ85W+jRSJRZmbmkCFD3N3dk5OT586de/z48fv371ssRhCERCKJiYnZtWuXUql8+PAh3bsDPTqYAfqCCE528OBBgUBgeki/M+gd5e/Am2++iRDatm2bxfQtW7a8/fbbg9FjVFQUQqi+vn4wGv9VKIrav38/fVuGL774wvyyS/TdSXp6emw8PTExMSMjQ6VSOXaA6mAGbt++rVAohEKhq6vrtGnTLly40O9iFEVt2bIlJCSEz+d7enomJCTcunXLNLesrCwiIkIgEAiFQrlcvmHDBounP3z4UC6Xc7ncWbNm9W28ublZIpHQxwnW/OMf/xAIBFKp9E9/+pOPj49AIJgyZUp1dfWA5dmufDC88MILISEhZ8+etbhLTU9Pz8svv2yx8FdffTVmzBixWCwQCEJDQ0+cOIEQ+uyzz0QiEUEQnp6ehw4dqqmp8ff353A4Cxcu7LdHvV6PEOLz+YiJTXHhwgU/Pz+CILZu3YoQ+vjjj4VCoZub2+HDh2fPnu3h4SGTyegDXYSQwWDYtGnTc8895+rq6u3tHRAQsGnTJotr79G+//57V1fXgIAA21uPvm/DsWPHbC/WP/MDI/vHA4GBgXfv3tXpdPX19ZMmTRIIBE1NTVSfA8T169fzeLyysjK1Wl1bWztx4kRvb+8HDx5QFFVYWIgQysvLa21tbWtr27FjR1paGvXL8YBWq50/f/7hw4fNe9dqtS0tLcXFxXw+v6ysbMBqMzMzhULhzZs3nzx50tDQEBkZ6e7ufu/ePdvl2Zg1SOOBu3fvfvTRRwihFStWmKbPnTt3165dnZ2d6Jfjgf3797/33nttbW2tra3R0dFeXl709Js3b7q5uS1evJh++Ne//nXnzp3mvdAH07SysjKE0F/+8hemNgV9xFJcXEw/zMnJQQidPn26o6NDpVJNmzZNKBTSA57333+fw+EcPny4p6fn2rVrw4YNi4mJ6btZuru73d3ds7Ozra2CCX12xNfXd8BN3Xc8wMCYuLa2FiG0evVq6pcbpaenRyQSpaSkmJa8cuUKQig3N1er1UokktjYWNMsvV5fVFREmWVAp9OlpqYeO3bMovdhw4YhhLy8vD766KO+I8i+MjMzzbfa1atXEUL/9V//ZaM8G7OowcyAWq0WCoWenp49PT0URd25c0cmk/300099M2Bu06ZNCCGVSkU/3LFjB0Jo7969n3/++apVqyx6MY2JDxw4MGzYMKlU2tLSwtSm6DcDvb299MOSkhKE0O3btymKioyMjIqKMrW5dOlSFxeXn376yWLVcnJygoODNRpN31Xoix4h9DvLHGNjYnOhoaFisZhOgrmGhoaurq6IiAjTlMjISB6PV11dXVtbq1ar4+LiTLM4HM7y5ctNDw0Gw8KFC6VSad+joPv376tUqs8//3z37t1hYWEqlepXVRsREeHm5nbr1i0b5dmY9av6+rXEYvHChQvb29vLy8sRQoWFhW+++eaAv7inx2amGxosXbo0MTHxT3/6k1Kp/Pvf/26xcEdHB0EQYrF4+fLlr7zyypUrV0aOHOmcTUGviE6nQwg9efKEMrvchsFgIEnS4r4kBw8eVCqVJ06ccHd3H7Dx7u5uiqI8PDx+bVWIqc/ISJKk182cWq1GCIlEIvOJEomks7OT3nNJJBJrDWZlZTU3N2/fvv3mzZt9+xo6dOjLL79cXl7e0NBA/xf8Vfh8/qNHj2yUZ2PWr+3r16JHxtu3b1er1fv37//Tn/7U72JHjx6NiYkZOnQon89fs2aNxdz333+/q6ur3/8O9D9RvV7f0tLy3//93/Royvmb4pVXXrl27drhw4d7e3tramoOHTr0H//xH+YZKC8v37x587lz5+jLkA2oqakJIaRQKBwohoEM6PX6trY2Pz8/i+n0W9xiY6nVaplMNmLECITQ48ePrbWZnJx86tQpiUSSnp5OD936GjVqFIfDMb+poz10Oh1dg43ybMz6VX05YMKECdHR0VeuXMnMzExKSvL09Oy7zL179+bOnTt8+PDq6uqOjo4PPvjAfK5Op1u+fPmWLVuqqqo2btxoT6fO3xTvvffeCy+8kJGR4eHhMW/evOTk5E8++cQ0t7i4eO/evWfOnKHfJ/Y4fvw4Qmj27NkOFMNABs6ePWs0GidOnGgx/fnnnxeJRDU1NaYp1dXVWq02PDxcLpcPGTLk5MmT1tqMjY319vYuLS29du0a/UK2trZanN9obm42GAy+vr6/qtpz585RFBUdHW2jPBuzflVfjqF3BQcOHFi5cmW/C9TV1el0ujfffDMwMFAgEFh8VrNs2bL//M//XLly5apVqzZs2FBVVTVgj87fFA0NDXfu3Hn06JFOp7t3797HH39Mp52iqLVr19bV1R06dMhi52PDgwcPCgsLZTLZ66+/7kg15oMD+8fEISEharVap9Ndu3ZNoVD4+/t3dHRQfQZJ7777LkmSZWVlHR0dtbW1YWFhPj4+XV1dFEUVFBQghJYtW9bS0mIwGDQaTUNDA9Xnc+KMjAwul1tTU9Pb2+vl5UWfZNBqtdevX4+OjhYKhXV1dbarzczMdHd3b2tr0+l0//73v8eMGePn50cfj9ooz8aswRsT038/efLE29t7/vz5prkWY2J66LVu3bre3t6mpqbExESE0I8//khR1NatW+nRKkVRP/30U2hoaEBAAP3SUDYHlIxsCttjYvo/PX1Dzujo6BkzZrS3t1uUYe3Divz8fNMqeHh4dHZ2GgwGo9GoUqnKy8sDAwOHDx9eU1Njz6Zm5rzQrl27YmNjpVIpl8v18vJKTU397rvvKIr68MMP6ZM2QqFw3rx5FEUZjcb8/PzRo0eTJOnp6Tl37tzGxkZTO1u3bg0NDRUIBAKBICwsrKSkpLKykv5/IJfLVSqVRqOh/82LRKI9e/bMmTMnICBAJBLx+fygoKCUlJQBA0BRVGZmJv31GC6X6+HhkZCQcOfOHXqWjfKszeq7jjbYsz0PHjxIf1HC29s7KyuLnrhmzZpLly7Rf7/zzjvDhw9HCLm4uIwZM+arr76iKGrt2rVDhgyRSCRJSUn0+figoKAJEyYQBDFkyBD6uStXrnRxcUEIicXif/zjH6Y7Xvr4+CQlJVmU8fSbori4mK7Tzc1tzpw5JSUlbm5uCKHRo0ffuXOntLSUHrD6+/s3NTWdOXPG/H4LJEmGhIRUVlbW1dVZy8CRI0fGjRvn5ubG4/Ho9aJPBEVFReXm5ra2tg74TqAxk4FnC/3BOytd/y63JyNKSkrMPwb56aefVq5cyefz6ZPCg6pvBvq55u7vT98boQIWPXjwIDs72/yrwTwez8/PT6fT6XQ651988pn//cCtW/nwwFEAACAASURBVLcI61JSUtguEFhydXUlSfLTTz99+PChTqf74Ycfdu7cuX79+pSUFMdO8D+lZz4DCoXCxo4vMDBw165dHR0dAQEBBw4cYLtYgBBCYrH45MmT9fX1wcHBrq6uY8aM2bVr1+bNm3fv3s1KPb/zY6FNmzY58CEaGGzTpk07deoU21X8n2d+PwDAU4IMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYC7fr43qlQqnV/H7xL9e3bYnr8pLS0tlhfFMP+2Pf3bPwB+3yx+S0lQZpf7As5HEERFRUW/l5sFzgHjAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAu37uRwYG1b59+zo7O82nfPnll2q12vQwISFBKpU6vS58wb2YnG3x4sV79uwhSZJ+aDQaCYIgCAIhZDAYhELho0eP+Hw+qzXiBY6FnC01NRUhpPuZwWDQ6/X03xwOJykpCQLgZLAfcDa9Xj9s2LC2trZ+53755ZczZ850ckmYg/2As3G53NTUVNOxkDkvL6+YmBinV4Q7yAALUlNTdTqdxUQej/faa69xOBxWSsIZHAuxgKIomUz2ww8/WEyvrq6OiopipSScwX6ABQRBpKenWxwO+fr6RkZGslUSziAD7LA4HCJJMiMjgz5DCpwMjoVYo1AoGhsbTQ/r6+vHjh3LYj3Ygv0Aa1577TXT4dCYMWMgAGyBDLAmNTVVr9cjhEiSXLx4Mdvl4AuOhdgUERFx/fp1hNDdu3f9/f3ZLgdTsB9gU3p6OkVRUVFREAA2UQypqKhge1UARhITE5l66zL83WlIwq+Vl5f35ptvisViB55bVVVVVFSE4TYvLCxksDWGM5CcnMxsg797YWFho0ePdvjpRUVFGG7z/fv3M9gajAdY9jQBAIyADADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwJ1TMxAZGcnhcCZMmNB3VkFBgVQqJQhi+/btjjWel5cnFosJgvj6669tL/nkyROFQvHOO+841tHgMRqNhYWFU6ZMGYzGGxsbly1bNnbsWHd3dy6XKxaLg4OD4+Pjq6qqBqO73NzcMWPGeHh48Pn8UaNGrVmzpqurCyFUWVkZGBhImOHxeFKpNCYmJj8/v729fTCKsc2pGbh69WpsbGy/s1avXn3p0qWnafyvf/3rjh077FkyJyfH/KImvxHNzc3Tp09ftWpVT08P441/+umnoaGhtbW1W7ZsuX//fnd3940bNzZs2KBWq+vq6hjvDiF05syZrKys//f//t/jx483bdpUVFSUlJSEEJo/f/63334bFBQkFospijIajSqVSqlUBgQErF27duzYsTU1NYNRjw0s3IOD3StJXbp0qb6+nsUC+vXvf/87Nzf3z3/+c3d3N8X0VQ4uX76cmZk5Y8aMEydOcLn/94oHBgYGBgZKJJLm5mZmu6OJRKLMzEz68qnJycmVlZVKpfL+/fu+vr7mixEEIZFIYmJiYmJi4uPjFyxYEB8f39TU5NgP6xzDwnig30suO0dvb+9f/vKXoqIitgqwZvz48ZWVlWlpaYNx84GNGzcaDIa8vDxTAEzi4uKysrIY7xEh9MUXX5hfP9jb2xshZHsXl5iYmJGRoVKpHD4edgwLGbh9+7ZCoRAKha6urtOmTbtw4UK/i1EUtWXLlpCQED6f7+npmZCQcOvWLdPcsrKyiIgIgUAgFArlcvmGDRssnv7w4UO5XM7lcmfNmmWamJOT89Zbbw0dOtT+avvtyFptH3/8sVAodHNzO3z48OzZsz08PGQy2b59+xBCISEhBEG4uLiEh4fTb4U1a9aIxWKBQPDZZ5/ZX8+vpdVqT58+7eXlZftqvoO9Rt9//72rq2tAQIDtajMyMhBCx44dc3yFHcDUj/PpX3YPuNjMmTMDAwPv3r2r0+nq6+snTZokEAiampooiqJ3ytu2baOXXL9+PY/HKysrU6vVtbW1EydO9Pb2fvDgAUVR9E+q8/LyWltb29raduzYkZaWRlEU/drcuHGDoiitVjt//vzDhw+bur5w4cKcOXMoinr06BFCKCcnZ8BqrXVko7acnByE0OnTpzs6OlQq1bRp04RCoVar1ev1crncz89Pr9eb2l+5cmVhYaF5j5MmTRo/fvyAhdHs2eZNTU0IoejoaNuLDd4aURTV3d3t7u6enZ1tmmIaD1jQaDQIIV9fX9vVJiYmMnhdCRYyYP4a19bWIoRWr15N/TIDPT09IpEoJSXFtOSVK1cQQrm5uVqtViKRxMbGmmbp9fqioiLKLAM6nS41NfXYsWOmZXp6eiIiIlpaWii7M2CtIxu1UT+/Y3p7e+lZJSUlCKHbt29TPydKqVTSs7q7u/38/Do6Osw7ZTwD9BDzxRdftLHMoK4R3UJwcLBGozFNsZYBiqLoEYLtlWI2Ayx/PhAaGioWi+kkmGtoaOjq6oqIiDBNiYyM5PF41dXVtbW1arU6Li7ONIvD4Sxfvtz00GAwLFy4UCqVmh8F/e1vf1u6dOnIkSPtr81aRzZq69sIj8dDCNGXmF6yZIlYLDaNRvbu3ZuQkODh4WF/SQ4QiURooAPxQV2jgwcPKpXKEydOuLu7D1gtfUpgsLeJBfY/IyNJsu9NWeh7ldKvn4lEIuns7KR3lxKJxFqDWVlZzc3N27dvv3nzJj3lwoULdXV1S5Ys+VWFWevIRm22GxSJREuXLr106RL9X3bbtm3Z2dm/qiQHyOVy+mjTxjKDt0bl5eWbN28+d+6cXC63p1q6ToVCYc/CTGE5A3q9vq2tzc/Pz2I6/c6zeA3UarVMJhsxYgRC6PHjx9baTE5OPnXqlEQiSU9Ppy9q++mnn54+fdrFxYX+UIYeE7///vsEQdg4G22tIxu1Dbi+2dnZJEkWFhaeP3/e19c3KChowKc8JT6fHxcX9/jx44sXL/ad29bWtmTJkkFao+Li4r179545c4bekvY4fvw4Qmj27Nl2Ls8IljNw9uxZo9E4ceJEi+nPP/+8SCQyf4NWV1drtdrw8HC5XD5kyJCTJ09aazM2Ntbb27u0tPTatWsbN25ECO3atcv8+M98PGB+AGDBWkc2ahtwfWUyWXJy8oEDB9atW7dixYoBl2fEe++9x+fzV61a1dvbazGrvr6ey+UyvkYURa1du7auru7QoUMWuxcbHjx4UFhYKJPJXn/9dTufwggWMqDVajs6OvR6/fXr17Ozs/39/ekzYuYEAsHbb7998ODBvXv3ajSaurq6P//5zz4+PpmZmXw+/29/+9v58+ezs7O///57o9HY2dlpOuwxmTNnTkZGxvvvv3/t2jXH6rTWkY3a7Gn27bff1uv17e3tL7zwgmOF/VoTJkz4n//5n/r6+mnTpv3zn//s6OjQ6XR379795JNP3njjDZIkGV+jmzdv/v3vf//kk09IkjT/WkRBQYHpWRRFdXV1GY1G+r9SRUXF1KlTORzOoUOHnDwecPZ5oV27dsXGxkqlUi6X6+XllZqa+t1331EU9eGHHw4bNgwhJBQK582bR1GU0WjMz88fPXo0SZKenp5z585tbGw0tbN169bQ0FCBQCAQCMLCwkpKSiorKz09PRFCcrlcpVJpNBr6I0mRSLRnzx5r+4EB9e3IRm0lJSVubm4IodGjR9+5c6e0tJR+Of39/enzv7TY2NidO3ea91JVVTV16lQfHx/6RRk+fPiUKVP+9a9/2a7Nzm1Ou3fv3urVq0NDQ0UiEYfDkUgkYWFhb7zxxsWLFxlfI2vfv8jPzz9y5Mi4cePc3Nx4PJ6Liwv6+aPiqKio3Nzc1tZWe9aF2fNCjN1/QKlULliwgKnWgD2w3eb0V4+Yuuoo++eFAGAX1hm4desWYV1KSgrbBQJnYOF7o78dCoUCwwMJYAHr/QAACDIAAGQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANwx/N1pdq+niyc8t3liYiJTTTH2W8qWlpanvHg6nhYsWLBixYrJkyezXcgzxtfXl6mNxlgGgGMIgqioqEhOTma7EHzBeADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHcP3YgIDUqvVFvc96e7ubm9vNz0UiUQkSTq9LnzBfWicLTY29ty5c9bmcjiclpaW4cOHO7Ei3MGxkLOlpqZau4uei4vL9OnTIQBOBhlwtqSkJA6H0+8sgiDS09OdXA+ADDibp6fnyy+/3G8MXFxcEhISnF8S5iADLFi0aJHRaLSYyOVyX3nlFYlEwkpJOIMMsOCPf/wjn8+3mGg0GhctWsRKPZiDDLDAzc0tISHB4gQon8+Pj49nqyScQQbYkZaWptPpTA9JkkxKSnJ1dWWxJGxBBtgRFxfn4eFheqjT6RYuXMhiPTiDDLCDJMnU1FQej0c/lEgkM2fOZLckbEEGWJOamqrVahFCJEmmpaVxufC9FXbAdyVYYzQaR4wY8fDhQ4TQV1999Yc//IHtijAF+wHWuLi40CdDfXx8pk6dynY5+GJs/1tVVbVlyxamWsME/XVRDw+P5ORktmt5xkyePHnVqlWMNMXYfuD+/fsHDhxgqjVMeHp6enh4+Pn5Ofb0lpYWPLf55cuXq6qqmGqN4XHY/v37mW3wd0+pVDq8E1AqlQsWLMBwmyclJTHYGowHWAZHQayDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwJ1TMxAZGcnhcCZMmNB3VkFBgVQqJQhi+/btjjWel5cnFosJgvj6669tL/nkyROFQvHOO+841tFgyM3NHTNmjIeHB5/PHzVq1Jo1a7q6upjtorGxcdmyZWPHjnV3d+dyuWKxODg4OD4+nsEv4puztkaVlZWBgYGEGR6PJ5VKY2Ji8vPzza9B7zwUQyoqKuxpbebMmePHj+93VnNzM0Jo27ZtDtewb98+hNCNGzdsL0b//ignJ8fhjhg3Y8aMkpKS1tZWjUZTUVFBkuSsWbMGfJad25yiqJ07d5IkOX369OPHj7e3tz958uTOnTvl5eVTpkzZsWPHU5ffD9trFBQUJBaLKYoyGo3t7e1nz57NyMggCMLHx+fq1asDNp6YmJiYmMhUqSxcy8Dalced49KlS/X19SwW0C+RSJSZmUlfiDc5ObmyslKpVN6/f9/X1/fpG798+XJmZuaMGTNOnDhhunpFYGBgYGCgRCKh//Uwzs41IghCIpHExMTExMTEx8cvWLAgPj6+qalJLBYPRlX9YmE8wOJNVnp7e//yl78UFRWxVYA1X3zxhfmVqL29vRFCPT09jDS+ceNGg8GQl5fX9/ItcXFxWVlZjPRiwYE1SkxMzMjIUKlUDh8PO4aFDNy+fVuhUAiFQldX12nTpl24cKHfxSiK2rJlS0hICJ/P9/T0TEhIuHXrlmluWVlZRESEQCAQCoVyuXzDhg0WT3/48KFcLudyubNmzTJNzMnJeeutt4YOHWp/tf12ZK22jz/+WCgUurm5HT58ePbs2R4eHjKZjD5CCwkJIQjCxcUlPDycfiusWbNGLBYLBILPPvvMotPvv//e1dU1ICDA/jqt0Wq1p0+f9vLyioqKsrHYb2SNMjIyEELHjh1zfIUdwNRBlf3jgcDAwLt37+p0uvr6+kmTJgkEgqamJqrPeGD9+vU8Hq+srEytVtfW1k6cONHb2/vBgwcURRUWFiKE8vLyWltb29raduzYkZaWRv1yPKDVaufPn3/48GFT1xcuXJgzZw5FUY8ePUL2jQesdWSjtpycHITQ6dOnOzo6VCrVtGnThEKhVqvV6/VyudzPz0+v15vaX7lyZWFhoUWn3d3d7u7u2dnZA5ZnzzZvampCCEVHR9tezMlrZBoPWNBoNAghX19f29UyOx5geUxcW1uLEFq9ejX1ywz09PSIRKKUlBTTkleuXEEI5ebmarVaiUQSGxtrmqXX64uKiiizDOh0utTU1GPHjpmW6enpiYiIaGlpoezOgLWObNRG/fyO6e3tpWeVlJQghG7fvk39nCilUknP6u7u9vPz6+josOg3JycnODhYo9EMuDHt2eY1NTUIoRdffNHGMs5fI2sZoCiKHiHYXilmM8Dy5wOhoaFisZhOgrmGhoaurq6IiAjTlMjISB6PV11dXVtbq1ar4+LiTLM4HM7y5ctNDw0Gw8KFC6VSqflR0N/+9relS5eOHDnS/tqsdWSjtr6N0FcUpS8xvWTJErFYbBqN7N27NyEhwfzKuwihgwcPKpXKEydOuLu721+qDSKRCA10IP7bWaPu7m6KoixaGGzsf0ZGkqT5VchparUa/fz6mUgkks7OTnp3aeN+LVlZWc3Nzdu3b7958yY95cKFC3V1dUuWLPlVhVnryEZtthsUiURLly69dOkS/V9227Zt2dnZ5guUl5dv3rz53Llzcrn8V5Vqg1wup482bSzz21kjuk6FQmHPwkxhOQN6vb6tra3vRabod57Fa6BWq2Uy2YgRIxBCjx8/ttZmcnLyqVOnJBJJenq6Xq9HCH366aenT592cXGhP5Shx8Tvv/8+QRD0oUK/rHVko7YB1zc7O5skycLCwvPnz/v6+gYFBZlmFRcX792798yZM3S/TOHz+XFxcY8fP7548WLfuW1tbUuWLPntrNHx48cRQrNnz7ZzeUawnIGzZ88ajcaJEydaTH/++edFIpH5G7S6ulqr1YaHh8vl8iFDhpw8edJam7Gxsd7e3qWlpdeuXdu4cSNCaNeuXebHf+bjAfMDAAvWOrJR24DrK5PJkpOTDxw4sG7duhUrVtATKYpau3ZtXV3doUOHLP4ZM+K9997j8/mrVq3q7e21mFVfX8/lcn8ja/TgwYPCwkKZTPb666/b+RRmMDWwsH9MHBISolardTrdtWvXFAqFv78/PYqyOC/07rvvkiRZVlbW0dFRW1sbFhbm4+PT1dVFUVRBQQFCaNmyZS0tLQaDQaPRNDQ0UH0+J87IyOByuTU1NRY12H9eyFpHNmqzGEF+8sknCKFvvvnG1Ob169cRQqGhoaYp1j6zy8/Pt12e/Z8THzhwwM3NLTw8/OjRo2q1WqvVfvvtt6WlpaNGjcrKynL+GgUFBXl4eHR2dhoMBqPRqFKpysvLAwMDhw8f3vf16uvZPi+0a9eu2NhYqVTK5XK9vLxSU1O/++47iqI+/PDDYcOGIYSEQuG8efMoijIajfn5+aNHjyZJ0tPTc+7cuY2NjaZ2tm7dGhoaKhAIBAJBWFhYSUlJZWWlp6cnQkgul6tUKo1GQ38kKRKJ9uzZY16D/RnotyMbtZWUlLi5uSGERo8efefOndLSUnp45+/vT5//pcXGxu7cudP0sK6ubrAzQFHUvXv3Vq9eHRoaKhKJOByORCIJCwt74403Ll686Mw1OnLkyLhx49zc3Hg8nouLC/r5o+KoqKjc3NzW1lZ71oXZDDB2/wH62pdMtQbsge02p683ytSFVtk/LwQAu7DOwK1btwjrUlJS2C4QOAPW98BSKBQYHkgAC1jvBwBAkAEAIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4I7h707TP/ABztHS0oKw3OaXL1+Ojo5mqjXG9gO+vr6JiYlMtYaP8+fP079vdoBMJsNzm0dHR0+ePJmp1hj7PTFwDEEQFRUVycnJbBeCLxgPANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcwX1onC0zM7OxsdH08OLFi88995y3tzf9kMPh7N69WyaTsVQdjhi+Jx8YkFQqLS0tNZ/S0NBg+jsgIAAC4GRwLORsaWlp1mbxeLyMjAwn1gIQgmMhVowdO/abb77pd8s3NjYGBwc7vyScwX6ABenp6RwOx2IiQRDjxo2DADgfZIAFCxcuNBgMFhO5XO7ixYtZqQdzcCzEjujo6KtXrxqNRtMUgiDu378/cuRIFqvCE+wH2JGenk4QhOmhi4vL1KlTIQCsgAyww+LG9ARBpKens1UM5iAD7PD29p45c6b5yHjevHks1oMzyABrFi1aRA/GOBzOrFmzvLy82K4IU5AB1iQkJJAkiRCiKGrRokVsl4MvyABr3N3dX331VYQQj8ej/wCsYOz7Qi0tLZcuXWKqNUzI5XKE0MSJE48ePcp2Lc8YX1/fyZMnM9MWxZCKigpmCgLADomJiUy9dRk+FmKqLHy8/fbbP/30k2PPpf/vMFvPMyExMZHBNy2MB1i2YcMGHo/HdhVYgwywzNXVle0ScAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3Ts1AZGQkh8OZMGFC31kFBQVSqZQgiO3btzvWeF5enlgsJgji66+/tr3kkydPFArFO++841hHg+GDDz5QKBSurq5CoVChUKxbt06j0TDbRWNj47Jly8aOHevu7s7lcsVicXBwcHx8fFVVFbMd0XJzc8eMGePh4cHn80eNGrVmzZquri6EUGVlZWBgIGGGx+NJpdKYmJj8/Pz29vbBKGYATH2l287vss+cOXP8+PH9zmpubkYIbdu2zeEa9u3bhxC6ceOG7cVWrVqFEMrJyXG4I8bFx8cXFBSoVKrOzk6lUkmS5EsvvTTgs+z//cDOnTtJkpw+ffrx48fb29ufPHly586d8vLyKVOm7Nix46nL78eMGTNKSkpaW1s1Gk1FRQVJkrNmzTLNDQoKEovFFEUZjcb29vazZ89mZGQQBOHj43P16tUBG09MTGTwNzQsXHvd/NpSznfp0qX6+noWC+gXj8d76623BAIBQigpKWn//v379+//8ccffXx8nr7xy5cvZ2Zmzpgx48SJE1zu/73igYGBgYGBEomE/tfDOJFIlJmZSV88Jjk5ubKyUqlU3r9/39fX13wxgiAkEklMTExMTEx8fPyCBQvi4+ObmprEYvFgVNUvFsYD/x97dx7WxLX/D/wMWUlCEgQjaIAASgHFiiyl9lqh9ilab1tUQFCLfFsr/XkR1+rTa7VesGIvCrSKC7WXVnwqIPiIV69bXb4uUBRsL4uyaG2RWowsYdds8/tjvs2TBhIihox6Pq+/yMzknM9M8mbmTJIZ6mIKtOjr6/voo48yMzPpKsCYw4cPUwGgUBecow4entzmzZs1Gk1qaqouADrh4eGJiYkW6cXAsWPH9K+eRN1kpLe318RTIiMj4+Pj5XL5kI+Hh4aGDNy6dcvb25vP59va2k6dOvXy5csDLkaSZHp6uo+PD4fDsbe3j4iIqK2t1c3Nzc0NDAzkcrl8Pl8mk6WkpBg8/f79+zKZjMlkzpgxQzdx/fr1f/vb30aOHGl+tQN2ZKy2Xbt28fl8Ho9XXFw8c+ZMoVAolUqpIzQfHx+CIGxsbAICAqi3wtq1a0UiEZfL/eabbww6bWhoEIvFbm5u5tdpjFKpPHv2rIODQ3BwsInFhnuNfvvtN1tbW3d3d9PVUrdfOHHixNBXeAgsdVBl/njAw8Pjzp07KpWqurr6pZde4nK59fX1ZL/xwMaNG9lsdm5urkKhqKysnDx5sqOjY3NzM0mSGRkZCKHU1NTW1ta2tra9e/cuWLCA/PN4QKlUzp07t7i4WNf15cuX3377bZIkHzx4gMwbDxjryERt69evRwidPXu2o6NDLpdPnTqVz+crlUq1Wi2TyVxdXdVqta79lStXZmRk6B4qlcqmpqYdO3ZwOJzc3FyLbPP6+nqEUEhIiOnFhmmNKD09PXZ2dklJSbopuvGAAepMgIuLi+lqLTseoHlMXFlZiRBas2YN+ecM9Pb2CgSCmJgY3ZJXr15FCCUnJyuVSrFYHBYWppulVqszMzNJvQyoVKrY2NgTJ07olunt7Q0MDGxqaiLNzoCxjkzURv7xjunr66NmZWVlIYRu3bpF/pGogoICalZPT4+rq2tHR4eunVGjRiGEHBwcvvjiC6VSOejGNGebl5eXI4Ref/11E8sM3xpR1q9f7+Xl1dnZqZtiLAMkSVIjBNMrZdkM0Pz5gJ+fn0gkopKgr6ampru7OzAwUDclKCiIzWaXlZVVVlYqFIrw8HDdLAaDsXz5ct1DjUYzf/58iUSifxT097//fcmSJY91YWdjHZmorX8j1O/lVSoVQmjx4sUikUg3Gjlw4EBERIRQKNQtfPfuXblc/t1333377bf+/v5yudz8ao0RCARosAPx4VsjhNDhw4cLCgpOnTplZ2c3aLU9PT0kSRq0MNzo/4yMxWJRG1SfQqFAf7x+OmKxuKuri9pdisViYw0mJiY2NDTs2bPnxo0b1JTLly9XVVUtXrz4sQoz1pGJ2kw3KBAIlixZUlJSQv2X3b17d1JSkv4CLBZr5MiRb7zxRl5eXk1NzZYtWx6r4AHJZDLqaNPEMsO3Rnl5eVu3br1w4QJ1NbFBUXV6e3ubs7Cl0JwBtVrd1tbm6upqMJ165xm8BgqFQiqVjh49GiHU0tJirM3o6OgzZ86IxeK4uDi1Wo0Q+vrrr8+eXIaM6AAAIABJREFUPWtjY0N9KEONiT/77DOCIKhDhQEZ68hEbYOub1JSEovFysjIuHjxoouLi6en54CLjR07lsFg6N+vcsg4HE54eHhLS8uVK1f6z21ra1u8ePEwrdGOHTsOHDhw7tw5akua4+TJkwihmTNnmrm8RdCcgfPnz2u12smTJxtMnzBhgkAg0H+DlpWVKZXKgIAAmUw2YsSI06dPG2szLCzM0dExOzu7oqJi8+bNCKGcnBz94z/98YD+AYABYx2ZqG3Q9ZVKpdHR0YWFhRs2bFixYgU1sbW1df78+fqLNTQ0aDQag1PpQ7Zp0yYOh7Nq1aq+vj6DWdXV1Uwm0+JrRJLkunXrqqqqjhw5YrB7MaG5uTkjI0Mqlb733ntmPsUyLDWwMH9M7OPjo1AoVCpVRUWFt7e3m5sbNYoyOC/06aefslis3Nzcjo6OyspKf39/Z2fn7u5ukiS3bduGEFq2bFlTU5NGo+ns7KypqSH7fU4cHx/PZDLLy8sNajD/vJCxjkzUZjCC/OqrrxBC1F0oKdevX0cI+fn56ab09fU5ODhQJ16USuX169dDQkL4fH5VVZXp8sz/nLiwsJDH4wUEBBw/flyhUCiVyp9//jk7O3vs2LGJiYkWXyNjn0KmpaVRC3h6egqFwq6uLo1Go9Vq5XJ5Xl6eh4eHk5NT/9erv2f7vFBOTk5YWJhEImEymQ4ODrGxsb/++itJktu3b6fOivD5/Dlz5pAkqdVq09LSxo0bx2Kx7O3tZ8+eXVdXp2tn586dfn5+XC6Xy+X6+/tnZWUVFRXZ29sjhGQymVwu7+zspP6PCgSC/fv369dgfgYG7MhEbVlZWTweDyE0bty427dvZ2dnU8M7Nzc36vwvJSwsbN++ffq9vP322+7u7gKBgMPheHp6xsTEDBoA8jGvtdjY2LhmzRo/Pz+BQMBgMMRisb+///vvv3/lyhWLr1FVVZWxDBw9enTixIk8Ho/NZtvY2KA/PioODg5OTk5ubW01Z10smwGL3ZOvoKBg3rx5lmoNmAPbbR4VFYUQOnTokEVao/+8EAD0wjoDtbW1hHExMTF0FwisgYbvjT49vL29MTyQAAaw3g8AgCADAEAGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMCdhb87XVBQYNkGgQnUZdMx3OZNTU3mXPPCXJb6USb121YArONp/D0xGBqCIPLz86Ojo+kuBF8wHgC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuLPw/cjAoA4ePNjV1aU/5fvvv1coFLqHEREREonE6nXhC+7FZG2LFi3av38/i8WiHmq1WoIgCIJACGk0Gj6f/+DBAw6HQ2uNeIFjIWuLjY1FCKn+oNFo1Go19TeDwYiKioIAWBnsB6xNrVaPGjWqra1twLnff//99OnTrVwS5mA/YG1MJjM2NlZ3LKTPwcEhNDTU6hXhDjJAg9jYWJVKZTCRzWa/++67DAaDlpJwBsdCNCBJUiqV3rt3z2B6WVlZcHAwLSXhDPYDNCAIIi4uzuBwyMXFJSgoiK6ScAYZoIfB4RCLxYqPj6fOkAIrg2Mh2nh7e9fV1ekeVldXjx8/nsZ6sAX7Adq8++67usMhX19fCABdIAO0iY2NVavVCCEWi7Vo0SK6y8EXHAvRKTAw8Pr16wihO3fuuLm50V0OpmA/QKe4uDiSJIODgyEAdCL15Ofn010OAMMuMjJS/20/wHenIQmWUlpampmZaXp7pqamLl26VCQSWa0qzGVkZBhMGSAD0dHRVikGC5mZmaa3p7+//7hx46xWDzh06JDBFBgP0AwCQDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3D12BoKCghgMxqRJk/rP2rZtm0QiIQhiz549Q6smNTVVJBIRBPHTTz+ZXvLhw4fe3t6ffPLJ0DoasidfRwNFRUUeHh7Upac3bNgw4DLp6ekEQdjY2Hh7e1+8ePEJeyEIgsVijRkzZsGCBTdv3hxy5f03xX/+8x+RSPTvf/97yG0ihJKTk319fYVCIYfDGTt27Nq1a7u7u/uvAkEQbDZbIpGEhoampaW1t7cPvcv+vyMjBzN9+vQXX3xxwFkNDQ0Iod27dw/aiDEHDx5ECP3444+mF1u1ahVCaP369UPuaMjMX0cztydJkp6engghJycnpVJpMEutVlO/tJw+ffpQyv1zLyKRiCTJ7u7uo0ePurq6CgSC2traITdosCmOHTsmFAqPHj36JEVOmzYtKyurtbW1s7MzPz+fxWLNmDGj/ypotdr29vbz589T12Vydna+du2aOe1HRkYa/I5siMdC9F4NqqSkpLq6msYChkNAQEBzc/ORI0cMphcVFY0ZM8ayffH5/LfeeuuLL77o7u7esWOHpZqdNWtWR0fHW2+99SSNCASChISEESNG2NnZRUdHz549++TJk3fv3jVYjCAIsVgcGhqak5NTUFBw//59qvch9DjEDAx42WTr6Ovr++ijjzIzM+kqYJgsXboUIbR7926D6enp6atXrx6OHqlrmz4N/01Ikjx06FB2djZC6NixY/oXHnZ0dEQI9fb2mnh6ZGRkfHy8XC4f2gHqEDNw69Ytb29vPp9va2s7derUy5cvD7gYSZLp6ek+Pj4cDsfe3j4iIqK2tlY3Nzc3NzAwkMvl8vl8mUyWkpJi8PT79+/LZDImkzljxgzdxPXr1//tb38bOXKkOXV++eWXXC5XIpF8+OGHzs7OXC53ypQpZWVlg5ZnuvLh8Nprr/n4+Jw/f17/4nNXrlzp7e194403DBa+dOmSr6+vSCTicrl+fn6nTp1CCH3zzTcCgYAgCHt7+yNHjpSXl7u5uTEYjPnz5w/YI3V1I+qWH0++KS5fvuzq6koQxM6dOxFCu3bt4vP5PB6vuLh45syZQqFQKpVSB7oIIY1Gs2XLlhdeeMHW1tbR0dHd3X3Lli0D/uj0t99+s7W1dXd3N7314uPjEUInTpwwvdjA9A+MzB8PeHh43LlzR6VSVVdXv/TSS1wut76+nux3gLhx40Y2m52bm6tQKCorKydPnuzo6Njc3EySJPXT5tTU1NbW1ra2tr179y5YsID883hAqVTOnTu3uLhY1/Xly5fffvttkiQfPHiAzBsPJCQk8Pn8GzduPHz4sKamJigoyM7OrrGx0XR5JmYN03jgzp07X3zxBUJoxYoVuumzZ8/Oycmh7l+mPx44dOjQpk2b2traWltbQ0JCHBwcqOk3btzg8XiLFi2iHn788cf79u3T74U6mKbk5uYihD766CNLbQrqiGXHjh3Uw/Xr1yOEzp4929HRIZfLp06dyufzqQHPZ599xmAwiouLe3t7KyoqRo0aFRoa2n+z9PT02NnZJSUlGVsFnc7OToSQi4vLoJu6/3jAAmPiyspKhNCaNWvIP2+U3t5egUAQExOjW/Lq1asIoeTkZKVSKRaLw8LCdLPUanVmZiaplwGVShUbG3vixAndMr29vYGBgU1NTeRjZkB/q127dg0h9I9//MNEeSZmkcOZAYVCwefz7e3te3t7SZK8ffu2VCp99OhR/wzo27JlC0JILpdTD/fu3YsQOnDgwHfffbdq1SqDXnRj4sLCwlGjRkkkkqamJkttigEz0NfXRz3MyspCCN26dYskyaCgoODgYF2bS5YssbGxefTokcGqrV+/3svLq7Ozs/8q9EeNEAacpc9iY2J9fn5+IpGISoK+mpqa7u7uwMBA3ZSgoCA2m11WVlZZWalQKMLDw3WzGAzG8uXLdQ81Gs38+fMlEon+UdDf//73JUuWPOEAMTAwkMfj1dbWmijPxKwn6XpQIpFo/vz57e3teXl5CKGMjIylS5ey2WzTz6LGZhqNhnq4ZMmSyMjIDz/8sKCg4J///KfBwh0dHQRBiESi5cuXv/nmm1evXh0zZox1NgW1ItTVth8+fEjqXeBQo9GwWCyD+48cPny4oKDg1KlTdnZ2gzbe09NDkqRQKHzcqpClPiNjsVj9b6xC3W9UIBDoTxSLxV1dXdSeSywWG2swMTGxoaFhz549N27coKZcvny5qqpq8eLFT14th8N58OCBifJMzHry3k2jRsZ79uxRKBSHDh368MMPB1zs+PHjoaGhI0eO5HA4a9euNZj72WefdXd3y+Xy/k+k/omq1eqmpqZ//etf1FlX62+KN998s6Kiori4uK+vr7y8/MiRI3/961/1M5CXl7d169YLFy7IZDJzGqyvr0cIeXt7D6EYC2RArVa3tbW5uroaTKfe4gYbS6FQSKXS0aNHI4RaWlqMtRkdHX3mzBmxWBwXF0cN3b7++uuzZ8/a2NhQn49QY+LPPvuMIIjy8nLzq1WpVFQNJsozMcv8joZm0qRJISEhV69eTUhIiIqKsre3779MY2Pj7NmznZycysrKOjo6Pv/8c/25KpVq+fLl6enppaWlmzdvNqdT62+KTZs2vfbaa/Hx8UKhcM6cOdHR0V999ZVu7o4dOw4cOHDu3DnqfWKOkydPIoRmzpw5hGIskIHz589rtdrJkycbTJ8wYYJAINB/g5aVlSmVyoCAAJlMNmLEiNOnTxtrMywszNHRMTs7u6Kignohc3Jy9I/h9McD+nvqQV24cIEkyZCQEBPlmZhlfkdDRu0KCgsLV65cOeACVVVVKpVq6dKlHh4eXC7X4LOaZcuWffDBBytXrly1alVKSkppaemgPVp/U9TU1Ny+ffvBgwcqlaqxsXHXrl1U2kmSXLduXVVV1ZEjRwx2PiY0NzdnZGRIpdL33ntvKNXov7HMHxP7+PgoFAqVSlVRUeHt7e3m5tbR0UH2GyR9+umnLBYrNze3o6OjsrLS39/f2dm5u7ubJMlt27YhhJYtW9bU1KTRaDo7O2tqash+nxPHx8czmczy8nKDGh5rTGxnZ9fW1qZSqf773//6+vq6urpSx6MmyjMxa/jGxNTfDx8+dHR0nDt3rm6uwZiYGnpt2LChr6+vvr4+MjISIfT777+TJLlz505qtEqS5KNHj/z8/Nzd3amXhjQ5oLTIpjA9Jqb+09+8eZMkyZCQkGnTprW3txuUYezDirS0NN0qCIXCrq4ujUaj1WrlcnleXp6Hh4eTk1P/N8mALHNeKCcnJywsTCKRMJlMBweH2NjYX3/9lSTJ7du3jxo1CiHE5/PnzJlDkqRWq01LSxs3bhyLxbK3t589e3ZdXZ2unZ07d/r5+XG5XC6X6+/vn5WVVVRURP0/kMlkcrm8s7PTxcUFISQQCPbv369fw2NlgPp6DJPJFAqFERERt2/fpmaZKM/YrP7raII52/Pw4cPUFyUcHR0TExOpiWvXri0pKaH+/uSTT5ycnBBCNjY2vr6+ly5dIkly3bp1I0aMEIvFUVFR1Pl4T0/PSZMmEQQxYsQI6rkrV660sbFBCIlEoi+//NLLy4t6Pzk7O0dFRRmU8eSbYseOHVSdPB7v7bffzsrK4vF4CKFx48bdvn07OzubGrC6ubnV19efO3fOwcFB9xZnsVg+Pj5FRUVVVVXGMnD06NGJEyfyeDw2m02tF3UiKDg4ODk5ubW1ddB3AsUyGXi2UB+809L1c7k9LSIrK0v/Y5BHjx6tXLmSw+FQJ4WHVf8MDHDN3eeP7rwheBo0NzcnJSXpfzWYzWa7urqqVCqVSmVra2vlep753w/U1tYSxsXExNBdIDBka2vLYrG+/vrr+/fvq1Sqe/fu7du3b+PGjTExMUM7wf+EnvkMeHt7m9jxeXh45OTkdHR0uLu7FxYW0l0sQAghkUh0+vTp6upqLy8vW1tbX1/fnJycrVu3fvvtt7TU85wfC23ZsoX6KgF4qkydOvXMmTN0V/F/nvn9AABPCDIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4G+N4ovdfTff7A9nzaUL/A1iFIvUsdNTU1lZSUWL0krM2bN2/FihUvv/wy3YVgxMXFRX+D/ykDwPoIgsjPzx/wcrPAOmA8AHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOBugHsxgWGlUCgM7nvS09PT3t6ueygQCFgsltXrwhfch8bawsLCLly4YGwug8FoampycnKyYkW4g2Mha4uNjTV2lz4bG5tXX30VAmBlkAFri4qKYjAYA84iCCIuLs7K9QDIgLXZ29u/8cYbA8bAxsYmIiLC+iVhDjJAg4ULF2q1WoOJTCbzzTffFIvFtJSEM8gADd555x0Oh2MwUavVLly4kJZ6MAcZoAGPx4uIiDA4AcrhcGbNmkVXSTiDDNBjwYIFKpVK95DFYkVFRdna2tJYErYgA/QIDw8XCoW6hyqVav78+TTWgzPIAD1YLFZsbCybzaYeisXi6dOn01sStiADtImNjVUqlQghFou1YMECJhO+t0IP+K4EbbRa7ejRo+/fv48QunTp0l/+8he6K8IU7AdoY2NjQ50MdXZ2fuWVV+guB18W2/+Wlpamp6dbqjVMUF8XFQqF0dHRdNfyjHn55ZdXrVplkaYsth+4e/duYWGhpVrDhL29vVAodHV1HdrTm5qa8NzmP/zwQ2lpqaVas/A47NChQ5Zt8LlXUFAw5J1AQUHBvHnzMNzmUVFRFmwNxgM0g6Mg2kEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgzqoZCAoKYjAYkyZN6j9r27ZtEomEIIg9e/YMrfHU1FSRSEQQxE8//dR/7ubNm4k/mzBhwtA6Gj5arTYjI2PKlCnD0XhdXd2yZcvGjx9vZ2fHZDJFIpGXl9esWbMs+EV8fcnJyb6+vkKhkMPhjB07du3atd3d3QihoqIiDw8P/ReCzWZLJJLQ0NC0tDT9a9BbjVUzcO3atbCwsAFnrVmzpqSk5Eka//jjj/fu3fskLdCroaHh1VdfXbVqVW9vr8Ub//rrr/38/CorK9PT0+/evdvT0/Pjjz+mpKQoFIqqqiqLd4cQOnfuXGJi4i+//NLS0rJly5bMzEzqS/9z5879+eefPT09RSIRSZJarVYulxcUFLi7u69bt278+PHl5eXDUY8JNFzLwNiVx4dbbm7uU3sxw//+97/Jycn/7//9v56eHotf5eCHH35ISEiYNm3aqVOndFev8PDw8PDwEIvFDQ0Nlu2OIhAIEhISqEsLR0dHFxUVFRQU3L1718XFRX8xgiDEYnFoaGhoaOisWbPmzZs3a9as+vp6kUg0HFUNiIbxANxkpb8XX3yxqKhowYIF/a9D+uQ2b96s0WhSU1P7X74lPDw8MTHR4j0ihI4dO6Z/bW1HR0eEkOldXGRkZHx8vFwuH/Lx8NDQkIFbt255e3vz+XxbW9upU6devnx5wMVIkkxPT/fx8eFwOPb29hEREbW1tbq5ubm5gYGBXC6Xz+fLZLKUlBSDp9+/f18mkzGZzBkzZjxJtQN2ZKy2Xbt28fl8Ho9XXFw8c+ZMoVAolUoPHjyIEPLx8SEIwsbGJiAggHorrF27ViQScbncb7755kkqNE2pVJ49e9bBwSE4ONjEYsO9Rr/99putra27u7vpauPj4xFCJ06cGPoKDwFpIfn5+ea0Nn36dA8Pjzt37qhUqurq6pdeeonL5dbX15MkSe2Ud+/eTS25ceNGNpudm5urUCgqKysnT57s6OjY3NxMkmRGRgZCKDU1tbW1ta2tbe/evQsWLCBJknptfvzxR5IklUrl3Llzi4uLqdZSUlKkUqlYLGaxWDKZ7J133rl69eqg1RrryERt69evRwidPXu2o6NDLpdPnTqVz+crlUq1Wi2TyVxdXdVqta79lStXZmRk6Pf40ksvvfjii2ZtcfO2eX19PUIoJCTE9GLDt0YkSfb09NjZ2SUlJemm6MYDBjo7OxFCLi4upquNjIyMjIw0vYz5aMiA/mtcWVmJEFqzZg355wz09vYKBIKYmBjdklevXkUIJScnK5VKsVgcFhamm6VWqzMzM0m9DKhUqtjY2BMnTuiWaWxsvH79eldX16NHj0pLS/39/W1tbaurq02UaqwjE7WRf7xj+vr6qFlZWVkIoVu3bpF/JKqgoICa1dPT4+rq2tHRod+pxTNADTFff/11E8sM6xpRLXh5eXV2duqmGMsASZLUCMH0Slk2AzR/PuDn5ycSiagk6Kupqenu7g4MDNRNCQoKYrPZZWVllZWVCoUiPDxcN4vBYCxfvlz3UKPRzJ8/XyKR6B8Fubi4+Pv7CwQCNpsdEhKSk5PT19dHvZzGGOvIRG39G6GuKEpdYnrx4sUikSgzM5OadeDAgYiICP0r7w4HgUCABjsQH9Y1Onz4cEFBwalTp+zs7AatljolMNzbxAD9n5GxWCz9q5BTFAoF+uP10xGLxV1dXdTu0sT9WhITExsaGvbs2XPjxg1jy/j5+TEYDOo4wRhjHZmozURr1FOWLFlSUlJC/ZfdvXt3UlKS6ac8OZlMRh1tmlhm+NYoLy9v69atFy5ckMlk5lRL1ent7W3OwpZCcwbUanVbW1v/i0xR7zyD10ChUEil0tGjRyOEWlpajLUZHR195swZsVgcFxenVqsHXEar1Wq1WtMnYYx1ZKI2E61RkpKSWCxWRkbGxYsXXVxcPD09B33KE+JwOOHh4S0tLVeuXOk/t62tbfHixcO0Rjt27Dhw4MC5c+eoLWmOkydPIoRmzpxp5vIWQXMGzp8/r9VqJ0+ebDB9woQJAoFA/+OSsrIypVIZEBAgk8lGjBhx+vRpY22GhYU5OjpmZ2dXVFRs3ryZmqh/SIMQunbtGkmSL7/8sonajHVkojaT64oQQlKpNDo6urCwcMOGDStWrBh0eYvYtGkTh8NZtWpVX1+fwazq6momk2nxNSJJct26dVVVVUeOHDHYvZjQ3NyckZEhlUrfe+89M59iGZYaWJg/Jvbx8VEoFCqVqqKiwtvb283NjRpFGZwX+vTTT1ksVm5ubkdHR2Vlpb+/v7Ozc3d3N0mS27ZtQwgtW7asqalJo9F0dnbW1NSQfz4vRJJkfHw8k8ksLy8nSXL8+PEHDx5sb29XKpUlJSW+vr6urq4tLS2mqzXWkYnaDEaQX331FULo5s2bujavX7+OEPLz8xuwR4uPiSmFhYU8Hi8gIOD48eMKhUKpVP7888/Z2dljx45NTEy0+BpVV1cP+GZLS0ujFvD09BQKhV1dXRqNhvqoOC8vz8PDw8nJiXq9THu2zwvl5OSEhYVJJBImk+ng4BAbG/vrr7+SJLl9+/ZRo0YhhPh8/pw5c0iS1Gq1aWlp48aNY7FY9vb2s2fPrqur07Wzc+dOPz8/LpfL5XL9/f2zsrKKiors7e0RQjKZTC6Xd3Z2Uh9JCgSC/fv3r1692tPTk8/nM5lMqVT6wQcf3Lt3z5z16t+RidqysrJ4PB5CaNy4cbdv387OzqaGd25ubtT5X0pYWNi+ffv0eyktLX3llVecnZ2p94qTk9OUKVP+93//1yLbnNLY2LhmzRo/Pz+BQMBgMMRisb+///vvv3/lyhWLr5Gx71+kpaUdPXp04sSJPB6PzWbb2NigPz4qDg4OTk5Obm1tNWddLJsBi91/gLr2paVaA+bAdptTXz2y1IVW6T8vBAC9sM5AbW0tYVxMTAzdBQJrwPoeWN7e3hgeSAADWO8HAECQAQAgAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgzsLfnaZ+4AOso6mpCWG5zX/44YeQkBBLtWax/YCLi0tkZKSlWsPHxYsXHzx4MLTnSqVSPLd5SEiI6WuCPBaL/Z4YDA1BEPn5+dHR0XQXgi8YDwDcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3MF9aKwtISGhrq5O9/DKlSsvvPCCo6Mj9ZDBYHz77bdSqZSm6nBk4XvygUFJJJLs7Gz9KTU1Nbq/3d3dIQBWBsdC1rZgwQJjs9hsdnx8vBVrAQjBsRAtxo8ff/PmzQG3fF1dnZeXl/VLwhnsB2gQFxfHYDAMJhIEMXHiRAiA9UEGaDB//nyNRmMwkclkLlq0iJZ6MAfHQvQICQm5du2aVqvVTSEI4u7du2PGjKGxKjzBfoAecXFxBEHoHtrY2LzyyisQAFpABuhhcGN6giDi4uLoKgZzkAF6ODo6Tp8+XX9kPGfOHBrrwRlkgDYLFy6kBmMMBmPGjBkODg50V4QpyABtIiIiWCwWQogkyYULF9JdDr4gA7Sxs7N76623EEJsNpv6A9DCYt8XampqKikpsVRrmJDJZAihyZMnHz9+nO5anjEuLi4vv/yyZdoiLSQ/P98yBQFghsjISEu9dS18LGSpsvCxevXqR48eDe251P8dy9bzTIiMjLTgmxbGAzRLSUlhs9l0V4E1yADNbG1t6S4Bd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHBn1QwEBQUxGIxJkyb1n7Vt2zaJREIQxJ49e4YEUSNzAAAgAElEQVTWeGpqqkgkIgjip59+6j938+bNxJ9NmDBhaB0Nh+TkZF9fX6FQyOFwxo4du3bt2u7ubst2UVdXt2zZsvHjx9vZ2TGZTJFI5OXlNWvWrNLSUst2RDG2RkVFRR4eHvovBJvNlkgkoaGhaWlp7e3tw1HMICz1lW4zv8s+ffr0F198ccBZDQ0NCKHdu3cPuYaDBw8ihH788cf+s1JSUgxWfPz48UPuyOKmTZuWlZXV2tra2dmZn5/PYrFmzJgx6LPM//3Avn37WCzWq6++evLkyfb29ocPH96+fTsvL2/KlCl79+594vIHYHqNPD09RSIRSZJarba9vf38+fPx8fEEQTg7O1+7dm3QxiMjIy34Gxoarr2uf20pa8rNzX1qf7ouEAgSEhKoS61ER0cXFRUVFBTcvXvXxcXlyRv/4YcfEhISpk2bdurUKSbz/15xDw8PDw8PsVhM/euxODPXiCAIsVgcGhoaGho6a9asefPmzZo1q76+XiQSDUdVA6JhPEBdTAHoO3bsmP61hqhbcvT29lqk8c2bN2s0mtTUVF0AdMLDwxMTEy3Si4EhrFFkZGR8fLxcLh/y8fDQ0JCBW7dueXt78/l8W1vbqVOnXr58ecDFSJJMT0/38fHhcDj29vYRERG1tbW6ubm5uYGBgVwul8/ny2Sy/oc69+/fl8lkTCZzxowZT1LtgB0Zq23Xrl18Pp/H4xUXF8+cOVMoFEqlUuoIzcfHhyAIGxubgIAA6q2wdu1akUjE5XK/+eYbg05/++03W1tbd3f3J6mcolQqz5496+DgEBwcbGKxp2SNqNsvnDhxYugrPASWOqgyfzzg4eFx584dlUpVXV390ksvcbnc+vp6st94YOPGjWw2Ozc3V6FQVFZWTp482dHRsbm5mSTJjIwMhFBqampra2tbW9vevXsXLFhA/nk8oFQq586dW1xcTLWWkpIilUrFYjGLxZLJZO+8887Vq1cHrdZYRyZqW79+PULo7NmzHR0dcrl86tSpfD5fqVSq1WqZTObq6qpWq3Xtr1y5MiMjw6DTnp4eOzu7pKQki2zz+vp6hFBISIjpxay8RrrxgIHOzk6EkIuLi+lqLTseoHlMXFlZiRBas2YN+ecM9Pb2CgSCmJgY3ZJXr15FCCUnJyuVSrFYHBYWppulVqszMzNJvQyoVKrY2NgTJ07olmlsbLx+/XpXV9ejR49KS0v9/f1tbW2rq6tNlGqsIxO1kX+8Y/r6+qhZWVlZCKFbt26RfySqoKCAmtXT0+Pq6trR0WHQ7/r16728vDo7OwfdmOZs8/LycoTQ66+/bmIZ66+RsQyQJEmNEEyvlGUzQPPnA35+fiKRiEqCvpqamu7u7sDAQN2UoKAgNptdVlZWWVmpUCjCw8N1sxgMxvLly3UPNRrN/PnzJRKJ/lGQi4uLv7+/QCBgs9khISE5OTl9fX3Uy2mMsY5M1Na/Eer38iqVCiG0ePFikUiUmZlJzTpw4EBERIRQKNRf/vDhwwUFBadOnbKzszNRm/kEAgEa7ED86Vmjnp4ekiQNWhhu9H9GxmKxqA2qT6FQoD9ePx2xWNzV1UXtLsVisbEGExMTGxoa9uzZc+PGDWPL+Pn5MRgM6jjBGGMdmajNRGvUU5YsWVJSUkL9l929e3dSUpL+Anl5eVu3br1w4QJ17S2LkMlk1NGmiWWenjWi6vT29jZnYUuhOQNqtbqtrc3V1dVgOvXOM3gNFAqFVCodPXo0QqilpcVYm9HR0WfOnBGLxXFxcWq1esBltFqtVqvlcDgmajPWkYnaTLRGSUpKYrFYGRkZFy9edHFx8fT01M3asWPHgQMHzp07R/VrKRwOJzw8vKWl5cqVK/3ntrW1LV68+OlZo5MnTyKEZs6caebyFkFzBs6fP6/VaidPnmwwfcKECQKBgDqWpZSVlSmVyoCAAJlMNmLEiNOnTxtrMywszNHRMTs7u6KiYvPmzdRE/UMahBD1QYzpi/UZ68hEbSbXFSGEpFJpdHR0YWHhhg0bVqxYQU0kSXLdunVVVVVHjhwx+GdsEZs2beJwOKtWrerr6zOYVV1dzWQyn5I1am5uzsjIkEql7733nplPsQxLDSzMHxP7+PgoFAqVSlVRUeHt7e3m5kaNogzOC3366acsFis3N7ejo6OystLf39/Z2bm7u5skyW3btiGEli1b1tTUpNFoOjs7a2pqyH6fE8fHxzOZzPLycpIkx48ff/Dgwfb2dqVSWVJS4uvr6+rq2tLSYrpaYx2ZqM1gBPnVV18hhKi7UFKuX7+OEPLz89NNqa6uHvClSUtLs8g2J0mysLCQx+MFBAQcP35coVAolcqff/45Ozt77NixiYmJ1l8jT09PoVDY1dWl0Wi0Wq1cLs/Ly/Pw8HBycqJeL9Oe7fNCOTk5YWFhEomEyWQ6ODjExsb++uuvJElu37591KhRCCE+nz9nzhySJLVabVpa2rhx41gslr29/ezZs+vq6nTt7Ny508/Pj8vlcrlcf3//rKysoqIie3t7hJBMJpPL5Z2dndRHkgKBYP/+/atXr/b09OTz+UwmUyqVfvDBB/fu3TNnvfp3ZKK2rKwsHo+HEBo3btzt27ezs7Op4Z2bmxt1/pcSFha2b98+3cOqqqrhzgBJko2NjWvWrPHz8xMIBAwGQywW+/v7v//++1euXLHmGh09enTixIk8Ho/NZtvY2KA/PioODg5OTk5ubW01Z10smwGL3ZOvoKBg3rx5lmoNmAPbbR4VFYUQOnTokEVao/+8EAD0wjoDtbW1hHExMTF0FwisgYbvjT49vL29MTyQAAaw3g8AgCADAEAGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMCdhb87XVBQYNkGgQnUZdMx3OZNTU3mXPPCXJb6USb121YArONp/D0xGBqCIPLz86Ojo+kuBF8wHgC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuLPw/cjAoA4ePNjV1aU/5fvvv1coFLqHEREREonE6nXhC+7FZG2LFi3av38/i8WiHmq1WoIgCIJACGk0Gj6f/+DBAw6HQ2uNeIFjIWuLjY1FCKn+oNFo1Go19TeDwYiKioIAWBnsB6xNrVaPGjWqra1twLnff//99OnTrVwS5mA/YG1MJjM2NlZ3LKTPwcEhNDTU6hXhDjJAg9jYWJVKZTCRzWa/++67DAaDlpJwBsdCNCBJUiqV3rt3z2B6WVlZcHAwLSXhDPYDNCAIIi4uzuBwyMXFJSgoiK6ScAYZoIfB4RCLxYqPj6fOkAIrg2Mh2nh7e9fV1ekeVldXjx8/nsZ6sAX7Adq8++67usMhX19fCABdIAO0iY2NVavVCCEWi7Vo0SK6y8EXHAvRKTAw8Pr16wihO3fuuLm50V0OpmA/QKe4uDiSJIODgyEAdCItJD8/n+5VARiJjIy01FvXwt+dhiQ8rtTU1KVLl4pEoiE8t7S0NDMzE8NtnpGRYcHWLJyB6Ohoyzb43PP39x83btyQn56ZmYnhNj906JAFW4PxAM2eJADAIiADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwZ9UMBAUFMRiMSZMm9Z+1bds2iURCEMSePXuG1nhqaqpIJCII4qeffuo/d/PmzcSfTZgwYWgdDYfPP//c29vb1taWz+d7e3tv2LChs7PTsl3U1dUtW7Zs/PjxdnZ2TCZTJBJ5eXnNmjWrtLTUsh1RkpOTfX19hUIhh8MZO3bs2rVru7u7EUJFRUUeHh76LwSbzZZIJKGhoWlpae3t7cNRjGlWzcC1a9fCwsIGnLVmzZqSkpInafzjjz/eu3fvk7RAo0uXLn3wwQeNjY33799PSUn5/PPPIyMjLdj+119/7efnV1lZmZ6efvfu3Z6enh9//DElJUWhUFRVVVmwI51z584lJib+8ssvLS0tW7ZsyczMjIqKQgjNnTv3559/9vT0FIlEJElqtVq5XF5QUODu7r5u3brx48eXl5cPRz0m0HAPDrquJJWbm7tw4UJauh4Um83+29/+xuVyEUJRUVGHDh06dOjQ77//7uzs/OSN//DDDwkJCdOmTTt16hST+X+vuIeHh4eHh1gsbmhoePIu+hMIBAkJCdTlU6Ojo4uKigoKCu7evevi4qK/GEEQYrE4NDQ0NDR01qxZ8+bNmzVrVn19/dB+WDc0NIwHBrzkMuYOHz5MBYAyZswYhBB18PDkNm/erNFoUlNTdQHQCQ8PT0xMtEgvBo4dO6Z//WBHR0eEUG9vr4mnREZGxsfHy+XyIR8PDw0NGbh165a3tzefz7e1tZ06derly5cHXIwkyfT0dB8fHw6HY29vHxERUVtbq5ubm5sbGBjI5XL5fL5MJktJSTF4+v3792UyGZPJnDFjxpNUO2BHxmrbtWsXn8/n8XjFxcUzZ84UCoVSqfTgwYMIIR8fH4IgbGxsAgICqLfC2rVrRSIRl8v95ptvDDptaGgQi8UWudiEUqk8e/asg4OD6av5Dvca/fbbb7a2tu7u7qarjY+PRwidOHFi6Cs8BJb6cT71y+5BF5s+fbqHh8edO3dUKlV1dfVLL73E5XLr6+tJkqR2yrt376aW3LhxI5vNzs3NVSgUlZWVkydPdnR0bG5uJkmS+kl1ampqa2trW1vb3r17FyxYQJIk9dr8+OOPJEkqlcq5c+cWFxdTraWkpEilUrFYzGKxZDLZO++8c/Xq1UGrNdaRidrWr1+PEDp79mxHR4dcLp86dSqfz1cqlWq1WiaTubq6qtVqXfsrV67MyMjQPVQqlU1NTTt27OBwOLm5uRbZ5vX19QihkJAQ04sN0xpRenp67OzskpKSdFN04wED1JkAFxcX09VGRkZa8LoSNGTgxRdf1D2srKxECK1Zs4b8cwZ6e3sFAkFMTIxuyatXryKEkpOTlUqlWCwOCwvTzVKr1ZmZmaReBlQqVWxs7IkTJ3TLNDY2Xr9+vaur69GjR6Wlpf7+/ra2ttXV1SZKNdaRidrIP94xfX191KysrCyE0K1bt8g/ElVQUEDN6unpcXV17ejo0LUzatQohJCDg8MXX3yhVCoH3ZjmbHNqiPn666+bWGb41oiyfv16Ly+vzs5O3RRjGSBJkhohmF4py2aA5s8H/Pz8RCIRlQR9NTU13d3dgYGBuilBQUFsNrusrKyyslKhUISHh+tmMRiM5cuX6x5qNJr58+dLJBL9oyAXFxd/f3+BQMBms0NCQnJycvr6+qiX0xhjHZmorX8jbDYbIURdYnrx4sUikSgzM5OadeDAgYiICKFQqFv47t27crn8u++++/bbb/39/eVyuYnyzCQQCNBgB+LDt0YIocOHDxcUFJw6dcrOzm7Qant6ekiSNGhhuNH/GRmLxep/UxbqXqXU66cjFou7urqo3aVYLDbWYGJiYkNDw549e27cuGFsGT8/PwaDQR0nGGOsIxO1mWiNesqSJUtKSkqo/7K7d+9OSkrSX4DFYo0cOfKNN97Iy8urqanZsmWL6QbNIZPJqKNNE8sM3xrl5eVt3br1woULMpnMnGqpOr29vc1Z2FJozoBarW5ra3N1dTWYTr3zDF4DhUIhlUpHjx6NEGppaTHWZnR09JkzZ8RicVxcHHVR2/60Wq1WqzV9B0hjHZmozURrlKSkJBaLlZGRcfHiRRcXF09PzwEXGzt2LIPBqKmpGbTBQXE4nPDw8JaWlitXrvSf29bWtnjx4mFaox07dhw4cODcuXPUljTHyZMnEUIzZ840c3mLoDkD58+f12q1kydPNpg+YcIEgUCg/3FJWVmZUqkMCAiQyWQjRow4ffq0sTbDwsIcHR2zs7MrKio2b95MTdQ/pEEIXbt2jSTJl19+2URtxjoyUZvJdUUIIalUGh0dXVhYuGHDhhUrVlATW1tb58+fr79YQ0ODRqMxOJU+ZJs2beJwOKtWrerr6zOYVV1dzWQyLb5GJEmuW7euqqrqyJEjBrsXE5qbmzMyMqRS6XvvvWfmUyzDUgML88fEPj4+CoVCpVJVVFR4e3u7ublRoyiD80Kffvopi8XKzc3t6OiorKz09/d3dnbu7u4mSXLbtm0IoWXLljU1NWk0ms7OzpqaGvLP54VIkoyPj2cymeXl5SRJjh8//uDBg+3t7UqlsqSkxNfX19XVtaWlxXS1xjoyUZvBCPKrr75CCN28eVPXJnWhaT8/P92Uvr4+BwcH6sSLUqm8fv16SEgIn8+vqqqyyDYnSbKwsJDH4wUEBBw/flyhUCiVyp9//jk7O3vs2LGJiYkWX6Pq6uoB32xpaWnUAp6enkKhsKurS6PRUB8V5+XleXh4ODk5Ua+Xac/2eaGcnJywsDCJRMJkMh0cHGJjY3/99VeSJLdv306dFeHz+XPmzCFJUqvVpqWljRs3jsVi2dvbz549u66uTtfOzp07/fz8uFwul8v19/fPysoqKiqyt7dHCMlkMrlc3tnZSf0fFQgE+/fvX716taenJ5/PZzKZUqn0gw8+uHfvnjnr1b8jE7VlZWXxeDyE0Lhx427fvp2dnU0N79zc3Kjzv5SwsLB9+/bp9/L222+7u7sLBAIOh+Pp6RkTEzNoAMzf5pTGxsY1a9b4+fkJBAIGgyEWi/39/d9///0rV65YfI2Mff8iLS3t6NGjEydO5PF4bDbbxsYG/fFRcXBwcHJycmtrqznrYtkMWOz+AwUFBfPmzbNUa8Ac2G5z6qtHlrrqKP3nhQCgF9YZqK2tJYyLiYmhu0BgDTR8b/Tp4e3tjeGBBDCA9X4AAAQZAAAyAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuLPzdabqup4szPLe5Ba/LbbHfUjY1NT3hxdPxNG/evBUrVpi+wgXoz8XFxVIbzWIZAENDEER+fn50dDTdheALxgMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7ix8LyYwKIVCYXDfk56envb2dt1DgUDAYrGsXhe+4D401hYWFnbhwgVjcxkMRlNTk5OTkxUrwh0cC1lbbGyssbvo2djYvPrqqxAAK4MMWFtUVBSDwRhwFkEQcXFxVq4HQAaszd7e/o033hgwBjY2NhEREdYvCXOQARosXLhQq9UaTGQymW+++aZYLKalJJxBBmjwzjvvcDgcg4larXbhwoW01IM5yAANeDxeRESEwQlQDocza9YsukrCGWSAHgsWLFCpVLqHLBYrKirK1taWxpKwBRmgR3h4uFAo1D1UqVTz58+nsR6cQQbowWKxYmNj2Ww29VAsFk+fPp3ekrAFGaBNbGysUqlECLFYrAULFjCZ8L0VesB3JWij1WpHjx59//59hNClS5f+8pe/0F0RpmA/QBsbGxvqZKizs/Mrr7xCdzn4+tP+t7S0ND09na5SMER9XVQoFEZHR9NdC0ZefvnlVatW6R7+aT9w9+7dwsJCq5f03GpqajK9Pe3t7YVCoaurq9VKAj/88ENpaan+lAHGYYcOHbJWPc+5goKCefPmmd6eBQUFsBOwpqioKIMpMB6gGQSAdpABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4e+wMBAUFMRiMSZMm9Z+1bds2iURCEMSePXuGVk1qaqpIJCII4qeffuo/d/PmzcSfTZgwYWgdDdmTr6OBoqIiDw8PanU2bNgw4DLp6ekEQdjY2Hh7e1+8ePEJeyEIgsVijRkzZsGCBTdv3hxy5f03xX/+8x+RSPTvf/97yG0ihJKTk319fYVCIYfDGTt27Nq1a7u7u/uvAkEQbDZbIpGEhoampaXpX7z+sZF68vPzDaYMaPr06S+++OKAsxoaGhBCu3fvHrQRYw4ePIgQ+vHHH/vPSklJMSh+/PjxQ+5oyMxfRzO3J0mSnp6eCCEnJyelUmkwS61Wu7m5IYSmT58+lHL/3ItIJCJJsru7++jRo66urgKBoLa2dsgNGmyKY8eOCYXCo0ePPkmR06ZNy8rKam1t7ezszM/PZ7FYM2bM6L8KWq22vb39/Pnz8fHxBEE4Oztfu3bNnPYjIyMjIyP1pwzxWMjY1cOHW25urn711dXVtJQxHAICApqbm48cOWIwvaioaMyYMZbti8/nv/XWW1988UV3d/eOHTss1eysWbM6OjreeuutJ2lEIBAkJCSMGDHCzs4uOjp69uzZJ0+evHv3rsFiBEGIxeLQ0NCcnJyCgoL79+9TvQ+hxyFmAG6UYnFLly5FCO3evdtgenp6+urVq4ejx+DgYITQ0/B/hCTJQ4cOZWdnI4SOHTumf1FuR0dHhFBvb6+Jp0dGRsbHx8vl8qEdoA4xA7du3fL29ubz+ba2tlOnTr18+fKAi5EkmZ6e7uPjw+Fw7O3tIyIiamtrdXNzc3MDAwO5XC6fz5fJZP0Pde7fvy+TyZhM5owZM4ZW55dffsnlciUSyYcffujs7MzlcqdMmVJWVjZoeaYrHw6vvfaaj4/P+fPn6+rqdBOvXLnS29v7xhtvGCx86dIlX19fkUjE5XL9/PxOnTqFEPrmm28EAgFBEPb29keOHCkvL3dzc2MwGMauYKdWqxFC1NV/n3xTXL582dXVlSCInTt3IoR27drF5/N5PF5xcfHMmTOFQqFUKqUOdBFCGo1my5YtL7zwgq2traOjo7u7+5YtWwb8Sd1vv/1ma2vr7u5ueuvFx8cjhE6cOGF6sYHpH1qYPx7w8PC4c+eOSqWqrq5+6aWXuFxufX092e8AcePGjWw2Ozc3V6FQVFZWTp482dHRsbm5mSTJjIwMhFBqampra2tbW9vevXsXLFhA/nk8oFQq586dW1xcTLWWkpIilUrFYjGLxZLJZO+8887Vq1cHrTYhIYHP59+4cePhw4c1NTVBQUF2dnaNjY2myzMxa5jGA3fu3Pniiy8QQitWrNBNnz17dk5OTldXF/rzeODQoUObNm1qa2trbW0NCQlxcHCgpt+4cYPH4y1atIh6+PHHH+/bt0+/F+pgmpKbm4sQ+uijjyy1Kagjlh07dlAP169fjxA6e/ZsR0eHXC6fOnUqn8+nBjyfffYZg8EoLi7u7e2tqKgYNWpUaGho/83S09NjZ2eXlJRkbBV0Ojs7EUIuLi6Dbur+4wELjIkrKysRQmvWrCH/vFF6e3sFAkFMTIxuyatXryKEkpOTlUqlWCwOCwvTzVKr1ZmZmaReBlQqVWxs7IkTJ3TLNDY2Xr9+vaur69GjR6Wlpf7+/ra2ttXV1aarTUhI0N9q165dQwj94x//MFGeiVnkcGZAoVDw+Xx7e/ve3l6SJG/fvi2VSh89etQ/A/q2bNmCEJLL5dTDvXv3IoQOHDjw3XffrVq1yqAX3Zi4sLBw1KhREomkqanJUptiwAz09fVRD7OyshBCt27dIkkyKCgoODhY1+aSJUtsbGwePXpksGrr16/38vLq7Ozsvwr9USOEAWfps9iYWJ+fn59IJKKSoK+mpqa7uzswMFA3JSgoiM1ml5WVVVZWKhSK8PBw3SwGg7F8+XLdQ41GM3/+fIlEon8U5OLi4u/vLxAI2Gx2SEhITk5OX18ftWXNFxgYyOPxamtrTZRnYtZj9fW4RCLR/Pnz29vb8/LyEEIZGRlLly7VXZPUGGpsptFoqIdLliyJjIz88MMPCwoK/vnPfxos3NHRQRCESCRavnz5m2++efXq1TFjxlhnU1ArQl1t++HDh6TeBQ41Gg2LxTK4N8/hw4cLCgpOnTplZ2c3aOM9PT0kSepfxth8lvmMjMVi6V9JnKJQKBBCAoFAf6JYLO7q6qL2XCbuuZKYmNjQ0LBnz54bN24YW8bPz4/BYNTX1z9utRwO58GDBybKMzHrcft6XNTIeM+ePQqF4tChQx9++OGAix0/fjw0NHTkyJEcDmft2rUGcz/77LPu7m65XN7/idQ/UbVa3dTU9K9//Ys662r9TfHmm29WVFQUFxf39fWVl5cfOXLkr3/9q34G8vLytm7deuHCBZlMZk6D1NvA29t7CMVYIANqtbqtra3/haKot7jBxlIoFFKpdPTo0QihlpYWY21GR0efOXNGLBbHxcVRQ7f+tFqtVqvtf0MX01QqFVWDifJMzHqsvoZg0qRJISEhV69eTUhIiIqKsre3779MY2Pj7NmznZycysrKOjo6Pv/8c/25KpVq+fLl6enppaWlmzdvNqdT62+KTZs2vfbaa/Hx8UKhcM6cOdHR0V999ZVu7o4dOw4cOHDu3DnqfWKOkydPIoRmzpw5hGIskIHz589rtdrJkycbTJ8wYYJAICgvL9dNKSsrUyqVAQEBMplsxIgRp0+fNtZmWFiYo6NjdnZ2RUWF7oXUP3ZCCFGfibz88suPVe2FCxdIkgwJCTFRnolZj9XX0FC7gsLCwpUrVw64QFVVlUqlWrp0qYeHB5fLNfisZtmyZR988MHKlStXrVqVkpJicE21AVl/U9TU1Ny+ffvBgwcqlaqxsXHXrl1U2kmSXLduXVVV1ZEjRwx2PiY0NzdnZGRIpdL33ntvKNXoDw7MHxP7+PgoFAqVSlVRUeHt7e3m5tbR0UH2GyR9+umnLBYrNze3o6OjsrLS39/f2dm5u7ubJMlt27YhhJYtW9bU1KTRaDo7O2tqaq0T+8kAABl8SURBVMh+nxPHx8czmczy8nKSJMePH3/w4MH29nalUllSUuLr6+vq6trS0mK62oSEBDs7u7a2NpVK9d///pd6FnU8aqI8E7OGb0xM/f3w4UNHR8e5c+fq5hqMiamh14YNG/r6+urr6yMjIxFCv//+O0mSO3fupEarJEk+evTIz8/P3d2demlIkwNKi2wK02Ni6j/9zZs3SZIMCQmZNm1ae3u7QRnGPqxIS0vTrYJQKOzq6tJoNFqtVi6X5+XleXh4ODk5UW+SQVnmvFBOTk5YWJhEImEymQ4ODrGxsb/++itJktu3bx81ahRCiM/nz5kzhyRJrVablpY2btw4Fotlb28/e/bsuro6XTs7d+708/PjcrlcLtff3z8rK6uoqIj6fyCTyeRyeWdnp4uLC0JIIBDs379/9erVnp6efD6fyWRKpdIPPvjg3r17g1abkJBAfT2GyWQKhcKIiIjbt29Ts0yUZ2xW/3U0wZztefjwYeqLEo6OjomJidTEtWvXlpSUUH9/8skn1F27bWxsfH19L126RJLkunXrRowYIRaLo6KiqPPxnp6ekyZNIghixIgR1HNXrlxpY2ODEBKJRF9++aWXlxf1fnJ2do6KijIo48k3xY4dO6g6eTze22+/nZWVxePxEELjxo27fft2dnY2NWB1c3Orr68/d+6cg4OD7i3OYrF8fHyKioqqqqqMZeDo0aMTJ07k8XhsNptaL+pEUHBwcHJycmtr66DvBIplMvBsoT54p6Xr53J7WkRWVpb+xyCPHj1auXIlh8OhTgoPq/4ZwOLeJ7rzhuBp0NzcnJSUpP/VYDab7erqqlKpVCqV9W9M+Mz/fqC2tpYwLiYmhu4CgSFbW1sWi/X111/fv39fpVLdu3dv3759GzdujImJGdoJ/if0zGfA29vbxI7Pw8MjJyeno6PD3d0dbq3wlBCJRKdPn66urvby8rK1tfX19c3Jydm6deu3335LSz3P+bHQli1bqK8SgKfK1KlTz5w5Q3cV/+eZ3w8A8IQgAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgboDvjUZFRVm/judSU1MTgu35lPnhhx9CQkL0p/xpP+Di4kL9QBtYhFQqHXR7Xrx48cGDB9apByCEQkJCDK5FQpB6l/sC1kcQRH5+/oCXmwXWAeMBgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7yADAHWQA4A4yAHAHGQC4gwwA3EEGAO4gAwB3kAGAO8gAwB1kAOAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7iADAHeQAYA7uA+NtSUkJNTV1ekeXrly5YUXXnB0dKQeMhiMb7/9ViqV0lQdjga4Jx8YVhKJJDs7W39KTU2N7m93d3cIgJXBsZC1LViwwNgsNpsdHx9vxVoAQnAsRIvx48ffvHlzwC1fV1fn5eVl/ZJwBvsBGsTFxTEYDIOJBEFMnDgRAmB9kAEazJ8/X6PRGExkMpmLFi2ipR7MwbEQPUJCQq5du6bVanVTCIK4e/fumDFjaKwKT7AfoEdcXBxBELqHNjY2r7zyCgSAFpABehjcmJ4giLi4OLqKwRxkgB6Ojo7Tp0/XHxnPmTOHxnpwBhmgzcKFC6nBGIPBmDFjhoODA90VYQoyQJuIiAgWi4UQIkly4cKFdJeDL8gAbezs7N566y2EEJvNpv4AtHjGvi9UUFBAdwmWJJPJEEKTJ08+fvw43bVY0pQpU56hbz09Y58P6J9PBE+t/Px8gxNfT7Nn71goPz+ffC5Q67J69epHjx7RXYsl0f0GeWzPXgaeMykpKWw2m+4qsAYZoJmtrS3dJeAOMgBwBxkAuIMMANxBBgDuIAMAd5ABgDvIAMAdZADgDjIAcAcZALiDDADcQQYA7p7PDDx69Gj58uVOTk48Hu/111+XSCQEQezZs4fuuh5PUVGRh4cHMRCZTLZt27ZndL2eNs9nBrZv337y5Mna2trMzMwPP/ywpKSE7oqGYu7cuT///LOnp6dIJKK+mq9Wq3t7e+/fv8/j8dasWfOMrtfT5vnMwJEjRwIDA8Vi8ZIlSyIjI818Vl9f35QpU4w9fBowGAxbW1uJRPJYlyV9+teLXs9nBpqamqhLNjyWr7/+Wi6XG3v4VDly5Ij5Cz9D60WL5y0DZ86cGTt27O+///7tt98SBCEQCPovc+nSJV9fX5FIxOVy/fz8Tp06hRBasWLF6tWrb9++TRDE2LFjDR4ihDQazcaNG11dXW1tbSdOnJifn48Q2rVrF5/P5/F4xcXFM2fOFAqFUqn04MGDVl7r53u9hh29vz19XMi83xOPGjVq0aJFuocNDQ0Iod27d1MPDx06tGnTpra2ttbW1pCQEAcHB2r63LlzPT09dc8yeLhmzRoOh1NYWNje3v73v//dxsbm2rVrJEmuX78eIXT27NmOjg65XD516lQ+n69UKi21LvrjAZIkz549m5aW9hys19PjedsPmCMyMvLTTz+1t7cfMWLE22+/3dra+uDBA9NPefjw4a5du2bPnj137lyxWPzJJ5+wWKycnBzdAlOmTBEKhSNHjoyJienp6WlsbLRgwR0dHbozQtOnTze22DO3Xk8JHDOgjxo29L8bgIG6urre3t4JEyZQD21tbZ2cnGpra/svSf1AXqVSWbBI/f3A+fPnzXnKM7FeTwkcM3D8+PHQ0NCRI0dyOJy1a9ea85Senh6E0CeffKL7f/zrr7/29vYOc6UDCA0NXbNmzYCznun1ohF2GWhsbJw9e7aTk1NZWVlHR8fnn39uzrNGjhyJEMrIyNA/jiwtLR3mYh/D87peVvCMXWvxyVVVValUqqVLl3p4eCCzL1zn4uLC5XJ/+umnYa5u6J7X9bIC7PYDrq6uCKHvv//+4cOHDQ0NZWVlulkjRoy4d+/eL7/80tXVpVKp9B8yGIz/+Z//OXjw4K5duzo7OzUaTVNT0++//07fehh6XtfLGqx0/slC0GDn3X755Rd/f3+EEJPJnDx5cmFh4fbt20eNGoUQ4vP5c+bMIUny/7d37zFN3f8fxz+90fZUj8WtWAk3URYjgoEgk4sGYzLD+GNGilJBQf9YnFlEjVkTMMZgHHNqSjJL1P3lXMKKuOAlkYkSdVl00ajzQpCpA4eFgQgi0FBKz++PxsIXFfgh9Ni+X4+/7Onp4U3D03N6PSaTaebMmVqtNisr6/Dhw4yxuXPnPn369NatW+Hh4Wq1OjU1tbW1dcTF/v5+k8kUFhYml8t1Ol1mZuaDBw8sFgvHcYyxqKiox48fHzt2jOd5xlh4eHhDQ8N7/i5//PGH5/VgvV6/YsWK4df67u/1ofG3BnyIP/0uw/nc70XuWAhgBDQA1KEBoA4NAHVoAKhDA0AdGgDq0ABQhwaAOjQA1KEBoA4NAHVoAKhDA0AdGgDq0ABQhwaAOt/7TL0/feuBP/0uvksiCILYM/w/jPPrEkBcVqt1zZo1Yk8xXj7WgP+RSCS+9Rfjf/B4AKhDA0AdGgDq0ABQhwaAOjQA1KEBoA4NAHVoAKhDA0AdGgDq0ABQhwaAOjQA1KEBoA4NAHVoAKhDA0AdGgDq0ABQhwaAOjQA1KEBoA4NAHVoAKhDA0AdGgDq0ABQhwaAOjQA1KEBoA4NAHVoAKjzvfOR+bry8vJXr14NX3Lx4sWuri7PxVWrVgUFBXl9LrpwLiZvy8vL++mnnxQKhfuiy+WSSCTu86wNDg5qNJr29nalUinqjLTgWMjbjEYjY2zgtcHBQafT6f63TCbLyspCAF6G/YC3OZ3OWbNmvXjx4q3XXrx4ccWKFV4eiTjsB7xNLpcbjUbPsdBwH330UVpamtcnog4NiMBoNA4MDIxYGBAQsH79eplMJspIlOFYSASCIISEhNhsthHL//zzz8TERFFGogz7ARFIJJINGzaMOBwKDQ1dvHixWCNRhgbEMeJwSKFQ5Ofnu58hBS/DsZBo5s+f//DhQ8/F+/fvR0dHizgPWdgPiGb9+vWew6EFCxYgALGgAdEYjUan08kYUygUeXl5Yo9DF46FxJSQkHDr1i3G2D///BMeHi72OERhPyCmDRs2CIKQmJiIAETkt/sBPMcy6axW65o1a8SeYvL583unt23blpSUJO4MZrOZMbZ9+/Z3rVBSUrJly5YZM2Z4caiJWLt2rdgjTBV/biApKUn0/7dOnjzJGBtljLi4uKioKC9ONEF+3AAeD4jMJwLwb2gAqEMDQB0aAOrQAFCHBoA6NADUoQGgDg0AdWgAqEMDQB0aAOrQAFCHBoA66g309/cXFBTo9XqO46qrq0df2eVymc3m5OTkyZ3h1KlTkZGRkmECAgKCgoLS0tIOHDjQ2dk5uT8ORqDewKFDh6qrq+vr60tLS3t6ekZZ8++//162bNmOHTv6+vomd4bMzMwnT57MnTt3xowZgiC4XK62traKioo5c+aYTKbo6OibN29O7k+E4fz5MzTjUVVVlZCQoNVqv/zyy1FW++uvv4qLi7/66qve3t6p/vSpRCLRarVpaWlpaWkZGRlr167NyMhoaGj48D9r5qOo7weam5vf+hXQIyxatOjUqVM5OTlePjmAwWDIz89va2s7cuSIN38uKXQbqKmpmTdvXktLy/HjxyUSybRp09zLT5w4kZCQoFKpNBpNRETE3r17xZ0zPz+fMXb+/HnG2ODg4O7du8PCwtRqdWxsrNVqZYyVlZVpNBqO406fPp2ens7zfEhISHl5ufvmV65cSUxM5DiO5/mYmJju7u53bYcuwU8xxqxW65irzZo1Ky8vz3PR/RH4kpKSjo6OFy9eHD16NCcnZ/j6n3766aJFi8Y/hsFgMBgM41nT83hgBPdfbWhoqCAIO3fuVCqVlZWVnZ2dhYWFUqn0xo0bgiAUFRUxxi5duvTy5cu2tralS5dqNBqHw9HT08Pz/P79++12e2tr6+rVq9vb20fZzijGeX/6IjQw1IDD4dBqtcuXL/dc63Q6S0tLh6/v/QYEQXA/QrDb7RzHZWdnuxf29fUplcotW7YIrxuw2+3uqywWC2Ps0aNH9+/fZ4ydO3du+NZG2c4o/LgBusdCb7p7925XV9fKlSs9S2QyWUFBgYgjMcbcj8J5nn/48GFfX9/ChQvdy9VqtV6vr6+vf/MmAQEBjLGBgYHIyMigoKDc3Nw9e/Y0Nja6rx3/dohAA0PcRx1arVbsQf5HQ0MDY2z+/Pm9vb2MsV27dnleRmhqahr9iVq1Wl1bW5uamrpv377IyMjs7Gy73T6B7fg3NDAkODiYMfb8+XOxB/kf7lfu0tPTdTodY8xsNg/fj1+7dm30m0dHR589e9Zms5lMJqvVevDgwYltx4+hgSEREREzZ868cOGC2IMMaW1tNZvNISEhmzZtCg0NValUd+7cGf/NbTZbXV0dY0yn05WUlMTHx9fV1U1gO/4NDQxRKpWFhYVXr17dunXrs2fPXC7Xq1ev3H9D3iEIQk9Pj8vlEgShvb3darWmpKTIZLKqqiqe51Uq1caNG8vLy8vKyrq7uwcHB5ubm1taWkbZoM1m27x5c319vcPhuH37dlNT05IlSyawHT/nxcffXsXGeh6jsbExLi6OMSaXy+Pj4ysrK93LDx8+HBMTo1KpVCpVXFycxWIRBOHatWspKSmzZ89232l6vT45OfnKlStjjjGe54XOnDkTGxvLcVxAQIBUKmWvXypOTEwsLi7u6OjwrNnf328ymcLCwuRyuU6ny8zMfPDggcVi4TiOMRYVFfX48eNjx47xPM8YCw8Pr6mpSU5ODgwMlMlkwcHBRUVFTqfzXdt5z/vTd/nz905/CN+TnJWVxV5/66hP+0Duz6mAYyGgDg0AdWgAqEMDQB0aAOrQAFCHBoA6NADUoQGgDg0AdWgAqEMDQB0aAOrQAFCHBoA6NADUoQGgzp8/Ryb2CP7GXz9H5rffO+0r36G5du3abdu2JSUliT3I2Cb9xAsfCL/dD/gKP/6crq/A4wGgDg0AdWgAqEMDQB0aAOrQAFCHBoA6NADUoQGgDg0AdWgAqEMDQB0aAOrQAFCHBoA6NADUoQGgDg0AdWgAqEMDQB0aAOrQAFCHBoA6NADUoQGgDg0AdWgAqEMDQB0aAOrQAFCHBoA6NADU+e15aD5YXV1dI8570tvb29nZ6bk4bdo0hULh9bnownlovG358uWXL19+17Uymay5uVmv13txIupwLORtRqPxXecLlEqly5YtQwBehga8LSsrSyaTvfUqiUSyYcMGL88DaMDbAgMDP/vss7dmIJVKV61a5f2RiEMDIsjNzXW5XCMWyuXyzz//XKvVijISZWhABF988YVSqRyx0OVy5ebmijIPcWhABBzHrVq1asQToEqlMiMjQ6yRKEMD4sjJyRkYGPBcVCgUWVlZarVaxJHIQgPiWLlyJc/znosDAwPr1q0TcR7K0IA4FAqF0WgMCAhwX9RqtStWrBB3JLLQgGiMRqPD4WCMKRSKnJwcuRzvWxEH3ishGpfLFRwc/N9//zHGfv/999TUVLEnIgr7AdFIpVL3k6GzZ89OSUkRexy6/Hb/m5WVJfYIY3O/XZTn+TVr1og9y9h27NiRlJQk9hSTz2/3A5WVlc3NzWJPwa5fv379+vV3XRsYGMjzfFhYmDdHmpjKysp///1X7CmmhN/uBxhj27dvF/3/V/fu6OTJk+9aoaKiQvQhx+Nd73X1A367H/AVPhGAf0MDQB0aAOrQAFCHBoA6NADUoQGgDg0AdWgAqEMDQB0aAOrQAFCHBoA6NADUUW+gv7+/oKBAr9dzHFddXf2u1YqLixcsWMDzvFKpnDdv3jfffNPT0zNZM5w6dSoyMlIyTEBAQFBQUFpa2oEDB4Z/LTtMBeoNHDp0qLq6ur6+vrS0dJQ/69ra2q+//rqxsfH58+fffvttaWnpJH5OLTMz88mTJ3Pnzp0xY4YgCC6Xq62traKiYs6cOSaTKTo6+ubNm5P1s+AtBD/FGLNarWOutnjx4nXr1o25WkZGhtPp9Fx0v+n/6dOnY97QYDAYDIYxVxMEwdPAcCdPnpRKpUFBQe4zd4honPenL6K+H2hubh7PSV/OnTs3/JuiP/74Y8ZYX1/fFE7GGGPMYDDk5+e3tbUdOXJkqn8WWXQbqKmpmTdvXktLy/HjxyUSybRp09zLT5w4kZCQoFKpNBpNRETE3r1737zts2fP1Gr1nDlzvDBnfn4+Y+z8+fOMscHBwd27d4eFhanV6tjYWKvVyhgrKyvTaDQcx50+fTo9PZ3n+ZCQkPLycvfNr1y5kpiYyHEcz/MxMTHd3d3v2g5dYu+Ipgob37571qxZeXl5notms5kxVlJS0tHR8eLFi6NHj+bk5Iy4SW9v7/Tp07du3TqeMd7zWEgQBPdfbWhoqCAIO3fuVCqVlZWVnZ2dhYWFUqn0xo0bgiAUFRUxxi5duvTy5cu2tralS5dqNBqHw9HT08Pz/P79++12e2tr6+rVq9vb20fZzijGeX/6IjQw1IDD4dBqtcuXL/dc63Q6S0tLR9ykqKjok08+6e7uHs8Y79+AIAgSiUSr1drtdo7jsrOz3Qv7+vqUSuWWLVuE1w3Y7Xb3VRaLhTH26NGj+/fvM8bOnTs3fGujbGcUftwA3WOhN929e7erq2vlypWeJTKZrKCgYPg6v/76a0VFxW+//TZ9+nTvTNXb2ysIAs/zDx8+7OvrW7hwoXu5Wq3W6/X19fVv3sT9NaYDAwORkZFBQUG5ubl79uxpbGx0Xzv+7RCBBoa4jzpGORPML7/88t13312+fDkiIsJrUzU0NDDG5s+f39vbyxjbtWuX52WEpqam0R+Xq9Xq2tra1NTUffv2RUZGZmdn2+32CWzHv6GBIcHBwYyx58+fv/XaH3744eeff66trXWv5jXuV+7S09N1Oh1jzGw2D9+PX7t2bfSbR0dHnz171mazmUwmq9V68ODBiW3Hj6GBIRERETNnzrxw4cKI5YIgmEyme/fuVVVVeZ4+8o7W1laz2RwSErJp06bQ0FCVSnXnzp3x39xms9XV1THGdDpdSUlJfHx8XV3dBLbj39DAEKVSWVhYePXq1a1btz579szlcr169aqurq6uru7777//8ccfFQrF8Hc0HDx4cHIHEAShp6fH5XIJgtDe3m61WlNSUmQyWVVVFc/zKpVq48aN5eXlZWVl3d3dg4ODzc3NLS0to2zQZrNt3ry5vr7e4XDcvn27qalpyZIlE9iOn/Pew2/vYmM9j9HY2BgXF8cYk8vl8fHxlZWV7uWHDx+OiYlRqVQqlSouLs5isdy7d++td92BAwfGHGM8zwudOXMmNjaW47iAgACpVMoYcz8RlJiYWFxc3NHR4Vmzv7/fZDKFhYXJ5XKdTpeZmfngwQOLxcJxHGMsKirq8ePHx44dc5/hJjw8vKamJjk5OTAwUCaTBQcHFxUVuV/tfut23vP+9F1+e/4BiURitVpF/ybDMb9v1Fd8IPfnVMCxEFCHBoA6NADUoQGgDg0AdWgAqEMDQB0aAOrQAFCHBoA6NADUoQGgDg0AdWgAqEMDQB0aAOrQAFAnF3uAKWQ2m0X/ANf169fZ60+TwYfJbxswGAxij8AYY0uWLBF7hMlhMBhCQ0PFnmJK+O3niQHGCY8HgDo0ANShAaAODQB1/weu1hSaAe5RXAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i_hZr0srAwy",
        "outputId": "90d09198-f533-4741-9bbd-0bfa772056c5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134260544 (512.16 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 134260544 (512.16 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.layers[-3].output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9spuigDpZeS",
        "outputId": "8964d906-f2e5-48c6-bbb4-1caea2c0aeed"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 25088) dtype=float32 (created by layer 'flatten')>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_conv_info(model):\n",
        "\n",
        "    trainable_params = 0\n",
        "    frozen_params = 0\n",
        "\n",
        "    for layer in model.layers:\n",
        "        if layer.trainable:\n",
        "            trainable_params += layer.count_params()\n",
        "        else:\n",
        "            frozen_params += layer.count_params()\n",
        "\n",
        "    return trainable_params, frozen_params"
      ],
      "metadata": {
        "id": "Xpi9pWv-_YZ9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for unfreeze in range(1, len(base_model.layers) + 1):\n",
        "    print(f\"Tuning last {unfreeze} layers.\")\n",
        "    if type(base_model.layers[-unfreeze]) in meaningless:\n",
        "        continue\n",
        "\n",
        "    iter_accs = []\n",
        "\n",
        "    for k in range(20):\n",
        "        temp_model = models.Model(inputs=base_model.inputs, outputs=base_model.outputs)\n",
        "        time.sleep(3)\n",
        "\n",
        "        curr_filter_size = []\n",
        "        curr_num_filters = []\n",
        "        curr_pool_size = []\n",
        "        curr_acts = []\n",
        "        curr_pad = []\n",
        "        curr_units = []\n",
        "        curr_dropouts = []\n",
        "\n",
        "        # saving the architecture\n",
        "        temp_arc = []\n",
        "        for j in range(1, unfreeze + 1):\n",
        "            if type(temp_model.layers[-j]) == layers.Conv2D:\n",
        "                temp_arc.append('conv')\n",
        "                curr_filter_size.append(random.sample(filter_size_space, 1)[0])\n",
        "                curr_num_filters.append(random.sample(num_filter_space, 1)[0])\n",
        "                curr_acts.append(random.sample(acts_space, 1)[0])\n",
        "            elif type(temp_model.layers[-j]) == layers.MaxPooling2D:\n",
        "                temp_arc.append('maxpool')\n",
        "                curr_pool_size.append(random.sample(pool_size_space, 1)[0])\n",
        "            elif type(temp_model.layers[-j]) == layers.GlobalAveragePooling2D:\n",
        "                temp_arc.append('globalavgpool')\n",
        "            elif type(temp_model.layers[-j]) == layers.Activation:\n",
        "                temp_arc.append('activation')\n",
        "                curr_acts.append(random.sample(acts_space, 1)[0])\n",
        "            elif type(temp_model.layers[-j]) == layers.Add:\n",
        "                temp_arc.append('add')\n",
        "            elif type(temp_model.layers[-j]) == layers.BatchNormalization:\n",
        "                temp_arc.append('batch')\n",
        "            elif type(temp_model.layers[-j]) == layers.ZeroPadding2D:\n",
        "                temp_arc.append('zeropad')\n",
        "                curr_pad.append(random.sample(pad_size_space, 1)[0])\n",
        "            elif type(temp_model.layers[-j]) == layers.Dense:\n",
        "                temp_arc.append('dense')\n",
        "                curr_units.append(random.sample(units_space, 1)[0])\n",
        "                curr_dropouts.append(random.sample(dropouts_space, 1)[0])\n",
        "                curr_acts.append(random.sample(acts_space, 1)[0])\n",
        "            elif type(temp_model.layers[-j]) == layers.Flatten:\n",
        "                temp_arc.append('flatten')\n",
        "\n",
        "        # for each iteration - create another model\n",
        "        print(f'#{k}')\n",
        "        to_train_model = get_model_conv(temp_model, # temporary model\n",
        "                                        -unfreeze, # number of layer to be modified\n",
        "                                        reverse_list(temp_arc),\n",
        "                                        reverse_list(curr_num_filters),\n",
        "                                        reverse_list(curr_filter_size),\n",
        "                                        reverse_list(curr_pool_size),\n",
        "                                        reverse_list(curr_acts), # acts are parameters to modify the actvation target layer\n",
        "                                        reverse_list(curr_pad),\n",
        "                                        curr_units,\n",
        "                                        curr_dropouts)\n",
        "        to_train_model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # train the modified model\n",
        "        history = to_train_model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data=valid_generator, epochs=EPOCHS,\n",
        "            steps_per_epoch=len(train_generator) / batch_size,\n",
        "            validation_steps=len(valid_generator), callbacks=[reduce_LR]\n",
        "        )\n",
        "\n",
        "        best_acc_index = history.history['val_accuracy'].index(max(history.history['val_accuracy']))\n",
        "        temp_acc = history.history['val_accuracy'][best_acc_index]\n",
        "        iter_accs.append(temp_acc)\n",
        "\n",
        "        # log the results\n",
        "        n_trainable_params, n_frozen_params = get_model_conv_info(to_train_model)\n",
        "        log_tuple = (reverse_list(curr_acts), 'he_normal', unfreeze, len(curr_units), reverse_list(curr_units),\n",
        "                     reverse_list(curr_dropouts), reverse_list(curr_filter_size), reverse_list(curr_num_filters), [1] * len(curr_num_filters),\n",
        "                     reverse_list(curr_pool_size), history.history['loss'][best_acc_index], history.history['accuracy'][best_acc_index],\n",
        "                     history.history['val_loss'][best_acc_index], history.history['val_accuracy'][best_acc_index],n_trainable_params, n_frozen_params,\n",
        "                     datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') )\n",
        "        # aux_tuple = list(log_tuple)\n",
        "\n",
        "        # Add number of trainable parameters\n",
        "        # n_trainable_params, n_frozen_params = get_model_conv_info(to_train_model)\n",
        "        # aux_tuple += [n_trainable_params, n_frozen_params]\n",
        "\n",
        "        log_df.loc[log_df.shape[0], :] = log_tuple\n",
        "        # log_df.loc[log_df.shape[0], :] = tuple(aux_tuple)\n",
        "        log_df.to_csv(RESULTS_PATH)\n",
        "\n",
        "    if best_acc > (sum(iter_accs) / len(iter_accs)):\n",
        "        print(\"Validation Accuracy did not improve.\")\n",
        "        print(f\"Breaking out at {i} layers.\")\n",
        "        break\n",
        "\n",
        "    best_acc = max(best_acc, sum(iter_accs) / len(iter_accs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT8DgSpipAdh",
        "outputId": "d51001ba-d06f-44ae-c80e-c428360ebae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning last 1 layers.\n",
            "#0\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 641ms/step - loss: 6.5107 - accuracy: 0.0000e+00 - val_loss: 13.7303 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 5.4048 - accuracy: 0.0000e+00 - val_loss: 11.4117 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 6.2062 - accuracy: 0.0500 - val_loss: 9.1842 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 5.5616 - accuracy: 0.0000e+00 - val_loss: 8.4836 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 5.4739 - accuracy: 0.0750 - val_loss: 7.9374 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 5.3296 - accuracy: 0.0500 - val_loss: 7.3810 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 4.9078 - accuracy: 0.0000e+00 - val_loss: 6.9760 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 4.8804 - accuracy: 0.0250 - val_loss: 6.6501 - val_accuracy: 0.0132 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 4.9299 - accuracy: 0.0500 - val_loss: 6.4216 - val_accuracy: 0.0165 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 5.0806 - accuracy: 0.0500 - val_loss: 6.2487 - val_accuracy: 0.0198 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 4.5682 - accuracy: 0.1500 - val_loss: 6.1179 - val_accuracy: 0.0198 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 4.8024 - accuracy: 0.1000 - val_loss: 5.9499 - val_accuracy: 0.0231 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 4.6689 - accuracy: 0.0750 - val_loss: 5.8638 - val_accuracy: 0.0231 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 4.8083 - accuracy: 0.1250 - val_loss: 5.7955 - val_accuracy: 0.0264 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 5.4762 - accuracy: 0.0500 - val_loss: 5.7357 - val_accuracy: 0.0231 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 4.5459 - accuracy: 0.1500 - val_loss: 5.6582 - val_accuracy: 0.0297 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 4.4285 - accuracy: 0.1000 - val_loss: 5.6213 - val_accuracy: 0.0264 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.6724 - accuracy: 0.0750 - val_loss: 5.5774 - val_accuracy: 0.0297 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.5032 - accuracy: 0.0000e+00 - val_loss: 5.5318 - val_accuracy: 0.0297 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.9016 - accuracy: 0.0513 - val_loss: 5.4998 - val_accuracy: 0.0297 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 4.7716 - accuracy: 0.0500 - val_loss: 5.4500 - val_accuracy: 0.0297 - lr: 1.0000e-04\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.8605 - accuracy: 0.0500 - val_loss: 5.4158 - val_accuracy: 0.0297 - lr: 1.0000e-05\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 4.5866 - accuracy: 0.1750 - val_loss: 5.3769 - val_accuracy: 0.0297 - lr: 1.0000e-05\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.9016 - accuracy: 0.0750 - val_loss: 5.3563 - val_accuracy: 0.0297 - lr: 1.0000e-05\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 4.6022 - accuracy: 0.1000 - val_loss: 5.3376 - val_accuracy: 0.0297 - lr: 1.0000e-05\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 5.0504 - accuracy: 0.0500 - val_loss: 5.3127 - val_accuracy: 0.0297 - lr: 1.0000e-05\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 4.3275 - accuracy: 0.0750 - val_loss: 5.2973 - val_accuracy: 0.0297 - lr: 1.0000e-06\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 4.9838 - accuracy: 0.0750 - val_loss: 5.2781 - val_accuracy: 0.0297 - lr: 1.0000e-06\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 4.2284 - accuracy: 0.1000 - val_loss: 5.2710 - val_accuracy: 0.0297 - lr: 1.0000e-06\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 4.7275 - accuracy: 0.1026 - val_loss: 5.2684 - val_accuracy: 0.0297 - lr: 1.0000e-06\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 4.9833 - accuracy: 0.0000e+00 - val_loss: 5.2582 - val_accuracy: 0.0330 - lr: 1.0000e-06\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 4.5750 - accuracy: 0.0500 - val_loss: 5.2538 - val_accuracy: 0.0330 - lr: 1.0000e-06\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 4.8987 - accuracy: 0.0500 - val_loss: 5.2452 - val_accuracy: 0.0330 - lr: 1.0000e-06\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 4.6991 - accuracy: 0.0500 - val_loss: 5.2333 - val_accuracy: 0.0330 - lr: 1.0000e-06\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 4.6532 - accuracy: 0.0750 - val_loss: 5.2247 - val_accuracy: 0.0330 - lr: 1.0000e-06\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 4.7733 - accuracy: 0.0750 - val_loss: 5.2096 - val_accuracy: 0.0330 - lr: 1.0000e-06\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 4.9181 - accuracy: 0.0513 - val_loss: 5.2111 - val_accuracy: 0.0363 - lr: 1.0000e-07\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 5.0355 - accuracy: 0.0500 - val_loss: 5.2084 - val_accuracy: 0.0363 - lr: 1.0000e-07\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 5.0211 - accuracy: 0.0500 - val_loss: 5.1893 - val_accuracy: 0.0363 - lr: 1.0000e-07\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.7049 - accuracy: 0.0250 - val_loss: 5.1771 - val_accuracy: 0.0363 - lr: 1.0000e-07\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 4.7081 - accuracy: 0.0500 - val_loss: 5.1734 - val_accuracy: 0.0363 - lr: 1.0000e-07\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 5.2844 - accuracy: 0.1000 - val_loss: 5.1671 - val_accuracy: 0.0363 - lr: 1.0000e-07\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 4.9883 - accuracy: 0.0250 - val_loss: 5.1618 - val_accuracy: 0.0363 - lr: 1.0000e-08\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 5.1315 - accuracy: 0.0750 - val_loss: 5.1602 - val_accuracy: 0.0363 - lr: 1.0000e-08\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.7016 - accuracy: 0.0750 - val_loss: 5.1490 - val_accuracy: 0.0363 - lr: 1.0000e-08\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.7669 - accuracy: 0.0750 - val_loss: 5.1447 - val_accuracy: 0.0363 - lr: 1.0000e-08\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.1378 - accuracy: 0.0500 - val_loss: 5.1470 - val_accuracy: 0.0363 - lr: 1.0000e-08\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.8032 - accuracy: 0.0750 - val_loss: 5.1465 - val_accuracy: 0.0363 - lr: 1.0000e-09\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 4.5011 - accuracy: 0.1750 - val_loss: 5.1488 - val_accuracy: 0.0363 - lr: 1.0000e-09\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.6967 - accuracy: 0.0750 - val_loss: 5.1468 - val_accuracy: 0.0363 - lr: 1.0000e-09\n",
            "#1\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 656ms/step - loss: 7.6021 - accuracy: 0.0000e+00 - val_loss: 12.6326 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 7.5597 - accuracy: 0.0000e+00 - val_loss: 10.3000 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 6.7273 - accuracy: 0.0000e+00 - val_loss: 8.9233 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 6.2050 - accuracy: 0.0250 - val_loss: 7.9814 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 7.6549 - accuracy: 0.0250 - val_loss: 7.3584 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 6.3030 - accuracy: 0.0500 - val_loss: 6.8856 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 6.9887 - accuracy: 0.0000e+00 - val_loss: 6.5575 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 6.8153 - accuracy: 0.0500 - val_loss: 6.2388 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 6.7476 - accuracy: 0.0256 - val_loss: 6.0133 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 5.7286 - accuracy: 0.0750 - val_loss: 5.8009 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 6.4277 - accuracy: 0.0250 - val_loss: 5.6314 - val_accuracy: 0.0528 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 6.2139 - accuracy: 0.0500 - val_loss: 5.4973 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 5.2193 - accuracy: 0.0500 - val_loss: 5.3223 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 5.6319 - accuracy: 0.0750 - val_loss: 5.1812 - val_accuracy: 0.0594 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 6.2122 - accuracy: 0.0500 - val_loss: 5.0776 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 5.7568 - accuracy: 0.0750 - val_loss: 4.9702 - val_accuracy: 0.0660 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 5.8881 - accuracy: 0.0500 - val_loss: 4.8780 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 5.0101 - accuracy: 0.0000e+00 - val_loss: 4.8029 - val_accuracy: 0.0660 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 5.1841 - accuracy: 0.0250 - val_loss: 4.7414 - val_accuracy: 0.0726 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.2316 - accuracy: 0.0750 - val_loss: 4.6614 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.4328 - accuracy: 0.0256 - val_loss: 4.5970 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 5.5803 - accuracy: 0.1250 - val_loss: 4.5374 - val_accuracy: 0.1023 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.8389 - accuracy: 0.1250 - val_loss: 4.4863 - val_accuracy: 0.0957 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 5.3083 - accuracy: 0.1500 - val_loss: 4.4587 - val_accuracy: 0.1023 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 4.8027 - accuracy: 0.0750 - val_loss: 4.4079 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.3438 - accuracy: 0.0750 - val_loss: 4.3593 - val_accuracy: 0.1023 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 4.0192 - accuracy: 0.2000 - val_loss: 4.3168 - val_accuracy: 0.1023 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.0922 - accuracy: 0.1250 - val_loss: 4.3011 - val_accuracy: 0.1056 - lr: 1.0000e-04\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 4.8140 - accuracy: 0.1000 - val_loss: 4.2919 - val_accuracy: 0.1023 - lr: 1.0000e-04\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 5.3684 - accuracy: 0.0500 - val_loss: 4.2827 - val_accuracy: 0.1056 - lr: 1.0000e-04\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 4.5577 - accuracy: 0.2051 - val_loss: 4.2689 - val_accuracy: 0.1023 - lr: 1.0000e-04\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.2004 - accuracy: 0.1000 - val_loss: 4.2590 - val_accuracy: 0.1023 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 4.6527 - accuracy: 0.1000 - val_loss: 4.2496 - val_accuracy: 0.1056 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.6728 - accuracy: 0.1250 - val_loss: 4.2457 - val_accuracy: 0.0990 - lr: 1.0000e-05\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.8964 - accuracy: 0.1250 - val_loss: 4.2398 - val_accuracy: 0.0990 - lr: 1.0000e-05\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.6846 - accuracy: 0.0250 - val_loss: 4.2355 - val_accuracy: 0.0990 - lr: 1.0000e-05\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 4.5237 - accuracy: 0.1500 - val_loss: 4.2300 - val_accuracy: 0.0990 - lr: 1.0000e-05\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.8632 - accuracy: 0.0750 - val_loss: 4.2247 - val_accuracy: 0.1023 - lr: 1.0000e-05\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.8122 - accuracy: 0.1250 - val_loss: 4.2237 - val_accuracy: 0.1023 - lr: 1.0000e-06\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 4.8031 - accuracy: 0.1750 - val_loss: 4.2183 - val_accuracy: 0.1023 - lr: 1.0000e-06\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.4271 - accuracy: 0.2000 - val_loss: 4.2160 - val_accuracy: 0.1056 - lr: 1.0000e-06\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.2350 - accuracy: 0.1000 - val_loss: 4.2132 - val_accuracy: 0.1023 - lr: 1.0000e-06\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 4.6532 - accuracy: 0.0769 - val_loss: 4.2116 - val_accuracy: 0.1089 - lr: 1.0000e-06\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.8670 - accuracy: 0.0500 - val_loss: 4.2084 - val_accuracy: 0.1089 - lr: 1.0000e-06\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.5607 - accuracy: 0.1500 - val_loss: 4.2058 - val_accuracy: 0.1056 - lr: 1.0000e-06\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 4.5303 - accuracy: 0.1250 - val_loss: 4.2026 - val_accuracy: 0.1056 - lr: 1.0000e-06\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 4.7295 - accuracy: 0.1282 - val_loss: 4.2004 - val_accuracy: 0.1056 - lr: 1.0000e-06\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.9922 - accuracy: 0.0750 - val_loss: 4.2000 - val_accuracy: 0.1056 - lr: 1.0000e-06\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 5.0809 - accuracy: 0.1250 - val_loss: 4.1973 - val_accuracy: 0.1056 - lr: 1.0000e-07\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.0131 - accuracy: 0.0500 - val_loss: 4.1944 - val_accuracy: 0.1056 - lr: 1.0000e-07\n",
            "#2\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 648ms/step - loss: 7.1623 - accuracy: 0.0250 - val_loss: 5.5204 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 6.9161 - accuracy: 0.0000e+00 - val_loss: 5.4615 - val_accuracy: 0.0033 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 6.6205 - accuracy: 0.0000e+00 - val_loss: 5.4163 - val_accuracy: 0.0033 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 5.7341 - accuracy: 0.0000e+00 - val_loss: 5.4245 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.8506 - accuracy: 0.1000 - val_loss: 5.3924 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 6.2310 - accuracy: 0.0250 - val_loss: 5.3282 - val_accuracy: 0.0033 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 5.6018 - accuracy: 0.0500 - val_loss: 5.3230 - val_accuracy: 0.0033 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 5.5881 - accuracy: 0.0500 - val_loss: 5.3185 - val_accuracy: 0.0033 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 4.6289 - accuracy: 0.0769 - val_loss: 5.3152 - val_accuracy: 0.0033 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 6.3723 - accuracy: 0.0250 - val_loss: 5.3143 - val_accuracy: 0.0033 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 5.5917 - accuracy: 0.0500 - val_loss: 5.3107 - val_accuracy: 0.0033 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 5.4813 - accuracy: 0.0000e+00 - val_loss: 5.3126 - val_accuracy: 0.0033 - lr: 1.0000e-05\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 5.4650 - accuracy: 0.0500 - val_loss: 5.3143 - val_accuracy: 0.0033 - lr: 1.0000e-05\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 5.6329 - accuracy: 0.0000e+00 - val_loss: 5.3171 - val_accuracy: 0.0033 - lr: 1.0000e-05\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 6.2670 - accuracy: 0.0500 - val_loss: 5.3200 - val_accuracy: 0.0033 - lr: 1.0000e-05\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 5.5189 - accuracy: 0.0500 - val_loss: 5.3218 - val_accuracy: 0.0033 - lr: 1.0000e-05\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 5.6354 - accuracy: 0.0500 - val_loss: 5.3250 - val_accuracy: 0.0033 - lr: 1.0000e-06\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 6.1384 - accuracy: 0.0500 - val_loss: 5.3280 - val_accuracy: 0.0033 - lr: 1.0000e-06\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 5.6010 - accuracy: 0.0500 - val_loss: 5.3320 - val_accuracy: 0.0033 - lr: 1.0000e-06\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 5.3896 - accuracy: 0.0250 - val_loss: 5.3361 - val_accuracy: 0.0033 - lr: 1.0000e-06\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 5.7957 - accuracy: 0.0256 - val_loss: 5.3398 - val_accuracy: 0.0033 - lr: 1.0000e-06\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 4.6107 - accuracy: 0.0250 - val_loss: 5.3435 - val_accuracy: 0.0033 - lr: 1.0000e-07\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.7760 - accuracy: 0.0513 - val_loss: 5.3483 - val_accuracy: 0.0033 - lr: 1.0000e-07\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 5.3778 - accuracy: 0.0250 - val_loss: 5.3520 - val_accuracy: 0.0033 - lr: 1.0000e-07\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.8142 - accuracy: 0.0500 - val_loss: 5.3566 - val_accuracy: 0.0033 - lr: 1.0000e-07\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.8191 - accuracy: 0.0250 - val_loss: 5.3606 - val_accuracy: 0.0033 - lr: 1.0000e-07\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.5258 - accuracy: 0.0750 - val_loss: 5.3643 - val_accuracy: 0.0033 - lr: 1.0000e-08\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 6.2583 - accuracy: 0.0250 - val_loss: 5.3684 - val_accuracy: 0.0033 - lr: 1.0000e-08\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 5.2145 - accuracy: 0.0750 - val_loss: 5.3730 - val_accuracy: 0.0033 - lr: 1.0000e-08\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 5.4839 - accuracy: 0.0250 - val_loss: 5.3773 - val_accuracy: 0.0000e+00 - lr: 1.0000e-08\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 6.2115 - accuracy: 0.0000e+00 - val_loss: 5.3827 - val_accuracy: 0.0033 - lr: 1.0000e-08\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 6.1095 - accuracy: 0.0513 - val_loss: 5.3869 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 6.0894 - accuracy: 0.0250 - val_loss: 5.3897 - val_accuracy: 0.0033 - lr: 1.0000e-09\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 6.4256 - accuracy: 0.0000e+00 - val_loss: 5.3940 - val_accuracy: 0.0033 - lr: 1.0000e-09\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 5.3040 - accuracy: 0.0500 - val_loss: 5.3969 - val_accuracy: 0.0033 - lr: 1.0000e-09\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 5.5059 - accuracy: 0.0000e+00 - val_loss: 5.4009 - val_accuracy: 0.0033 - lr: 1.0000e-09\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 5.2638 - accuracy: 0.0750 - val_loss: 5.4054 - val_accuracy: 0.0033 - lr: 1.0000e-10\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 5.1889 - accuracy: 0.0500 - val_loss: 5.4087 - val_accuracy: 0.0033 - lr: 1.0000e-10\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 5.7299 - accuracy: 0.0750 - val_loss: 5.4128 - val_accuracy: 0.0033 - lr: 1.0000e-10\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 5.7541 - accuracy: 0.0000e+00 - val_loss: 5.4165 - val_accuracy: 0.0033 - lr: 1.0000e-10\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 6.2307 - accuracy: 0.0000e+00 - val_loss: 5.4193 - val_accuracy: 0.0033 - lr: 1.0000e-10\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 5.3960 - accuracy: 0.0500 - val_loss: 5.4229 - val_accuracy: 0.0033 - lr: 5.0000e-11\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.6510 - accuracy: 0.0750 - val_loss: 5.4263 - val_accuracy: 0.0033 - lr: 5.0000e-11\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 6.0275 - accuracy: 0.0750 - val_loss: 5.4284 - val_accuracy: 0.0033 - lr: 5.0000e-11\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 5.8885 - accuracy: 0.0750 - val_loss: 5.4313 - val_accuracy: 0.0033 - lr: 5.0000e-11\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 5.8622 - accuracy: 0.0250 - val_loss: 5.4339 - val_accuracy: 0.0033 - lr: 5.0000e-11\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 5.8563 - accuracy: 0.0250 - val_loss: 5.4374 - val_accuracy: 0.0033 - lr: 5.0000e-11\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 6.1708 - accuracy: 0.0250 - val_loss: 5.4393 - val_accuracy: 0.0033 - lr: 5.0000e-11\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 5.2656 - accuracy: 0.0750 - val_loss: 5.4423 - val_accuracy: 0.0033 - lr: 5.0000e-11\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.3660 - accuracy: 0.0000e+00 - val_loss: 5.4451 - val_accuracy: 0.0033 - lr: 5.0000e-11\n",
            "#3\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 650ms/step - loss: 6.6711 - accuracy: 0.0256 - val_loss: 5.3368 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.6584 - accuracy: 0.0500 - val_loss: 5.2366 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.8074 - accuracy: 0.0250 - val_loss: 5.1703 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 5.9516 - accuracy: 0.0750 - val_loss: 5.1041 - val_accuracy: 0.0528 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 5.3298 - accuracy: 0.0250 - val_loss: 5.0381 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 5.5025 - accuracy: 0.1250 - val_loss: 4.9733 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 4.9738 - accuracy: 0.1000 - val_loss: 4.9053 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 5.8486 - accuracy: 0.0256 - val_loss: 4.8288 - val_accuracy: 0.0594 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 5.3346 - accuracy: 0.1500 - val_loss: 4.7616 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 4.1506 - accuracy: 0.2000 - val_loss: 4.7023 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 4.4863 - accuracy: 0.1250 - val_loss: 4.6399 - val_accuracy: 0.0726 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 4.0516 - accuracy: 0.1750 - val_loss: 4.5837 - val_accuracy: 0.0825 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 4.1859 - accuracy: 0.1500 - val_loss: 4.5256 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 3.4166 - accuracy: 0.3590 - val_loss: 4.4894 - val_accuracy: 0.0891 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 3.7850 - accuracy: 0.2500 - val_loss: 4.4448 - val_accuracy: 0.0957 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 3.5799 - accuracy: 0.3000 - val_loss: 4.3879 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 3.4464 - accuracy: 0.1750 - val_loss: 4.3204 - val_accuracy: 0.1221 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 3.0894 - accuracy: 0.3500 - val_loss: 4.2615 - val_accuracy: 0.1287 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 2.9172 - accuracy: 0.2500 - val_loss: 4.2266 - val_accuracy: 0.1287 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 3.0153 - accuracy: 0.2821 - val_loss: 4.1777 - val_accuracy: 0.1287 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 2.6215 - accuracy: 0.3000 - val_loss: 4.1523 - val_accuracy: 0.1320 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 2.4532 - accuracy: 0.4615 - val_loss: 4.1145 - val_accuracy: 0.1320 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 2.5786 - accuracy: 0.3750 - val_loss: 4.0831 - val_accuracy: 0.1320 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 2.6032 - accuracy: 0.2750 - val_loss: 4.0651 - val_accuracy: 0.1452 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 2.7124 - accuracy: 0.4000 - val_loss: 4.0287 - val_accuracy: 0.1452 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.9452 - accuracy: 0.6250 - val_loss: 4.0009 - val_accuracy: 0.1551 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.9540 - accuracy: 0.5750 - val_loss: 3.9759 - val_accuracy: 0.1584 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 2.0388 - accuracy: 0.5641 - val_loss: 3.9545 - val_accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 2.4367 - accuracy: 0.4500 - val_loss: 3.9305 - val_accuracy: 0.1650 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.9262 - accuracy: 0.5500 - val_loss: 3.9153 - val_accuracy: 0.1683 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 2.1423 - accuracy: 0.5000 - val_loss: 3.8945 - val_accuracy: 0.1815 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.8646 - accuracy: 0.5750 - val_loss: 3.8622 - val_accuracy: 0.1848 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.4067 - accuracy: 0.6500 - val_loss: 3.8359 - val_accuracy: 0.1815 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.5844 - accuracy: 0.6154 - val_loss: 3.8198 - val_accuracy: 0.1980 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.7540 - accuracy: 0.5250 - val_loss: 3.7998 - val_accuracy: 0.2046 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.1411 - accuracy: 0.7750 - val_loss: 3.7748 - val_accuracy: 0.1980 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 1.6931 - accuracy: 0.6250 - val_loss: 3.7451 - val_accuracy: 0.2112 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.6376 - accuracy: 0.5750 - val_loss: 3.7196 - val_accuracy: 0.2178 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.4912 - accuracy: 0.6500 - val_loss: 3.7067 - val_accuracy: 0.2079 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.4476 - accuracy: 0.5250 - val_loss: 3.6789 - val_accuracy: 0.2079 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.1676 - accuracy: 0.7000 - val_loss: 3.6679 - val_accuracy: 0.2112 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 2.0037 - accuracy: 0.5897 - val_loss: 3.6570 - val_accuracy: 0.2079 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.5919 - accuracy: 0.6667 - val_loss: 3.6358 - val_accuracy: 0.2145 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.0203 - accuracy: 0.7750 - val_loss: 3.6336 - val_accuracy: 0.2112 - lr: 1.0000e-04\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.2396 - accuracy: 0.6923 - val_loss: 3.6301 - val_accuracy: 0.2112 - lr: 1.0000e-04\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.4703 - accuracy: 0.6250 - val_loss: 3.6281 - val_accuracy: 0.2112 - lr: 1.0000e-04\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.7782 - accuracy: 0.8250 - val_loss: 3.6257 - val_accuracy: 0.2112 - lr: 1.0000e-04\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 1.1850 - accuracy: 0.7250 - val_loss: 3.6233 - val_accuracy: 0.2079 - lr: 1.0000e-04\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.8130 - accuracy: 0.8500 - val_loss: 3.6227 - val_accuracy: 0.2079 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 1.4512 - accuracy: 0.7250 - val_loss: 3.6213 - val_accuracy: 0.2079 - lr: 1.0000e-05\n",
            "#4\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 760ms/step - loss: 7.0705 - accuracy: 0.0000e+00 - val_loss: 12.1298 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 5.9094 - accuracy: 0.0250 - val_loss: 9.9990 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.9032 - accuracy: 0.0500 - val_loss: 8.7097 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 5.2961 - accuracy: 0.1000 - val_loss: 7.9315 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 5.5660 - accuracy: 0.0250 - val_loss: 7.3948 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 5.3449 - accuracy: 0.1000 - val_loss: 6.8485 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 4.7987 - accuracy: 0.1250 - val_loss: 6.4930 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 4.4895 - accuracy: 0.1500 - val_loss: 6.1810 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 4.4202 - accuracy: 0.1026 - val_loss: 5.8546 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 3.6589 - accuracy: 0.2250 - val_loss: 5.5554 - val_accuracy: 0.0528 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 4.3661 - accuracy: 0.2051 - val_loss: 5.3734 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 3.9945 - accuracy: 0.1795 - val_loss: 5.1921 - val_accuracy: 0.0825 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 4.0287 - accuracy: 0.1250 - val_loss: 4.9995 - val_accuracy: 0.1056 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 3.5595 - accuracy: 0.2250 - val_loss: 4.8324 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 3.3709 - accuracy: 0.2500 - val_loss: 4.6861 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 2.3501 - accuracy: 0.5128 - val_loss: 4.5653 - val_accuracy: 0.1353 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 3.2164 - accuracy: 0.3250 - val_loss: 4.4649 - val_accuracy: 0.1452 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 3.2984 - accuracy: 0.3500 - val_loss: 4.3804 - val_accuracy: 0.1683 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 3.0599 - accuracy: 0.3000 - val_loss: 4.2888 - val_accuracy: 0.1749 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 2.6959 - accuracy: 0.4000 - val_loss: 4.2055 - val_accuracy: 0.1848 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 3.1730 - accuracy: 0.3750 - val_loss: 4.1098 - val_accuracy: 0.1980 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 2.6756 - accuracy: 0.4500 - val_loss: 4.0245 - val_accuracy: 0.1947 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 2.1235 - accuracy: 0.5000 - val_loss: 3.9525 - val_accuracy: 0.2046 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 2.1157 - accuracy: 0.5250 - val_loss: 3.8812 - val_accuracy: 0.2145 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 2.1514 - accuracy: 0.4000 - val_loss: 3.8121 - val_accuracy: 0.2277 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 2.0500 - accuracy: 0.5500 - val_loss: 3.7563 - val_accuracy: 0.2310 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 2.0903 - accuracy: 0.5000 - val_loss: 3.7131 - val_accuracy: 0.2409 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.9131 - accuracy: 0.5250 - val_loss: 3.6686 - val_accuracy: 0.2376 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.5944 - accuracy: 0.6500 - val_loss: 3.6204 - val_accuracy: 0.2475 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.7345 - accuracy: 0.6500 - val_loss: 3.5875 - val_accuracy: 0.2541 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.9204 - accuracy: 0.6000 - val_loss: 3.5513 - val_accuracy: 0.2541 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.3138 - accuracy: 0.6250 - val_loss: 3.5180 - val_accuracy: 0.2706 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.9928 - accuracy: 0.5500 - val_loss: 3.4817 - val_accuracy: 0.2706 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.5937 - accuracy: 0.6500 - val_loss: 3.4503 - val_accuracy: 0.2772 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.6781 - accuracy: 0.6250 - val_loss: 3.4202 - val_accuracy: 0.2937 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.5724 - accuracy: 0.5385 - val_loss: 3.3863 - val_accuracy: 0.3036 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.6766 - accuracy: 0.6667 - val_loss: 3.3595 - val_accuracy: 0.3135 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.5111 - accuracy: 0.6500 - val_loss: 3.3418 - val_accuracy: 0.3201 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.6270 - accuracy: 0.6667 - val_loss: 3.3143 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 1.7162 - accuracy: 0.6000 - val_loss: 3.2935 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.1221 - accuracy: 0.7500 - val_loss: 3.2743 - val_accuracy: 0.3465 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.0616 - accuracy: 0.8500 - val_loss: 3.2540 - val_accuracy: 0.3498 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 1.3834 - accuracy: 0.6667 - val_loss: 3.2346 - val_accuracy: 0.3498 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 1.2944 - accuracy: 0.7750 - val_loss: 3.2203 - val_accuracy: 0.3465 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 1.4709 - accuracy: 0.7000 - val_loss: 3.1896 - val_accuracy: 0.3465 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 1.0027 - accuracy: 0.8000 - val_loss: 3.1662 - val_accuracy: 0.3564 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 1.1107 - accuracy: 0.7750 - val_loss: 3.1485 - val_accuracy: 0.3630 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.8135 - accuracy: 0.9000 - val_loss: 3.1264 - val_accuracy: 0.3630 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.9504 - accuracy: 0.7750 - val_loss: 3.1101 - val_accuracy: 0.3630 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 1.1007 - accuracy: 0.7500 - val_loss: 3.0943 - val_accuracy: 0.3597 - lr: 0.0010\n",
            "#5\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 663ms/step - loss: 6.0839 - accuracy: 0.0000e+00 - val_loss: 11.6822 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 5.2580 - accuracy: 0.1026 - val_loss: 10.3591 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.9374 - accuracy: 0.0000e+00 - val_loss: 9.0867 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 5.0993 - accuracy: 0.1250 - val_loss: 8.3497 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.4726 - accuracy: 0.0513 - val_loss: 7.9265 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.5799 - accuracy: 0.0500 - val_loss: 7.5531 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 5.1943 - accuracy: 0.0000e+00 - val_loss: 7.0856 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 5.0756 - accuracy: 0.0250 - val_loss: 6.6227 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 4.7174 - accuracy: 0.0000e+00 - val_loss: 6.3928 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 4.3078 - accuracy: 0.0513 - val_loss: 6.1349 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 4.3718 - accuracy: 0.0250 - val_loss: 5.9632 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 4.4453 - accuracy: 0.0750 - val_loss: 5.7893 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 4.4863 - accuracy: 0.1000 - val_loss: 5.6330 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 4.2765 - accuracy: 0.1250 - val_loss: 5.5072 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 3.6173 - accuracy: 0.1250 - val_loss: 5.4351 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 4.4655 - accuracy: 0.1000 - val_loss: 5.3693 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 3.9393 - accuracy: 0.1500 - val_loss: 5.3106 - val_accuracy: 0.0264 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 4.0360 - accuracy: 0.2000 - val_loss: 5.2670 - val_accuracy: 0.0297 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 3.9928 - accuracy: 0.0750 - val_loss: 5.2227 - val_accuracy: 0.0297 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 3.6432 - accuracy: 0.1795 - val_loss: 5.1851 - val_accuracy: 0.0297 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.0248 - accuracy: 0.1000 - val_loss: 5.1549 - val_accuracy: 0.0330 - lr: 1.0000e-04\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 3.9971 - accuracy: 0.1250 - val_loss: 5.1339 - val_accuracy: 0.0330 - lr: 1.0000e-04\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.2467 - accuracy: 0.1000 - val_loss: 5.1115 - val_accuracy: 0.0330 - lr: 1.0000e-04\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 3.8548 - accuracy: 0.2250 - val_loss: 5.0882 - val_accuracy: 0.0330 - lr: 1.0000e-04\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.0066 - accuracy: 0.1000 - val_loss: 5.0656 - val_accuracy: 0.0330 - lr: 1.0000e-04\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 3.7472 - accuracy: 0.1750 - val_loss: 5.0350 - val_accuracy: 0.0330 - lr: 1.0000e-04\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.1090 - accuracy: 0.1500 - val_loss: 5.0235 - val_accuracy: 0.0330 - lr: 1.0000e-05\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 3.8540 - accuracy: 0.1500 - val_loss: 5.0095 - val_accuracy: 0.0330 - lr: 1.0000e-05\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 3.9594 - accuracy: 0.1250 - val_loss: 4.9903 - val_accuracy: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 3.7526 - accuracy: 0.1500 - val_loss: 4.9739 - val_accuracy: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 3.5774 - accuracy: 0.2500 - val_loss: 4.9585 - val_accuracy: 0.0330 - lr: 1.0000e-05\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 3.7191 - accuracy: 0.1282 - val_loss: 4.9479 - val_accuracy: 0.0330 - lr: 1.0000e-05\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 3.7644 - accuracy: 0.1795 - val_loss: 4.9364 - val_accuracy: 0.0330 - lr: 1.0000e-05\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.5047 - accuracy: 0.1250 - val_loss: 4.9331 - val_accuracy: 0.0297 - lr: 1.0000e-05\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 3.8606 - accuracy: 0.1500 - val_loss: 4.9258 - val_accuracy: 0.0297 - lr: 1.0000e-06\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.2776 - accuracy: 0.0500 - val_loss: 4.9219 - val_accuracy: 0.0330 - lr: 1.0000e-06\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 4.2102 - accuracy: 0.2000 - val_loss: 4.9074 - val_accuracy: 0.0297 - lr: 1.0000e-06\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 3.8276 - accuracy: 0.1250 - val_loss: 4.9045 - val_accuracy: 0.0297 - lr: 1.0000e-06\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 4.4808 - accuracy: 0.0500 - val_loss: 4.8998 - val_accuracy: 0.0264 - lr: 1.0000e-06\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 3.7733 - accuracy: 0.1500 - val_loss: 4.9025 - val_accuracy: 0.0264 - lr: 1.0000e-07\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 3.9991 - accuracy: 0.1250 - val_loss: 4.8926 - val_accuracy: 0.0264 - lr: 1.0000e-07\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 3.3721 - accuracy: 0.2564 - val_loss: 4.8944 - val_accuracy: 0.0264 - lr: 1.0000e-07\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 3.9202 - accuracy: 0.2250 - val_loss: 4.8938 - val_accuracy: 0.0264 - lr: 1.0000e-07\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 3.9170 - accuracy: 0.0500 - val_loss: 4.8870 - val_accuracy: 0.0264 - lr: 1.0000e-07\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 3.8792 - accuracy: 0.2000 - val_loss: 4.8846 - val_accuracy: 0.0264 - lr: 1.0000e-08\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.1202 - accuracy: 0.1282 - val_loss: 4.8768 - val_accuracy: 0.0264 - lr: 1.0000e-08\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 4.2108 - accuracy: 0.1000 - val_loss: 4.8733 - val_accuracy: 0.0297 - lr: 1.0000e-08\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 4.1192 - accuracy: 0.0750 - val_loss: 4.8693 - val_accuracy: 0.0297 - lr: 1.0000e-08\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 3.8702 - accuracy: 0.1026 - val_loss: 4.8658 - val_accuracy: 0.0297 - lr: 1.0000e-08\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 3.9189 - accuracy: 0.1250 - val_loss: 4.8675 - val_accuracy: 0.0264 - lr: 1.0000e-09\n",
            "#6\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 644ms/step - loss: 5.9800 - accuracy: 0.0000e+00 - val_loss: 4.9860 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 6.1197 - accuracy: 0.0000e+00 - val_loss: 4.9421 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.6189 - accuracy: 0.0500 - val_loss: 4.8942 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 5.4034 - accuracy: 0.0500 - val_loss: 4.8522 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 4.8574 - accuracy: 0.1250 - val_loss: 4.7987 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 4.3050 - accuracy: 0.1500 - val_loss: 4.7591 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 4.3397 - accuracy: 0.1250 - val_loss: 4.7121 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.0498 - accuracy: 0.1538 - val_loss: 4.6695 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 4.0761 - accuracy: 0.1750 - val_loss: 4.6249 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 3.6831 - accuracy: 0.2250 - val_loss: 4.5933 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 4.2618 - accuracy: 0.2000 - val_loss: 4.5642 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 3.5543 - accuracy: 0.1750 - val_loss: 4.5326 - val_accuracy: 0.0528 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 3.5732 - accuracy: 0.2750 - val_loss: 4.5015 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 3.4962 - accuracy: 0.1750 - val_loss: 4.4705 - val_accuracy: 0.0594 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 3.4926 - accuracy: 0.3000 - val_loss: 4.4389 - val_accuracy: 0.0594 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 2.5616 - accuracy: 0.4000 - val_loss: 4.4142 - val_accuracy: 0.0594 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 3.7726 - accuracy: 0.3000 - val_loss: 4.3762 - val_accuracy: 0.0660 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 2.7149 - accuracy: 0.3000 - val_loss: 4.3440 - val_accuracy: 0.0726 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 2.3970 - accuracy: 0.4750 - val_loss: 4.3158 - val_accuracy: 0.0726 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 2.6456 - accuracy: 0.4000 - val_loss: 4.2933 - val_accuracy: 0.0726 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 2.5970 - accuracy: 0.4500 - val_loss: 4.2651 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 2.0297 - accuracy: 0.6250 - val_loss: 4.2399 - val_accuracy: 0.0891 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 2.5669 - accuracy: 0.4750 - val_loss: 4.2050 - val_accuracy: 0.0957 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 2.3541 - accuracy: 0.3750 - val_loss: 4.1817 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 2.1074 - accuracy: 0.5385 - val_loss: 4.1607 - val_accuracy: 0.1056 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 1.9668 - accuracy: 0.5897 - val_loss: 4.1351 - val_accuracy: 0.1287 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 2.4083 - accuracy: 0.4000 - val_loss: 4.1088 - val_accuracy: 0.1320 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 2.2433 - accuracy: 0.4750 - val_loss: 4.0802 - val_accuracy: 0.1320 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 2.1316 - accuracy: 0.5250 - val_loss: 4.0512 - val_accuracy: 0.1386 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 2.2903 - accuracy: 0.4250 - val_loss: 4.0264 - val_accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.8772 - accuracy: 0.5128 - val_loss: 4.0090 - val_accuracy: 0.1386 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.8769 - accuracy: 0.6000 - val_loss: 3.9879 - val_accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 2.2135 - accuracy: 0.4750 - val_loss: 3.9621 - val_accuracy: 0.1551 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.9081 - accuracy: 0.5000 - val_loss: 3.9450 - val_accuracy: 0.1683 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.7040 - accuracy: 0.7250 - val_loss: 3.9266 - val_accuracy: 0.1650 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.7165 - accuracy: 0.6250 - val_loss: 3.9054 - val_accuracy: 0.1650 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.3574 - accuracy: 0.7000 - val_loss: 3.8878 - val_accuracy: 0.1650 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.6194 - accuracy: 0.6500 - val_loss: 3.8659 - val_accuracy: 0.1716 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.9054 - accuracy: 0.6154 - val_loss: 3.8364 - val_accuracy: 0.1749 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.5551 - accuracy: 0.6500 - val_loss: 3.8216 - val_accuracy: 0.1749 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.4122 - accuracy: 0.6750 - val_loss: 3.8053 - val_accuracy: 0.1782 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.3324 - accuracy: 0.7000 - val_loss: 3.7860 - val_accuracy: 0.1914 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.6874 - accuracy: 0.7500 - val_loss: 3.7687 - val_accuracy: 0.1848 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 1.4701 - accuracy: 0.7000 - val_loss: 3.7504 - val_accuracy: 0.1914 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.5959 - accuracy: 0.5750 - val_loss: 3.7385 - val_accuracy: 0.1914 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 1.1938 - accuracy: 0.8000 - val_loss: 3.7254 - val_accuracy: 0.1881 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.9018 - accuracy: 0.5750 - val_loss: 3.7096 - val_accuracy: 0.1980 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.3145 - accuracy: 0.7179 - val_loss: 3.7001 - val_accuracy: 0.2013 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.3334 - accuracy: 0.7000 - val_loss: 3.6854 - val_accuracy: 0.1980 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.2123 - accuracy: 0.8000 - val_loss: 3.6814 - val_accuracy: 0.1980 - lr: 0.0010\n",
            "#7\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 644ms/step - loss: 5.4776 - accuracy: 0.0750 - val_loss: 4.8813 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 5.3751 - accuracy: 0.0250 - val_loss: 4.8213 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 5.0697 - accuracy: 0.0769 - val_loss: 4.7549 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 4.1266 - accuracy: 0.2500 - val_loss: 4.6965 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.0083 - accuracy: 0.2500 - val_loss: 4.6410 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 3.4219 - accuracy: 0.4103 - val_loss: 4.5942 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 3.5208 - accuracy: 0.3500 - val_loss: 4.5537 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 3.4016 - accuracy: 0.3000 - val_loss: 4.5058 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 3.2089 - accuracy: 0.3750 - val_loss: 4.4566 - val_accuracy: 0.0594 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 2.7624 - accuracy: 0.4250 - val_loss: 4.4067 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 2.7626 - accuracy: 0.5500 - val_loss: 4.3609 - val_accuracy: 0.0726 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 574ms/step - loss: 2.2860 - accuracy: 0.5250 - val_loss: 4.3209 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 1.8866 - accuracy: 0.7692 - val_loss: 4.2810 - val_accuracy: 0.0924 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 2.1355 - accuracy: 0.6667 - val_loss: 4.2410 - val_accuracy: 0.0825 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 574ms/step - loss: 1.6510 - accuracy: 0.7000 - val_loss: 4.1997 - val_accuracy: 0.0957 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 1.8092 - accuracy: 0.7000 - val_loss: 4.1695 - val_accuracy: 0.0924 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 1.5612 - accuracy: 0.7000 - val_loss: 4.1312 - val_accuracy: 0.1056 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 1.4690 - accuracy: 0.7500 - val_loss: 4.1020 - val_accuracy: 0.1023 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 1.5410 - accuracy: 0.7436 - val_loss: 4.0706 - val_accuracy: 0.1089 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 1.5574 - accuracy: 0.7949 - val_loss: 4.0433 - val_accuracy: 0.1089 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 1.2180 - accuracy: 0.8000 - val_loss: 4.0130 - val_accuracy: 0.1155 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 1.0908 - accuracy: 0.8500 - val_loss: 3.9857 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 1.4608 - accuracy: 0.7750 - val_loss: 3.9558 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.9788 - accuracy: 0.9250 - val_loss: 3.9322 - val_accuracy: 0.1287 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.0723 - accuracy: 0.8500 - val_loss: 3.8991 - val_accuracy: 0.1386 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.1261 - accuracy: 0.8500 - val_loss: 3.8663 - val_accuracy: 0.1584 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.8172 - accuracy: 0.9000 - val_loss: 3.8382 - val_accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.2241 - accuracy: 0.8500 - val_loss: 3.8100 - val_accuracy: 0.1617 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.6834 - accuracy: 0.9500 - val_loss: 3.7903 - val_accuracy: 0.1650 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.9558 - accuracy: 0.9000 - val_loss: 3.7661 - val_accuracy: 0.1650 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.6661 - accuracy: 0.9500 - val_loss: 3.7419 - val_accuracy: 0.1716 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.7964 - accuracy: 0.9487 - val_loss: 3.7200 - val_accuracy: 0.1815 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.7678 - accuracy: 0.8750 - val_loss: 3.6975 - val_accuracy: 0.1749 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.5348 - accuracy: 0.9750 - val_loss: 3.6784 - val_accuracy: 0.1749 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.5216 - accuracy: 1.0000 - val_loss: 3.6605 - val_accuracy: 0.1749 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.6013 - accuracy: 0.9500 - val_loss: 3.6395 - val_accuracy: 0.1782 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.3764 - accuracy: 0.9750 - val_loss: 3.6232 - val_accuracy: 0.1848 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.7669 - accuracy: 0.9250 - val_loss: 3.6012 - val_accuracy: 0.1815 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.6338 - accuracy: 0.9250 - val_loss: 3.5851 - val_accuracy: 0.1980 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.6045 - accuracy: 0.9231 - val_loss: 3.5669 - val_accuracy: 0.1947 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.2900 - accuracy: 1.0000 - val_loss: 3.5533 - val_accuracy: 0.1947 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.6866 - accuracy: 0.9231 - val_loss: 3.5366 - val_accuracy: 0.2046 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.3811 - accuracy: 0.9750 - val_loss: 3.5190 - val_accuracy: 0.2046 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.3581 - accuracy: 1.0000 - val_loss: 3.5056 - val_accuracy: 0.2112 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.2600 - accuracy: 1.0000 - val_loss: 3.4922 - val_accuracy: 0.2145 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.2935 - accuracy: 1.0000 - val_loss: 3.4768 - val_accuracy: 0.2145 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.3259 - accuracy: 1.0000 - val_loss: 3.4586 - val_accuracy: 0.2211 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.2898 - accuracy: 1.0000 - val_loss: 3.4477 - val_accuracy: 0.2277 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.2884 - accuracy: 1.0000 - val_loss: 3.4369 - val_accuracy: 0.2343 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.2616 - accuracy: 1.0000 - val_loss: 3.4229 - val_accuracy: 0.2310 - lr: 0.0010\n",
            "#8\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 661ms/step - loss: 5.5210 - accuracy: 0.0250 - val_loss: 5.4112 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 5.2929 - accuracy: 0.0000e+00 - val_loss: 5.3172 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.1474 - accuracy: 0.0500 - val_loss: 5.2343 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.3130 - accuracy: 0.0250 - val_loss: 5.1717 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 4.3787 - accuracy: 0.0750 - val_loss: 5.1214 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 4.3204 - accuracy: 0.1750 - val_loss: 5.0707 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 4.2088 - accuracy: 0.1250 - val_loss: 5.0216 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 4.0491 - accuracy: 0.1750 - val_loss: 4.9652 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 3.4191 - accuracy: 0.3000 - val_loss: 4.9085 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 3.6096 - accuracy: 0.3000 - val_loss: 4.8677 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 3.5009 - accuracy: 0.2750 - val_loss: 4.8229 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 2.5701 - accuracy: 0.4500 - val_loss: 4.7957 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 2.9305 - accuracy: 0.4250 - val_loss: 4.7530 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 2.8864 - accuracy: 0.3500 - val_loss: 4.7193 - val_accuracy: 0.0594 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 2.5084 - accuracy: 0.4750 - val_loss: 4.7061 - val_accuracy: 0.0528 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 2.3277 - accuracy: 0.5500 - val_loss: 4.6577 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 2.2927 - accuracy: 0.5500 - val_loss: 4.6367 - val_accuracy: 0.0726 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 2.2137 - accuracy: 0.6000 - val_loss: 4.6079 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 2.4718 - accuracy: 0.5000 - val_loss: 4.5913 - val_accuracy: 0.0825 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.8866 - accuracy: 0.7250 - val_loss: 4.5592 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 2.0576 - accuracy: 0.6250 - val_loss: 4.5215 - val_accuracy: 0.0924 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 2.0952 - accuracy: 0.6154 - val_loss: 4.4842 - val_accuracy: 0.0957 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.7823 - accuracy: 0.7250 - val_loss: 4.4447 - val_accuracy: 0.1023 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.7773 - accuracy: 0.7500 - val_loss: 4.4229 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.9394 - accuracy: 0.6750 - val_loss: 4.4002 - val_accuracy: 0.1023 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.7321 - accuracy: 0.7500 - val_loss: 4.3763 - val_accuracy: 0.1056 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.7421 - accuracy: 0.7000 - val_loss: 4.3565 - val_accuracy: 0.1122 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.7257 - accuracy: 0.7250 - val_loss: 4.3393 - val_accuracy: 0.1089 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.6694 - accuracy: 0.7750 - val_loss: 4.3316 - val_accuracy: 0.1056 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.8698 - accuracy: 0.6750 - val_loss: 4.3173 - val_accuracy: 0.1155 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.7132 - accuracy: 0.7750 - val_loss: 4.3034 - val_accuracy: 0.1089 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.2218 - accuracy: 0.8500 - val_loss: 4.2838 - val_accuracy: 0.1155 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.2323 - accuracy: 0.8750 - val_loss: 4.2709 - val_accuracy: 0.1221 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 1.2822 - accuracy: 0.9500 - val_loss: 4.2589 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.4369 - accuracy: 0.8250 - val_loss: 4.2438 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.5197 - accuracy: 0.7500 - val_loss: 4.2297 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.5215 - accuracy: 0.7949 - val_loss: 4.2091 - val_accuracy: 0.1155 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.2900 - accuracy: 0.8718 - val_loss: 4.1971 - val_accuracy: 0.1221 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.0188 - accuracy: 0.9250 - val_loss: 4.1954 - val_accuracy: 0.1221 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.1492 - accuracy: 0.8750 - val_loss: 4.1932 - val_accuracy: 0.1188 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.1618 - accuracy: 0.8500 - val_loss: 4.1917 - val_accuracy: 0.1221 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.3703 - accuracy: 0.8462 - val_loss: 4.1891 - val_accuracy: 0.1188 - lr: 1.0000e-04\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.0141 - accuracy: 0.8974 - val_loss: 4.1885 - val_accuracy: 0.1221 - lr: 1.0000e-04\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.8968 - accuracy: 0.9000 - val_loss: 4.1890 - val_accuracy: 0.1221 - lr: 1.0000e-05\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.4165 - accuracy: 0.7000 - val_loss: 4.1888 - val_accuracy: 0.1122 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.0743 - accuracy: 0.9250 - val_loss: 4.1891 - val_accuracy: 0.1155 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.1109 - accuracy: 0.9250 - val_loss: 4.1890 - val_accuracy: 0.1155 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.2939 - accuracy: 0.8250 - val_loss: 4.1889 - val_accuracy: 0.1155 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.2988 - accuracy: 0.9231 - val_loss: 4.1883 - val_accuracy: 0.1155 - lr: 1.0000e-06\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.0325 - accuracy: 0.9250 - val_loss: 4.1890 - val_accuracy: 0.1155 - lr: 1.0000e-06\n",
            "#9\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 644ms/step - loss: 6.9036 - accuracy: 0.0250 - val_loss: 5.4083 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 7.2102 - accuracy: 0.0256 - val_loss: 5.3405 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 6.9010 - accuracy: 0.0000e+00 - val_loss: 5.2894 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 5.9591 - accuracy: 0.0769 - val_loss: 5.2654 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 6.3729 - accuracy: 0.0500 - val_loss: 5.2463 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 6.0833 - accuracy: 0.0250 - val_loss: 5.1821 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 6.6734 - accuracy: 0.0250 - val_loss: 5.1334 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 5.6452 - accuracy: 0.0250 - val_loss: 5.0764 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 5.6719 - accuracy: 0.0500 - val_loss: 5.0720 - val_accuracy: 0.0231 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 5.0566 - accuracy: 0.0750 - val_loss: 5.0654 - val_accuracy: 0.0264 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 6.1123 - accuracy: 0.0500 - val_loss: 5.0603 - val_accuracy: 0.0264 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 5.1585 - accuracy: 0.0500 - val_loss: 5.0563 - val_accuracy: 0.0231 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 5.3524 - accuracy: 0.0250 - val_loss: 5.0538 - val_accuracy: 0.0264 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 5.4846 - accuracy: 0.0500 - val_loss: 5.0530 - val_accuracy: 0.0264 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 5.6378 - accuracy: 0.0250 - val_loss: 5.0501 - val_accuracy: 0.0198 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 5.5634 - accuracy: 0.0250 - val_loss: 5.0513 - val_accuracy: 0.0198 - lr: 1.0000e-05\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 5.6484 - accuracy: 0.0750 - val_loss: 5.0534 - val_accuracy: 0.0231 - lr: 1.0000e-05\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 5.3239 - accuracy: 0.1000 - val_loss: 5.0545 - val_accuracy: 0.0198 - lr: 1.0000e-05\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 5.3126 - accuracy: 0.0513 - val_loss: 5.0548 - val_accuracy: 0.0198 - lr: 1.0000e-05\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 5.4888 - accuracy: 0.0250 - val_loss: 5.0557 - val_accuracy: 0.0198 - lr: 1.0000e-05\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 5.7471 - accuracy: 0.0500 - val_loss: 5.0568 - val_accuracy: 0.0198 - lr: 1.0000e-06\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 5.5191 - accuracy: 0.0256 - val_loss: 5.0582 - val_accuracy: 0.0198 - lr: 1.0000e-06\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 5.2615 - accuracy: 0.0750 - val_loss: 5.0602 - val_accuracy: 0.0198 - lr: 1.0000e-06\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 5.5169 - accuracy: 0.0500 - val_loss: 5.0614 - val_accuracy: 0.0198 - lr: 1.0000e-06\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 4.9288 - accuracy: 0.0500 - val_loss: 5.0643 - val_accuracy: 0.0231 - lr: 1.0000e-06\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.9306 - accuracy: 0.1000 - val_loss: 5.0669 - val_accuracy: 0.0231 - lr: 1.0000e-07\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 5.3767 - accuracy: 0.0500 - val_loss: 5.0700 - val_accuracy: 0.0297 - lr: 1.0000e-07\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 5.4593 - accuracy: 0.1026 - val_loss: 5.0727 - val_accuracy: 0.0297 - lr: 1.0000e-07\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 5.1379 - accuracy: 0.0500 - val_loss: 5.0756 - val_accuracy: 0.0297 - lr: 1.0000e-07\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.8168 - accuracy: 0.0500 - val_loss: 5.0782 - val_accuracy: 0.0297 - lr: 1.0000e-07\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 5.8581 - accuracy: 0.0250 - val_loss: 5.0810 - val_accuracy: 0.0297 - lr: 1.0000e-07\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 5.7549 - accuracy: 0.0250 - val_loss: 5.0839 - val_accuracy: 0.0297 - lr: 1.0000e-07\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 5.9818 - accuracy: 0.0513 - val_loss: 5.0863 - val_accuracy: 0.0297 - lr: 1.0000e-08\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 5.7163 - accuracy: 0.0000e+00 - val_loss: 5.0897 - val_accuracy: 0.0297 - lr: 1.0000e-08\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.1574 - accuracy: 0.1750 - val_loss: 5.0925 - val_accuracy: 0.0297 - lr: 1.0000e-08\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 6.2816 - accuracy: 0.0250 - val_loss: 5.0957 - val_accuracy: 0.0297 - lr: 1.0000e-08\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 4.7142 - accuracy: 0.1000 - val_loss: 5.0982 - val_accuracy: 0.0264 - lr: 1.0000e-08\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 5.2529 - accuracy: 0.0000e+00 - val_loss: 5.1006 - val_accuracy: 0.0297 - lr: 1.0000e-09\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 5.4115 - accuracy: 0.1000 - val_loss: 5.1026 - val_accuracy: 0.0264 - lr: 1.0000e-09\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 5.1620 - accuracy: 0.0500 - val_loss: 5.1053 - val_accuracy: 0.0297 - lr: 1.0000e-09\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 5.1679 - accuracy: 0.0769 - val_loss: 5.1090 - val_accuracy: 0.0297 - lr: 1.0000e-09\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 5.2664 - accuracy: 0.0256 - val_loss: 5.1122 - val_accuracy: 0.0264 - lr: 1.0000e-09\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.9257 - accuracy: 0.0250 - val_loss: 5.1151 - val_accuracy: 0.0264 - lr: 1.0000e-10\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.5625 - accuracy: 0.0250 - val_loss: 5.1185 - val_accuracy: 0.0231 - lr: 1.0000e-10\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 5.2891 - accuracy: 0.0500 - val_loss: 5.1204 - val_accuracy: 0.0231 - lr: 1.0000e-10\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 5.3206 - accuracy: 0.1000 - val_loss: 5.1225 - val_accuracy: 0.0231 - lr: 1.0000e-10\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.7770 - accuracy: 0.0750 - val_loss: 5.1244 - val_accuracy: 0.0231 - lr: 1.0000e-10\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 6.2775 - accuracy: 0.0250 - val_loss: 5.1269 - val_accuracy: 0.0264 - lr: 5.0000e-11\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.9660 - accuracy: 0.1250 - val_loss: 5.1285 - val_accuracy: 0.0330 - lr: 5.0000e-11\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 4.9055 - accuracy: 0.1250 - val_loss: 5.1302 - val_accuracy: 0.0297 - lr: 5.0000e-11\n",
            "#10\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 640ms/step - loss: 6.2743 - accuracy: 0.0000e+00 - val_loss: 11.7446 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 5.4240 - accuracy: 0.0000e+00 - val_loss: 9.9401 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.2477 - accuracy: 0.0250 - val_loss: 8.7206 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 4.8599 - accuracy: 0.0256 - val_loss: 8.0244 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 5.0939 - accuracy: 0.0513 - val_loss: 7.5432 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.9394 - accuracy: 0.0750 - val_loss: 7.1010 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 4.4767 - accuracy: 0.1250 - val_loss: 6.6332 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 4.5379 - accuracy: 0.0250 - val_loss: 6.3921 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 4.0821 - accuracy: 0.0750 - val_loss: 6.0540 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 4.0016 - accuracy: 0.1282 - val_loss: 5.8163 - val_accuracy: 0.0528 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 4.2138 - accuracy: 0.0750 - val_loss: 5.5948 - val_accuracy: 0.0594 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 4.4039 - accuracy: 0.1000 - val_loss: 5.4308 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 3.9149 - accuracy: 0.2051 - val_loss: 5.2913 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 3.9058 - accuracy: 0.2000 - val_loss: 5.1563 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 3.3967 - accuracy: 0.2000 - val_loss: 5.0309 - val_accuracy: 0.0825 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 3.8146 - accuracy: 0.1250 - val_loss: 4.9281 - val_accuracy: 0.0891 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 3.4790 - accuracy: 0.2500 - val_loss: 4.8460 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 3.5435 - accuracy: 0.2750 - val_loss: 4.7492 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 3.1535 - accuracy: 0.4250 - val_loss: 4.6710 - val_accuracy: 0.1056 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 3.1163 - accuracy: 0.2750 - val_loss: 4.5918 - val_accuracy: 0.1023 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 3.3567 - accuracy: 0.1500 - val_loss: 4.5249 - val_accuracy: 0.1089 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 2.9800 - accuracy: 0.3250 - val_loss: 4.4738 - val_accuracy: 0.1155 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 3.1026 - accuracy: 0.2500 - val_loss: 4.4142 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 3.1345 - accuracy: 0.2750 - val_loss: 4.3852 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 2.9206 - accuracy: 0.3250 - val_loss: 4.3493 - val_accuracy: 0.1155 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 2.9950 - accuracy: 0.3750 - val_loss: 4.3101 - val_accuracy: 0.1155 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 3.2134 - accuracy: 0.3000 - val_loss: 4.2606 - val_accuracy: 0.1221 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 2.7332 - accuracy: 0.3750 - val_loss: 4.2150 - val_accuracy: 0.1320 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 2.8799 - accuracy: 0.3250 - val_loss: 4.1882 - val_accuracy: 0.1419 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 2.3641 - accuracy: 0.5000 - val_loss: 4.1587 - val_accuracy: 0.1452 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 2.7012 - accuracy: 0.3000 - val_loss: 4.1276 - val_accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 2.6017 - accuracy: 0.4750 - val_loss: 4.0938 - val_accuracy: 0.1518 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 2.4701 - accuracy: 0.4500 - val_loss: 4.0630 - val_accuracy: 0.1452 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 2.3360 - accuracy: 0.5250 - val_loss: 4.0396 - val_accuracy: 0.1518 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 2.5444 - accuracy: 0.4250 - val_loss: 4.0179 - val_accuracy: 0.1551 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 2.7901 - accuracy: 0.3750 - val_loss: 3.9944 - val_accuracy: 0.1551 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 2.5999 - accuracy: 0.4359 - val_loss: 3.9701 - val_accuracy: 0.1551 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 2.5098 - accuracy: 0.3250 - val_loss: 3.9525 - val_accuracy: 0.1584 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 2.3118 - accuracy: 0.5750 - val_loss: 3.9348 - val_accuracy: 0.1650 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 2.0890 - accuracy: 0.5500 - val_loss: 3.9236 - val_accuracy: 0.1716 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 2.3119 - accuracy: 0.4500 - val_loss: 3.9064 - val_accuracy: 0.1683 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 2.3732 - accuracy: 0.4500 - val_loss: 3.8914 - val_accuracy: 0.1749 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.9877 - accuracy: 0.6500 - val_loss: 3.8728 - val_accuracy: 0.1749 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 2.2356 - accuracy: 0.5000 - val_loss: 3.8614 - val_accuracy: 0.1848 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.9077 - accuracy: 0.6667 - val_loss: 3.8408 - val_accuracy: 0.1848 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 2.0229 - accuracy: 0.5750 - val_loss: 3.8223 - val_accuracy: 0.1881 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 2.1689 - accuracy: 0.5500 - val_loss: 3.8085 - val_accuracy: 0.1947 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.8297 - accuracy: 0.6667 - val_loss: 3.7961 - val_accuracy: 0.1914 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.8649 - accuracy: 0.5750 - val_loss: 3.7828 - val_accuracy: 0.1914 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 2.2547 - accuracy: 0.4500 - val_loss: 3.7728 - val_accuracy: 0.1914 - lr: 0.0010\n",
            "#11\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 650ms/step - loss: 6.2876 - accuracy: 0.0250 - val_loss: 4.9451 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 6.0390 - accuracy: 0.0000e+00 - val_loss: 4.8810 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.0950 - accuracy: 0.1000 - val_loss: 4.8210 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.9136 - accuracy: 0.0256 - val_loss: 4.7552 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.1169 - accuracy: 0.1500 - val_loss: 4.6870 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.4386 - accuracy: 0.1000 - val_loss: 4.6215 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 4.2332 - accuracy: 0.2000 - val_loss: 4.5650 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 3.6894 - accuracy: 0.3846 - val_loss: 4.5054 - val_accuracy: 0.0528 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 3.3558 - accuracy: 0.3250 - val_loss: 4.4536 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 2.8607 - accuracy: 0.4250 - val_loss: 4.4064 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 3.1090 - accuracy: 0.3000 - val_loss: 4.3431 - val_accuracy: 0.0759 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 2.3072 - accuracy: 0.5500 - val_loss: 4.2917 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 3.3471 - accuracy: 0.3000 - val_loss: 4.2432 - val_accuracy: 0.0957 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 2.3544 - accuracy: 0.4500 - val_loss: 4.1885 - val_accuracy: 0.1089 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 2.3056 - accuracy: 0.4500 - val_loss: 4.1486 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 2.1861 - accuracy: 0.5250 - val_loss: 4.1046 - val_accuracy: 0.1221 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 1.9229 - accuracy: 0.6250 - val_loss: 4.0697 - val_accuracy: 0.1320 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 2.0271 - accuracy: 0.5500 - val_loss: 4.0267 - val_accuracy: 0.1320 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 1.4998 - accuracy: 0.6750 - val_loss: 3.9843 - val_accuracy: 0.1353 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.6476 - accuracy: 0.6500 - val_loss: 3.9370 - val_accuracy: 0.1584 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 1.7203 - accuracy: 0.7000 - val_loss: 3.8990 - val_accuracy: 0.1551 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 1.8018 - accuracy: 0.6750 - val_loss: 3.8475 - val_accuracy: 0.1716 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 1.8499 - accuracy: 0.6000 - val_loss: 3.8084 - val_accuracy: 0.1782 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.7681 - accuracy: 0.9250 - val_loss: 3.7749 - val_accuracy: 0.1881 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.2400 - accuracy: 0.7500 - val_loss: 3.7373 - val_accuracy: 0.1947 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.2081 - accuracy: 0.7250 - val_loss: 3.6979 - val_accuracy: 0.1980 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.9435 - accuracy: 0.8250 - val_loss: 3.6680 - val_accuracy: 0.2112 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.8253 - accuracy: 0.8250 - val_loss: 3.6364 - val_accuracy: 0.2211 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.1268 - accuracy: 0.7750 - val_loss: 3.6025 - val_accuracy: 0.2409 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.7306 - accuracy: 0.8750 - val_loss: 3.5741 - val_accuracy: 0.2442 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.0681 - accuracy: 0.7500 - val_loss: 3.5446 - val_accuracy: 0.2409 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.9149 - accuracy: 0.8500 - val_loss: 3.5148 - val_accuracy: 0.2475 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.8659 - accuracy: 0.8250 - val_loss: 3.4896 - val_accuracy: 0.2541 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.8728 - accuracy: 0.8500 - val_loss: 3.4537 - val_accuracy: 0.2739 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.7108 - accuracy: 0.8750 - val_loss: 3.4298 - val_accuracy: 0.2805 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.8962 - accuracy: 0.8750 - val_loss: 3.4025 - val_accuracy: 0.2805 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.5325 - accuracy: 0.9487 - val_loss: 3.3787 - val_accuracy: 0.2904 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.6479 - accuracy: 0.8750 - val_loss: 3.3482 - val_accuracy: 0.2970 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.6543 - accuracy: 0.8500 - val_loss: 3.3221 - val_accuracy: 0.3003 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.5234 - accuracy: 0.9487 - val_loss: 3.2988 - val_accuracy: 0.3135 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.6378 - accuracy: 0.8750 - val_loss: 3.2820 - val_accuracy: 0.3036 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.4924 - accuracy: 0.9250 - val_loss: 3.2602 - val_accuracy: 0.3069 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 0.4186 - accuracy: 0.9250 - val_loss: 3.2456 - val_accuracy: 0.3069 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.3951 - accuracy: 0.9500 - val_loss: 3.2288 - val_accuracy: 0.3135 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.3921 - accuracy: 0.9250 - val_loss: 3.2099 - val_accuracy: 0.3234 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.4394 - accuracy: 0.9750 - val_loss: 3.1929 - val_accuracy: 0.3300 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.3789 - accuracy: 0.9487 - val_loss: 3.1756 - val_accuracy: 0.3300 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.3270 - accuracy: 1.0000 - val_loss: 3.1542 - val_accuracy: 0.3366 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.3764 - accuracy: 0.9750 - val_loss: 3.1371 - val_accuracy: 0.3399 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.3265 - accuracy: 0.9750 - val_loss: 3.1247 - val_accuracy: 0.3366 - lr: 0.0010\n",
            "#12\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 642ms/step - loss: 5.8538 - accuracy: 0.0000e+00 - val_loss: 11.8740 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 5.2210 - accuracy: 0.0250 - val_loss: 10.1786 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 4.9635 - accuracy: 0.0513 - val_loss: 8.8138 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.6711 - accuracy: 0.0500 - val_loss: 8.1009 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.2550 - accuracy: 0.1250 - val_loss: 7.3359 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 4.4363 - accuracy: 0.1750 - val_loss: 6.8023 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 4.1340 - accuracy: 0.1500 - val_loss: 6.3719 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 4.1510 - accuracy: 0.1250 - val_loss: 6.0288 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 2.9272 - accuracy: 0.3250 - val_loss: 5.6859 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 3.4595 - accuracy: 0.3077 - val_loss: 5.4706 - val_accuracy: 0.0594 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 2.9155 - accuracy: 0.3500 - val_loss: 5.2359 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 2.4779 - accuracy: 0.5000 - val_loss: 5.0751 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 3.0687 - accuracy: 0.4250 - val_loss: 4.9220 - val_accuracy: 0.0891 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 2.6063 - accuracy: 0.4500 - val_loss: 4.7503 - val_accuracy: 0.1089 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 2.2099 - accuracy: 0.5000 - val_loss: 4.5995 - val_accuracy: 0.1122 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 2.7332 - accuracy: 0.4500 - val_loss: 4.4761 - val_accuracy: 0.1155 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 2.5911 - accuracy: 0.5250 - val_loss: 4.3815 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 2.1873 - accuracy: 0.5750 - val_loss: 4.2927 - val_accuracy: 0.1155 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 2.1707 - accuracy: 0.5500 - val_loss: 4.2034 - val_accuracy: 0.1287 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 1.6929 - accuracy: 0.6500 - val_loss: 4.1400 - val_accuracy: 0.1452 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.7929 - accuracy: 0.6500 - val_loss: 4.0866 - val_accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.6035 - accuracy: 0.7000 - val_loss: 4.0272 - val_accuracy: 0.1650 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.5070 - accuracy: 0.8000 - val_loss: 3.9760 - val_accuracy: 0.1716 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.7346 - accuracy: 0.6750 - val_loss: 3.9246 - val_accuracy: 0.1749 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.7640 - accuracy: 0.6750 - val_loss: 3.8783 - val_accuracy: 0.1914 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.4194 - accuracy: 0.7750 - val_loss: 3.8402 - val_accuracy: 0.1947 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.3782 - accuracy: 0.7750 - val_loss: 3.8018 - val_accuracy: 0.1980 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.4050 - accuracy: 0.8250 - val_loss: 3.7503 - val_accuracy: 0.1947 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.3166 - accuracy: 0.7750 - val_loss: 3.6955 - val_accuracy: 0.2145 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.1619 - accuracy: 0.8500 - val_loss: 3.6579 - val_accuracy: 0.2112 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.9114 - accuracy: 0.9000 - val_loss: 3.6285 - val_accuracy: 0.2145 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.1838 - accuracy: 0.8000 - val_loss: 3.5919 - val_accuracy: 0.2277 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.1471 - accuracy: 0.8250 - val_loss: 3.5658 - val_accuracy: 0.2211 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.9248 - accuracy: 0.9000 - val_loss: 3.5416 - val_accuracy: 0.2244 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.9714 - accuracy: 0.9000 - val_loss: 3.5190 - val_accuracy: 0.2409 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.7702 - accuracy: 0.8974 - val_loss: 3.5000 - val_accuracy: 0.2409 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.8662 - accuracy: 0.9500 - val_loss: 3.4748 - val_accuracy: 0.2508 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.6937 - accuracy: 0.9750 - val_loss: 3.4565 - val_accuracy: 0.2508 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.9984 - accuracy: 0.8750 - val_loss: 3.4297 - val_accuracy: 0.2640 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.8033 - accuracy: 0.9250 - val_loss: 3.4082 - val_accuracy: 0.2706 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.6297 - accuracy: 0.9231 - val_loss: 3.3933 - val_accuracy: 0.2640 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.6285 - accuracy: 0.9231 - val_loss: 3.3665 - val_accuracy: 0.2739 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.8595 - accuracy: 0.8500 - val_loss: 3.3492 - val_accuracy: 0.2904 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.6939 - accuracy: 0.9250 - val_loss: 3.3363 - val_accuracy: 0.2904 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.7945 - accuracy: 0.9250 - val_loss: 3.3250 - val_accuracy: 0.2970 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.5462 - accuracy: 1.0000 - val_loss: 3.3077 - val_accuracy: 0.2937 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.5699 - accuracy: 0.9250 - val_loss: 3.2985 - val_accuracy: 0.3003 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.4612 - accuracy: 0.9744 - val_loss: 3.2856 - val_accuracy: 0.3003 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.6042 - accuracy: 0.9750 - val_loss: 3.2693 - val_accuracy: 0.3003 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.5601 - accuracy: 0.9250 - val_loss: 3.2618 - val_accuracy: 0.2970 - lr: 0.0010\n",
            "#13\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 642ms/step - loss: 6.7201 - accuracy: 0.0000e+00 - val_loss: 4.9326 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 5.9671 - accuracy: 0.0250 - val_loss: 4.8971 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 6.1669 - accuracy: 0.0000e+00 - val_loss: 4.8664 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 5.7705 - accuracy: 0.0256 - val_loss: 4.8330 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 5.6332 - accuracy: 0.0250 - val_loss: 4.8003 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 5.6459 - accuracy: 0.0000e+00 - val_loss: 4.7737 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.7489 - accuracy: 0.0250 - val_loss: 4.7443 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 4.7483 - accuracy: 0.0250 - val_loss: 4.7379 - val_accuracy: 0.0132 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 5.2760 - accuracy: 0.1000 - val_loss: 4.7330 - val_accuracy: 0.0165 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 5.6095 - accuracy: 0.0000e+00 - val_loss: 4.7275 - val_accuracy: 0.0165 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 5.4073 - accuracy: 0.0500 - val_loss: 4.7231 - val_accuracy: 0.0132 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 5.1568 - accuracy: 0.1000 - val_loss: 4.7185 - val_accuracy: 0.0132 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 5.2450 - accuracy: 0.0750 - val_loss: 4.7150 - val_accuracy: 0.0132 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 5.3642 - accuracy: 0.0500 - val_loss: 4.7115 - val_accuracy: 0.0132 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 5.6664 - accuracy: 0.0250 - val_loss: 4.7107 - val_accuracy: 0.0132 - lr: 1.0000e-05\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 5.7798 - accuracy: 0.0500 - val_loss: 4.7103 - val_accuracy: 0.0132 - lr: 1.0000e-05\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 5.2764 - accuracy: 0.0000e+00 - val_loss: 4.7104 - val_accuracy: 0.0132 - lr: 1.0000e-05\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.3659 - accuracy: 0.0500 - val_loss: 4.7115 - val_accuracy: 0.0132 - lr: 1.0000e-05\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.1885 - accuracy: 0.0250 - val_loss: 4.7129 - val_accuracy: 0.0165 - lr: 1.0000e-05\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 5.3967 - accuracy: 0.0250 - val_loss: 4.7148 - val_accuracy: 0.0165 - lr: 1.0000e-06\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.1993 - accuracy: 0.0750 - val_loss: 4.7174 - val_accuracy: 0.0165 - lr: 1.0000e-06\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.1398 - accuracy: 0.0500 - val_loss: 4.7198 - val_accuracy: 0.0165 - lr: 1.0000e-06\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.9394 - accuracy: 0.0250 - val_loss: 4.7230 - val_accuracy: 0.0165 - lr: 1.0000e-06\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.9235 - accuracy: 0.1250 - val_loss: 4.7269 - val_accuracy: 0.0165 - lr: 1.0000e-06\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 5.3920 - accuracy: 0.0000e+00 - val_loss: 4.7308 - val_accuracy: 0.0165 - lr: 1.0000e-07\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 5.5591 - accuracy: 0.0256 - val_loss: 4.7349 - val_accuracy: 0.0165 - lr: 1.0000e-07\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 4.7537 - accuracy: 0.0250 - val_loss: 4.7395 - val_accuracy: 0.0165 - lr: 1.0000e-07\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 5.8627 - accuracy: 0.0000e+00 - val_loss: 4.7442 - val_accuracy: 0.0165 - lr: 1.0000e-07\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 4.7639 - accuracy: 0.1250 - val_loss: 4.7491 - val_accuracy: 0.0132 - lr: 1.0000e-07\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.9402 - accuracy: 0.0750 - val_loss: 4.7544 - val_accuracy: 0.0132 - lr: 1.0000e-08\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 5.1936 - accuracy: 0.0750 - val_loss: 4.7598 - val_accuracy: 0.0165 - lr: 1.0000e-08\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 5.0513 - accuracy: 0.0750 - val_loss: 4.7658 - val_accuracy: 0.0165 - lr: 1.0000e-08\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 5.2973 - accuracy: 0.0250 - val_loss: 4.7722 - val_accuracy: 0.0132 - lr: 1.0000e-08\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 5.0924 - accuracy: 0.0513 - val_loss: 4.7791 - val_accuracy: 0.0132 - lr: 1.0000e-08\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 5.1980 - accuracy: 0.0250 - val_loss: 4.7847 - val_accuracy: 0.0132 - lr: 1.0000e-09\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 5.9279 - accuracy: 0.0000e+00 - val_loss: 4.7915 - val_accuracy: 0.0132 - lr: 1.0000e-09\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 5.4689 - accuracy: 0.1000 - val_loss: 4.7986 - val_accuracy: 0.0132 - lr: 1.0000e-09\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.8978 - accuracy: 0.1000 - val_loss: 4.8055 - val_accuracy: 0.0165 - lr: 1.0000e-09\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.4696 - accuracy: 0.1250 - val_loss: 4.8132 - val_accuracy: 0.0132 - lr: 1.0000e-09\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 4.6649 - accuracy: 0.1000 - val_loss: 4.8202 - val_accuracy: 0.0132 - lr: 1.0000e-10\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 5.1786 - accuracy: 0.0500 - val_loss: 4.8277 - val_accuracy: 0.0132 - lr: 1.0000e-10\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 4.9437 - accuracy: 0.0750 - val_loss: 4.8352 - val_accuracy: 0.0132 - lr: 1.0000e-10\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 5.4697 - accuracy: 0.0500 - val_loss: 4.8435 - val_accuracy: 0.0132 - lr: 1.0000e-10\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 5.1558 - accuracy: 0.0500 - val_loss: 4.8514 - val_accuracy: 0.0132 - lr: 1.0000e-10\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 5.2073 - accuracy: 0.0000e+00 - val_loss: 4.8590 - val_accuracy: 0.0132 - lr: 5.0000e-11\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 5.2915 - accuracy: 0.0500 - val_loss: 4.8667 - val_accuracy: 0.0132 - lr: 5.0000e-11\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.0375 - accuracy: 0.0750 - val_loss: 4.8745 - val_accuracy: 0.0132 - lr: 5.0000e-11\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 5.1091 - accuracy: 0.0750 - val_loss: 4.8824 - val_accuracy: 0.0132 - lr: 5.0000e-11\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.4061 - accuracy: 0.0750 - val_loss: 4.8905 - val_accuracy: 0.0099 - lr: 5.0000e-11\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 4.8454 - accuracy: 0.0500 - val_loss: 4.8975 - val_accuracy: 0.0132 - lr: 5.0000e-11\n",
            "#14\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 646ms/step - loss: 5.4696 - accuracy: 0.0000e+00 - val_loss: 12.5363 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 5.5104 - accuracy: 0.0000e+00 - val_loss: 10.5644 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 4.7755 - accuracy: 0.0750 - val_loss: 8.8414 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 5.2518 - accuracy: 0.0500 - val_loss: 8.0523 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.9300 - accuracy: 0.0513 - val_loss: 7.3941 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.3356 - accuracy: 0.1500 - val_loss: 6.9079 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 4.3773 - accuracy: 0.0500 - val_loss: 6.5327 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.2219 - accuracy: 0.1750 - val_loss: 6.2202 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 4.1197 - accuracy: 0.1538 - val_loss: 5.8261 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 3.9538 - accuracy: 0.1500 - val_loss: 5.5575 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 4.0611 - accuracy: 0.1750 - val_loss: 5.2868 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 3.2482 - accuracy: 0.3000 - val_loss: 5.1108 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 3.4355 - accuracy: 0.2750 - val_loss: 4.9455 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 3.2731 - accuracy: 0.2500 - val_loss: 4.8379 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 3.5265 - accuracy: 0.2500 - val_loss: 4.6985 - val_accuracy: 0.0726 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 2.8064 - accuracy: 0.3500 - val_loss: 4.5884 - val_accuracy: 0.0891 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 2.6778 - accuracy: 0.4250 - val_loss: 4.4840 - val_accuracy: 0.1023 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 2.6546 - accuracy: 0.4750 - val_loss: 4.4037 - val_accuracy: 0.1254 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 2.9758 - accuracy: 0.3750 - val_loss: 4.3396 - val_accuracy: 0.1254 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 2.8670 - accuracy: 0.4500 - val_loss: 4.2555 - val_accuracy: 0.1386 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 2.7434 - accuracy: 0.3750 - val_loss: 4.1889 - val_accuracy: 0.1452 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 2.7233 - accuracy: 0.4500 - val_loss: 4.1436 - val_accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 2.3874 - accuracy: 0.4750 - val_loss: 4.0886 - val_accuracy: 0.1584 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 2.5108 - accuracy: 0.4250 - val_loss: 4.0469 - val_accuracy: 0.1683 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 2.1832 - accuracy: 0.5500 - val_loss: 4.0125 - val_accuracy: 0.1716 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 2.0377 - accuracy: 0.6667 - val_loss: 3.9622 - val_accuracy: 0.1815 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 2.0726 - accuracy: 0.6250 - val_loss: 3.9267 - val_accuracy: 0.1815 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.9630 - accuracy: 0.6500 - val_loss: 3.8808 - val_accuracy: 0.1848 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.8802 - accuracy: 0.6750 - val_loss: 3.8443 - val_accuracy: 0.1848 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 2.1996 - accuracy: 0.5750 - val_loss: 3.8160 - val_accuracy: 0.1881 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.6909 - accuracy: 0.7000 - val_loss: 3.7928 - val_accuracy: 0.1980 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.8365 - accuracy: 0.6923 - val_loss: 3.7626 - val_accuracy: 0.2046 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.6766 - accuracy: 0.6750 - val_loss: 3.7358 - val_accuracy: 0.2112 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.5255 - accuracy: 0.7500 - val_loss: 3.7123 - val_accuracy: 0.2079 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.4565 - accuracy: 0.8250 - val_loss: 3.6819 - val_accuracy: 0.2178 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 1.8167 - accuracy: 0.6500 - val_loss: 3.6524 - val_accuracy: 0.2178 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 1.4869 - accuracy: 0.6923 - val_loss: 3.6274 - val_accuracy: 0.2244 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 1.5328 - accuracy: 0.7179 - val_loss: 3.6048 - val_accuracy: 0.2211 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.5155 - accuracy: 0.7949 - val_loss: 3.5851 - val_accuracy: 0.2211 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.8391 - accuracy: 0.6000 - val_loss: 3.5584 - val_accuracy: 0.2310 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.6281 - accuracy: 0.6750 - val_loss: 3.5408 - val_accuracy: 0.2310 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.2925 - accuracy: 0.8205 - val_loss: 3.5221 - val_accuracy: 0.2343 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.4451 - accuracy: 0.7500 - val_loss: 3.5116 - val_accuracy: 0.2277 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.4828 - accuracy: 0.7750 - val_loss: 3.5015 - val_accuracy: 0.2376 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.3136 - accuracy: 0.8250 - val_loss: 3.4864 - val_accuracy: 0.2409 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.3738 - accuracy: 0.8250 - val_loss: 3.4710 - val_accuracy: 0.2376 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.4428 - accuracy: 0.7750 - val_loss: 3.4555 - val_accuracy: 0.2442 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.9693 - accuracy: 0.9000 - val_loss: 3.4429 - val_accuracy: 0.2475 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.2669 - accuracy: 0.8205 - val_loss: 3.4275 - val_accuracy: 0.2475 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.0857 - accuracy: 0.9000 - val_loss: 3.4162 - val_accuracy: 0.2442 - lr: 0.0010\n",
            "#15\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 644ms/step - loss: 8.6966 - accuracy: 0.0250 - val_loss: 12.8300 - val_accuracy: 0.0033 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 8.3989 - accuracy: 0.0250 - val_loss: 10.8651 - val_accuracy: 0.0033 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 8.2806 - accuracy: 0.0250 - val_loss: 9.7350 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 7.7136 - accuracy: 0.0500 - val_loss: 8.7349 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 8.6347 - accuracy: 0.0000e+00 - val_loss: 8.2946 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 7.5166 - accuracy: 0.0000e+00 - val_loss: 7.5381 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 7.7846 - accuracy: 0.0000e+00 - val_loss: 7.2035 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 7.3723 - accuracy: 0.0250 - val_loss: 6.9594 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 6.3316 - accuracy: 0.1000 - val_loss: 6.6715 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 6.9002 - accuracy: 0.0000e+00 - val_loss: 6.5236 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 7.3702 - accuracy: 0.0000e+00 - val_loss: 6.2415 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 7.6797 - accuracy: 0.0250 - val_loss: 6.1125 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 7.5256 - accuracy: 0.0000e+00 - val_loss: 5.9732 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 7.3433 - accuracy: 0.0500 - val_loss: 5.8422 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 7.4286 - accuracy: 0.0500 - val_loss: 5.7504 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 7.2370 - accuracy: 0.0500 - val_loss: 5.6382 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 7.1402 - accuracy: 0.0000e+00 - val_loss: 5.5484 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 6.9647 - accuracy: 0.0250 - val_loss: 5.4321 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 6.7635 - accuracy: 0.0000e+00 - val_loss: 5.3706 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 6.7463 - accuracy: 0.0500 - val_loss: 5.3115 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 7.8007 - accuracy: 0.0000e+00 - val_loss: 5.2486 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 7.2252 - accuracy: 0.0000e+00 - val_loss: 5.2206 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 7.2712 - accuracy: 0.0250 - val_loss: 5.1510 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 6.8563 - accuracy: 0.0500 - val_loss: 5.1351 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 7.2999 - accuracy: 0.0000e+00 - val_loss: 5.0991 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 6.7050 - accuracy: 0.0250 - val_loss: 5.0400 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 7.0982 - accuracy: 0.0000e+00 - val_loss: 5.0103 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 6.8554 - accuracy: 0.0500 - val_loss: 4.9713 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 6.9594 - accuracy: 0.0250 - val_loss: 4.9393 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 6.0768 - accuracy: 0.0000e+00 - val_loss: 4.9030 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 6.3655 - accuracy: 0.0750 - val_loss: 4.8916 - val_accuracy: 0.0297 - lr: 1.0000e-04\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 6.9228 - accuracy: 0.0000e+00 - val_loss: 4.8871 - val_accuracy: 0.0297 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 6.5441 - accuracy: 0.0000e+00 - val_loss: 4.8804 - val_accuracy: 0.0330 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 7.0005 - accuracy: 0.0250 - val_loss: 4.8719 - val_accuracy: 0.0297 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 6.8510 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.0297 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 6.7688 - accuracy: 0.0000e+00 - val_loss: 4.8639 - val_accuracy: 0.0297 - lr: 1.0000e-05\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 7.1822 - accuracy: 0.0750 - val_loss: 4.8604 - val_accuracy: 0.0297 - lr: 1.0000e-05\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 6.9463 - accuracy: 0.0256 - val_loss: 4.8548 - val_accuracy: 0.0330 - lr: 1.0000e-05\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.5566 - accuracy: 0.0769 - val_loss: 4.8505 - val_accuracy: 0.0330 - lr: 1.0000e-05\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 6.0769 - accuracy: 0.1000 - val_loss: 4.8345 - val_accuracy: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.8173 - accuracy: 0.0500 - val_loss: 4.8337 - val_accuracy: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 6.2333 - accuracy: 0.0250 - val_loss: 4.8308 - val_accuracy: 0.0396 - lr: 1.0000e-05\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 6.8019 - accuracy: 0.0250 - val_loss: 4.8289 - val_accuracy: 0.0396 - lr: 1.0000e-05\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 6.0345 - accuracy: 0.0000e+00 - val_loss: 4.8290 - val_accuracy: 0.0396 - lr: 1.0000e-05\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 6.3698 - accuracy: 0.0500 - val_loss: 4.8320 - val_accuracy: 0.0396 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 6.9447 - accuracy: 0.0500 - val_loss: 4.8318 - val_accuracy: 0.0396 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 6.6369 - accuracy: 0.0000e+00 - val_loss: 4.8310 - val_accuracy: 0.0396 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 6.4932 - accuracy: 0.0000e+00 - val_loss: 4.8318 - val_accuracy: 0.0396 - lr: 1.0000e-06\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 6.4310 - accuracy: 0.0250 - val_loss: 4.8345 - val_accuracy: 0.0396 - lr: 1.0000e-06\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 7.1538 - accuracy: 0.0500 - val_loss: 4.8227 - val_accuracy: 0.0396 - lr: 1.0000e-06\n",
            "#16\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 642ms/step - loss: 6.5494 - accuracy: 0.0000e+00 - val_loss: 5.3913 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 5.5402 - accuracy: 0.0500 - val_loss: 5.3120 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 5.3337 - accuracy: 0.0769 - val_loss: 5.2264 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 5.0634 - accuracy: 0.1000 - val_loss: 5.1531 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 4.6275 - accuracy: 0.1500 - val_loss: 5.0945 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.4527 - accuracy: 0.1750 - val_loss: 5.0325 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 3.9997 - accuracy: 0.1538 - val_loss: 4.9629 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 4.2802 - accuracy: 0.2000 - val_loss: 4.8932 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 4.1581 - accuracy: 0.1500 - val_loss: 4.8252 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 3.7583 - accuracy: 0.2750 - val_loss: 4.7714 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 3.4477 - accuracy: 0.3500 - val_loss: 4.7050 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 3.6959 - accuracy: 0.2750 - val_loss: 4.6483 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 2.9736 - accuracy: 0.3500 - val_loss: 4.6032 - val_accuracy: 0.0825 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 2.8508 - accuracy: 0.4250 - val_loss: 4.5619 - val_accuracy: 0.0825 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 2.3973 - accuracy: 0.4500 - val_loss: 4.5205 - val_accuracy: 0.0891 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 3.7413 - accuracy: 0.2750 - val_loss: 4.4903 - val_accuracy: 0.1023 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 3.0695 - accuracy: 0.3500 - val_loss: 4.4445 - val_accuracy: 0.0957 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 2.9264 - accuracy: 0.4250 - val_loss: 4.3929 - val_accuracy: 0.1023 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 2.3087 - accuracy: 0.5000 - val_loss: 4.3445 - val_accuracy: 0.0957 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 2.5264 - accuracy: 0.4000 - val_loss: 4.2935 - val_accuracy: 0.1155 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 2.4876 - accuracy: 0.4000 - val_loss: 4.2453 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.4553 - accuracy: 0.7000 - val_loss: 4.2201 - val_accuracy: 0.1221 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.9788 - accuracy: 0.5500 - val_loss: 4.1790 - val_accuracy: 0.1287 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 2.1004 - accuracy: 0.5000 - val_loss: 4.1501 - val_accuracy: 0.1353 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.6088 - accuracy: 0.6500 - val_loss: 4.1141 - val_accuracy: 0.1386 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 2.1405 - accuracy: 0.6250 - val_loss: 4.0795 - val_accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.3064 - accuracy: 0.6410 - val_loss: 4.0465 - val_accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.6221 - accuracy: 0.5250 - val_loss: 4.0286 - val_accuracy: 0.1584 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.2074 - accuracy: 0.7500 - val_loss: 4.0022 - val_accuracy: 0.1551 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.2933 - accuracy: 0.6750 - val_loss: 3.9774 - val_accuracy: 0.1617 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.0449 - accuracy: 0.7500 - val_loss: 3.9521 - val_accuracy: 0.1584 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.6243 - accuracy: 0.9000 - val_loss: 3.9439 - val_accuracy: 0.1584 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.1094 - accuracy: 0.8000 - val_loss: 3.9275 - val_accuracy: 0.1716 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.0931 - accuracy: 0.7750 - val_loss: 3.9082 - val_accuracy: 0.1749 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.7593 - accuracy: 0.8500 - val_loss: 3.8907 - val_accuracy: 0.1650 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.8559 - accuracy: 0.8000 - val_loss: 3.8730 - val_accuracy: 0.1749 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.9534 - accuracy: 0.8250 - val_loss: 3.8409 - val_accuracy: 0.1716 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.9592 - accuracy: 0.7250 - val_loss: 3.8242 - val_accuracy: 0.1782 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.9645 - accuracy: 0.7750 - val_loss: 3.8032 - val_accuracy: 0.1881 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.0399 - accuracy: 0.7250 - val_loss: 3.7838 - val_accuracy: 0.1914 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.9882 - accuracy: 0.8250 - val_loss: 3.7678 - val_accuracy: 0.1947 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.0014 - accuracy: 0.7949 - val_loss: 3.7504 - val_accuracy: 0.2013 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.9823 - accuracy: 0.8250 - val_loss: 3.7240 - val_accuracy: 0.2013 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.5649 - accuracy: 0.8750 - val_loss: 3.7183 - val_accuracy: 0.1947 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.7269 - accuracy: 0.9250 - val_loss: 3.6987 - val_accuracy: 0.1980 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.7274 - accuracy: 0.9000 - val_loss: 3.6788 - val_accuracy: 0.2046 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.8136 - accuracy: 0.8500 - val_loss: 3.6686 - val_accuracy: 0.2112 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 1.1039 - accuracy: 0.7000 - val_loss: 3.6533 - val_accuracy: 0.2145 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 0.7065 - accuracy: 0.8974 - val_loss: 3.6391 - val_accuracy: 0.2145 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.6613 - accuracy: 0.9000 - val_loss: 3.6226 - val_accuracy: 0.2178 - lr: 0.0010\n",
            "#17\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 653ms/step - loss: 6.1703 - accuracy: 0.0000e+00 - val_loss: 12.9197 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 5.7439 - accuracy: 0.0000e+00 - val_loss: 10.9064 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.1879 - accuracy: 0.1000 - val_loss: 9.1153 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.3640 - accuracy: 0.0750 - val_loss: 8.2454 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.8455 - accuracy: 0.0750 - val_loss: 7.4857 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 4.9168 - accuracy: 0.0000e+00 - val_loss: 6.8982 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 4.2871 - accuracy: 0.1750 - val_loss: 6.5232 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 4.1883 - accuracy: 0.1000 - val_loss: 6.2564 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 4.5415 - accuracy: 0.1250 - val_loss: 5.9337 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 3.6315 - accuracy: 0.2000 - val_loss: 5.6307 - val_accuracy: 0.0594 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 3.5673 - accuracy: 0.2500 - val_loss: 5.4253 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 3.5528 - accuracy: 0.2500 - val_loss: 5.1802 - val_accuracy: 0.0759 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 3.1438 - accuracy: 0.3590 - val_loss: 5.0206 - val_accuracy: 0.0726 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 3.2395 - accuracy: 0.3000 - val_loss: 4.8294 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 3.6410 - accuracy: 0.3500 - val_loss: 4.6997 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 2.9773 - accuracy: 0.2750 - val_loss: 4.5606 - val_accuracy: 0.1056 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 2.9250 - accuracy: 0.4250 - val_loss: 4.4406 - val_accuracy: 0.1056 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 2.7630 - accuracy: 0.4250 - val_loss: 4.3343 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 2.2120 - accuracy: 0.4872 - val_loss: 4.2551 - val_accuracy: 0.1254 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 2.2882 - accuracy: 0.4750 - val_loss: 4.1799 - val_accuracy: 0.1419 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 2.8837 - accuracy: 0.4250 - val_loss: 4.0925 - val_accuracy: 0.1551 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 2.3466 - accuracy: 0.4500 - val_loss: 4.0244 - val_accuracy: 0.1617 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 2.3897 - accuracy: 0.4500 - val_loss: 3.9605 - val_accuracy: 0.1683 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 2.3855 - accuracy: 0.5000 - val_loss: 3.8941 - val_accuracy: 0.1749 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.7145 - accuracy: 0.6000 - val_loss: 3.8429 - val_accuracy: 0.1815 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 2.1513 - accuracy: 0.5385 - val_loss: 3.7928 - val_accuracy: 0.1815 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.8964 - accuracy: 0.6923 - val_loss: 3.7401 - val_accuracy: 0.1848 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.6776 - accuracy: 0.7000 - val_loss: 3.6983 - val_accuracy: 0.1815 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.8760 - accuracy: 0.5500 - val_loss: 3.6568 - val_accuracy: 0.1980 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.4858 - accuracy: 0.6750 - val_loss: 3.6173 - val_accuracy: 0.1947 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 2.2721 - accuracy: 0.5128 - val_loss: 3.5722 - val_accuracy: 0.2013 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.8273 - accuracy: 0.6750 - val_loss: 3.5318 - val_accuracy: 0.2277 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.8379 - accuracy: 0.6000 - val_loss: 3.5070 - val_accuracy: 0.2244 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.1102 - accuracy: 0.8000 - val_loss: 3.4778 - val_accuracy: 0.2343 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.4860 - accuracy: 0.7750 - val_loss: 3.4550 - val_accuracy: 0.2343 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.5006 - accuracy: 0.6250 - val_loss: 3.4274 - val_accuracy: 0.2343 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.4820 - accuracy: 0.7000 - val_loss: 3.4034 - val_accuracy: 0.2310 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.1502 - accuracy: 0.7692 - val_loss: 3.3799 - val_accuracy: 0.2475 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.1102 - accuracy: 0.8000 - val_loss: 3.3601 - val_accuracy: 0.2442 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.3120 - accuracy: 0.7179 - val_loss: 3.3433 - val_accuracy: 0.2508 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.3929 - accuracy: 0.6667 - val_loss: 3.3182 - val_accuracy: 0.2475 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.4839 - accuracy: 0.7250 - val_loss: 3.2949 - val_accuracy: 0.2475 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.1900 - accuracy: 0.8250 - val_loss: 3.2761 - val_accuracy: 0.2640 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.0344 - accuracy: 0.8250 - val_loss: 3.2629 - val_accuracy: 0.2640 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.3070 - accuracy: 0.7250 - val_loss: 3.2375 - val_accuracy: 0.2640 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 1.0026 - accuracy: 0.8500 - val_loss: 3.2201 - val_accuracy: 0.2739 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.1812 - accuracy: 0.7500 - val_loss: 3.1974 - val_accuracy: 0.2838 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 1.1704 - accuracy: 0.7750 - val_loss: 3.1823 - val_accuracy: 0.2805 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.0429 - accuracy: 0.8462 - val_loss: 3.1676 - val_accuracy: 0.2739 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.8637 - accuracy: 0.9000 - val_loss: 3.1509 - val_accuracy: 0.2739 - lr: 0.0010\n",
            "#18\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 647ms/step - loss: 7.3006 - accuracy: 0.0250 - val_loss: 13.5811 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 7.1228 - accuracy: 0.0250 - val_loss: 11.4799 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 7.2095 - accuracy: 0.0250 - val_loss: 10.1765 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 6.9080 - accuracy: 0.0500 - val_loss: 8.8412 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 6.4679 - accuracy: 0.0250 - val_loss: 8.2046 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 6.1940 - accuracy: 0.0250 - val_loss: 7.5899 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 6.4021 - accuracy: 0.0500 - val_loss: 7.0665 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 5.8680 - accuracy: 0.0250 - val_loss: 6.7844 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 6.3422 - accuracy: 0.0250 - val_loss: 6.5527 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 5.7018 - accuracy: 0.0750 - val_loss: 6.2342 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 5.9579 - accuracy: 0.1000 - val_loss: 5.9563 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 5.4550 - accuracy: 0.0250 - val_loss: 5.7350 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 5.3669 - accuracy: 0.0000e+00 - val_loss: 5.5771 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 5.9969 - accuracy: 0.0750 - val_loss: 5.4107 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 5.2635 - accuracy: 0.0500 - val_loss: 5.2940 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 5.2910 - accuracy: 0.0750 - val_loss: 5.1617 - val_accuracy: 0.0726 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 5.2613 - accuracy: 0.0256 - val_loss: 5.0618 - val_accuracy: 0.0759 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 5.4216 - accuracy: 0.0500 - val_loss: 4.9792 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 5.5433 - accuracy: 0.0769 - val_loss: 4.8507 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 5.4820 - accuracy: 0.0500 - val_loss: 4.7993 - val_accuracy: 0.0957 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 4.9643 - accuracy: 0.0750 - val_loss: 4.7133 - val_accuracy: 0.0957 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.9807 - accuracy: 0.1000 - val_loss: 4.6510 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.5460 - accuracy: 0.1000 - val_loss: 4.6140 - val_accuracy: 0.0957 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.1850 - accuracy: 0.2000 - val_loss: 4.5736 - val_accuracy: 0.0957 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.8545 - accuracy: 0.0769 - val_loss: 4.5079 - val_accuracy: 0.1122 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.3268 - accuracy: 0.0500 - val_loss: 4.4713 - val_accuracy: 0.1056 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 5.2473 - accuracy: 0.0750 - val_loss: 4.4264 - val_accuracy: 0.1122 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 3.6011 - accuracy: 0.2250 - val_loss: 4.3800 - val_accuracy: 0.1056 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.3728 - accuracy: 0.1750 - val_loss: 4.3440 - val_accuracy: 0.1221 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 4.2010 - accuracy: 0.1538 - val_loss: 4.2963 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.4970 - accuracy: 0.1750 - val_loss: 4.2708 - val_accuracy: 0.1221 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 4.4323 - accuracy: 0.1750 - val_loss: 4.2379 - val_accuracy: 0.1287 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.3357 - accuracy: 0.1250 - val_loss: 4.2130 - val_accuracy: 0.1452 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 3.7652 - accuracy: 0.2051 - val_loss: 4.1681 - val_accuracy: 0.1386 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.4466 - accuracy: 0.1750 - val_loss: 4.1267 - val_accuracy: 0.1353 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 3.9265 - accuracy: 0.2500 - val_loss: 4.1014 - val_accuracy: 0.1353 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 3.4615 - accuracy: 0.1750 - val_loss: 4.0707 - val_accuracy: 0.1518 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 3.6705 - accuracy: 0.3250 - val_loss: 4.0353 - val_accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 3.5319 - accuracy: 0.2250 - val_loss: 4.0153 - val_accuracy: 0.1551 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.4922 - accuracy: 0.1750 - val_loss: 3.9947 - val_accuracy: 0.1518 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 3.5607 - accuracy: 0.3000 - val_loss: 3.9689 - val_accuracy: 0.1551 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.0548 - accuracy: 0.1500 - val_loss: 3.9345 - val_accuracy: 0.1749 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 3.7415 - accuracy: 0.2750 - val_loss: 3.8950 - val_accuracy: 0.1683 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 3.2855 - accuracy: 0.3077 - val_loss: 3.8779 - val_accuracy: 0.1815 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 3.7449 - accuracy: 0.2250 - val_loss: 3.8576 - val_accuracy: 0.1815 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 3.5666 - accuracy: 0.2500 - val_loss: 3.8356 - val_accuracy: 0.1815 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 3.7591 - accuracy: 0.1750 - val_loss: 3.8180 - val_accuracy: 0.1848 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 3.5397 - accuracy: 0.3250 - val_loss: 3.8158 - val_accuracy: 0.1881 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 3.4978 - accuracy: 0.2000 - val_loss: 3.7978 - val_accuracy: 0.1848 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 3.4518 - accuracy: 0.2051 - val_loss: 3.7829 - val_accuracy: 0.1815 - lr: 0.0010\n",
            "#19\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 656ms/step - loss: 6.7149 - accuracy: 0.0000e+00 - val_loss: 12.5564 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 6.2992 - accuracy: 0.0000e+00 - val_loss: 10.4442 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 5.9689 - accuracy: 0.0250 - val_loss: 9.0710 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 6.0901 - accuracy: 0.0000e+00 - val_loss: 8.1738 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 6.2395 - accuracy: 0.0500 - val_loss: 7.6008 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 5.5341 - accuracy: 0.0250 - val_loss: 7.0664 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 5.4751 - accuracy: 0.0250 - val_loss: 6.6849 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 5.5647 - accuracy: 0.0250 - val_loss: 6.4043 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 5.3494 - accuracy: 0.0000e+00 - val_loss: 6.1569 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 5.3227 - accuracy: 0.0250 - val_loss: 5.9482 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 5.3693 - accuracy: 0.0769 - val_loss: 5.7378 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 5.3410 - accuracy: 0.0000e+00 - val_loss: 5.6004 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 5.2476 - accuracy: 0.0500 - val_loss: 5.4493 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 4.4254 - accuracy: 0.0750 - val_loss: 5.3364 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 4.5086 - accuracy: 0.0750 - val_loss: 5.2297 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 4.6438 - accuracy: 0.0750 - val_loss: 5.1265 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 4.5896 - accuracy: 0.0750 - val_loss: 5.0315 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 4.1337 - accuracy: 0.1500 - val_loss: 4.9599 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 4.5648 - accuracy: 0.0500 - val_loss: 4.8795 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 4.1059 - accuracy: 0.1750 - val_loss: 4.8013 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.8877 - accuracy: 0.0500 - val_loss: 4.7461 - val_accuracy: 0.0528 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 3.5398 - accuracy: 0.1750 - val_loss: 4.6681 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 4.3715 - accuracy: 0.1750 - val_loss: 4.6211 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.1283 - accuracy: 0.0750 - val_loss: 4.5680 - val_accuracy: 0.0726 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.1591 - accuracy: 0.1500 - val_loss: 4.5254 - val_accuracy: 0.0726 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.3409 - accuracy: 0.1026 - val_loss: 4.4684 - val_accuracy: 0.0825 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 3.9598 - accuracy: 0.1250 - val_loss: 4.4352 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 4.1239 - accuracy: 0.1000 - val_loss: 4.4060 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 3.8810 - accuracy: 0.1250 - val_loss: 4.3632 - val_accuracy: 0.0759 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 3.5005 - accuracy: 0.2000 - val_loss: 4.3267 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 3.0065 - accuracy: 0.2500 - val_loss: 4.3037 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.3316 - accuracy: 0.1000 - val_loss: 4.2973 - val_accuracy: 0.0858 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 3.6065 - accuracy: 0.2000 - val_loss: 4.2934 - val_accuracy: 0.0825 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 3.5844 - accuracy: 0.1250 - val_loss: 4.2838 - val_accuracy: 0.0825 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 3.8149 - accuracy: 0.2500 - val_loss: 4.2798 - val_accuracy: 0.0858 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 3.5645 - accuracy: 0.2000 - val_loss: 4.2776 - val_accuracy: 0.0858 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 3.7543 - accuracy: 0.1750 - val_loss: 4.2683 - val_accuracy: 0.0858 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 4.1992 - accuracy: 0.0513 - val_loss: 4.2614 - val_accuracy: 0.0891 - lr: 1.0000e-05\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 4.0855 - accuracy: 0.1500 - val_loss: 4.2601 - val_accuracy: 0.0891 - lr: 1.0000e-05\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 3.4899 - accuracy: 0.2051 - val_loss: 4.2567 - val_accuracy: 0.0858 - lr: 1.0000e-05\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 3.8547 - accuracy: 0.2000 - val_loss: 4.2498 - val_accuracy: 0.0858 - lr: 1.0000e-05\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 3.5638 - accuracy: 0.1500 - val_loss: 4.2491 - val_accuracy: 0.0858 - lr: 1.0000e-05\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 3.6296 - accuracy: 0.1026 - val_loss: 4.2443 - val_accuracy: 0.0858 - lr: 1.0000e-05\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 3.6925 - accuracy: 0.2250 - val_loss: 4.2399 - val_accuracy: 0.0858 - lr: 1.0000e-06\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 3.6569 - accuracy: 0.1250 - val_loss: 4.2369 - val_accuracy: 0.0858 - lr: 1.0000e-06\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 3.5876 - accuracy: 0.2000 - val_loss: 4.2391 - val_accuracy: 0.0825 - lr: 1.0000e-06\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 3.6017 - accuracy: 0.2250 - val_loss: 4.2383 - val_accuracy: 0.0825 - lr: 1.0000e-06\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 3.8698 - accuracy: 0.1750 - val_loss: 4.2379 - val_accuracy: 0.0825 - lr: 1.0000e-06\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 4.1364 - accuracy: 0.0500 - val_loss: 4.2359 - val_accuracy: 0.0891 - lr: 1.0000e-07\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 3.4426 - accuracy: 0.1750 - val_loss: 4.2364 - val_accuracy: 0.0825 - lr: 1.0000e-07\n",
            "Tuning last 2 layers.\n",
            "#0\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 619ms/step - loss: 5.7145 - accuracy: 0.0000e+00 - val_loss: 4.9989 - val_accuracy: 0.0033 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 5.5908 - accuracy: 0.0000e+00 - val_loss: 4.9850 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 5.8308 - accuracy: 0.0250 - val_loss: 4.9617 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 5.4607 - accuracy: 0.0000e+00 - val_loss: 4.9092 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 5.4538 - accuracy: 0.0250 - val_loss: 4.8636 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 5.5412 - accuracy: 0.0000e+00 - val_loss: 4.8369 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 5.7610 - accuracy: 0.0000e+00 - val_loss: 4.8072 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 5.3400 - accuracy: 0.0750 - val_loss: 4.7649 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 5.9037 - accuracy: 0.0250 - val_loss: 4.7293 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 5.4899 - accuracy: 0.0000e+00 - val_loss: 4.7073 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 5.0869 - accuracy: 0.0250 - val_loss: 4.6805 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 5.3799 - accuracy: 0.0250 - val_loss: 4.6582 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 5.2255 - accuracy: 0.0513 - val_loss: 4.6274 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 5.7735 - accuracy: 0.0250 - val_loss: 4.5964 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 4.9573 - accuracy: 0.0000e+00 - val_loss: 4.5689 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 5.2527 - accuracy: 0.0000e+00 - val_loss: 4.5463 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 5.4574 - accuracy: 0.0000e+00 - val_loss: 4.5265 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 5.1433 - accuracy: 0.0250 - val_loss: 4.5051 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 5.6323 - accuracy: 0.0250 - val_loss: 4.4961 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 5.0478 - accuracy: 0.0250 - val_loss: 4.4783 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 5.0983 - accuracy: 0.0250 - val_loss: 4.4642 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 4.7985 - accuracy: 0.0000e+00 - val_loss: 4.4526 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 5.1980 - accuracy: 0.0000e+00 - val_loss: 4.4228 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 5.1580 - accuracy: 0.0500 - val_loss: 4.4127 - val_accuracy: 0.0594 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 5.5245 - accuracy: 0.0000e+00 - val_loss: 4.3997 - val_accuracy: 0.0660 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 5.0027 - accuracy: 0.0500 - val_loss: 4.3885 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 5.3717 - accuracy: 0.0000e+00 - val_loss: 4.3662 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 4.9348 - accuracy: 0.0750 - val_loss: 4.3515 - val_accuracy: 0.0726 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 5.2168 - accuracy: 0.0250 - val_loss: 4.3291 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 4.7582 - accuracy: 0.0500 - val_loss: 4.3172 - val_accuracy: 0.0891 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 5.2656 - accuracy: 0.0000e+00 - val_loss: 4.3001 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 4.8908 - accuracy: 0.1000 - val_loss: 4.2885 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 4.8163 - accuracy: 0.0256 - val_loss: 4.2832 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 4.7825 - accuracy: 0.0256 - val_loss: 4.2688 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 4.6539 - accuracy: 0.0500 - val_loss: 4.2587 - val_accuracy: 0.0825 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.8727 - accuracy: 0.0000e+00 - val_loss: 4.2531 - val_accuracy: 0.0792 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 5.2794 - accuracy: 0.0250 - val_loss: 4.2477 - val_accuracy: 0.0825 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 5.1101 - accuracy: 0.0250 - val_loss: 4.2430 - val_accuracy: 0.0858 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 4.7502 - accuracy: 0.0500 - val_loss: 4.2379 - val_accuracy: 0.0858 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 5.1419 - accuracy: 0.0500 - val_loss: 4.2334 - val_accuracy: 0.0891 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 5.3430 - accuracy: 0.0250 - val_loss: 4.2301 - val_accuracy: 0.0924 - lr: 1.0000e-05\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 4.7066 - accuracy: 0.1000 - val_loss: 4.2264 - val_accuracy: 0.0924 - lr: 1.0000e-05\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 5.1573 - accuracy: 0.0500 - val_loss: 4.2234 - val_accuracy: 0.0924 - lr: 1.0000e-05\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 5.0262 - accuracy: 0.0000e+00 - val_loss: 4.2198 - val_accuracy: 0.0891 - lr: 1.0000e-05\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 4.9071 - accuracy: 0.0000e+00 - val_loss: 4.2167 - val_accuracy: 0.0891 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 5.3469 - accuracy: 0.0000e+00 - val_loss: 4.2136 - val_accuracy: 0.0891 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 5.0008 - accuracy: 0.0500 - val_loss: 4.2110 - val_accuracy: 0.0924 - lr: 1.0000e-06\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 4.9909 - accuracy: 0.0500 - val_loss: 4.2092 - val_accuracy: 0.0924 - lr: 1.0000e-06\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 5.1368 - accuracy: 0.0500 - val_loss: 4.2091 - val_accuracy: 0.0924 - lr: 1.0000e-06\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 5.1205 - accuracy: 0.0000e+00 - val_loss: 4.2081 - val_accuracy: 0.0891 - lr: 1.0000e-06\n",
            "#1\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 625ms/step - loss: 6.0237 - accuracy: 0.0000e+00 - val_loss: 5.1839 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 5.7540 - accuracy: 0.0000e+00 - val_loss: 5.1033 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 5.8617 - accuracy: 0.0513 - val_loss: 5.0404 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 5.4530 - accuracy: 0.0769 - val_loss: 5.0126 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 5.8654 - accuracy: 0.0000e+00 - val_loss: 4.9533 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 5.4258 - accuracy: 0.0750 - val_loss: 4.9297 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 5.3367 - accuracy: 0.0000e+00 - val_loss: 4.8984 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 5.3883 - accuracy: 0.0000e+00 - val_loss: 4.8894 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 5.4445 - accuracy: 0.0250 - val_loss: 4.8665 - val_accuracy: 0.0165 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 5.3544 - accuracy: 0.0250 - val_loss: 4.8472 - val_accuracy: 0.0165 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 5.7081 - accuracy: 0.0000e+00 - val_loss: 4.8321 - val_accuracy: 0.0132 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 5.2505 - accuracy: 0.0250 - val_loss: 4.8174 - val_accuracy: 0.0165 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 5.5812 - accuracy: 0.0000e+00 - val_loss: 4.8057 - val_accuracy: 0.0132 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 5.0002 - accuracy: 0.0000e+00 - val_loss: 4.7990 - val_accuracy: 0.0132 - lr: 1.0000e-05\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 4.7346 - accuracy: 0.0500 - val_loss: 4.7930 - val_accuracy: 0.0132 - lr: 1.0000e-05\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 5.1429 - accuracy: 0.0250 - val_loss: 4.7898 - val_accuracy: 0.0165 - lr: 1.0000e-05\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 5.2728 - accuracy: 0.0250 - val_loss: 4.7855 - val_accuracy: 0.0165 - lr: 1.0000e-05\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 5.7206 - accuracy: 0.0250 - val_loss: 4.7810 - val_accuracy: 0.0165 - lr: 1.0000e-05\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 5.1441 - accuracy: 0.0000e+00 - val_loss: 4.7793 - val_accuracy: 0.0165 - lr: 1.0000e-06\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 4.9772 - accuracy: 0.0250 - val_loss: 4.7760 - val_accuracy: 0.0165 - lr: 1.0000e-06\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 5.2992 - accuracy: 0.0500 - val_loss: 4.7742 - val_accuracy: 0.0198 - lr: 1.0000e-06\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 4.9931 - accuracy: 0.0250 - val_loss: 4.7728 - val_accuracy: 0.0198 - lr: 1.0000e-06\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 5.0651 - accuracy: 0.0250 - val_loss: 4.7709 - val_accuracy: 0.0198 - lr: 1.0000e-06\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 5.2397 - accuracy: 0.0250 - val_loss: 4.7715 - val_accuracy: 0.0198 - lr: 1.0000e-07\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 5.0888 - accuracy: 0.0256 - val_loss: 4.7703 - val_accuracy: 0.0165 - lr: 1.0000e-07\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 4.9962 - accuracy: 0.0000e+00 - val_loss: 4.7691 - val_accuracy: 0.0165 - lr: 1.0000e-07\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 5.3442 - accuracy: 0.0256 - val_loss: 4.7683 - val_accuracy: 0.0165 - lr: 1.0000e-07\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 5.3361 - accuracy: 0.0250 - val_loss: 4.7687 - val_accuracy: 0.0198 - lr: 1.0000e-07\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 5.4141 - accuracy: 0.0250 - val_loss: 4.7678 - val_accuracy: 0.0231 - lr: 1.0000e-08\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 5.0796 - accuracy: 0.0250 - val_loss: 4.7678 - val_accuracy: 0.0231 - lr: 1.0000e-08\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 5.2912 - accuracy: 0.0250 - val_loss: 4.7684 - val_accuracy: 0.0231 - lr: 1.0000e-08\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 5.4725 - accuracy: 0.0000e+00 - val_loss: 4.7696 - val_accuracy: 0.0231 - lr: 1.0000e-08\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 4.8341 - accuracy: 0.0250 - val_loss: 4.7701 - val_accuracy: 0.0264 - lr: 1.0000e-08\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 5.2295 - accuracy: 0.0250 - val_loss: 4.7710 - val_accuracy: 0.0297 - lr: 1.0000e-08\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 5.2016 - accuracy: 0.0513 - val_loss: 4.7721 - val_accuracy: 0.0297 - lr: 1.0000e-08\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 4.9160 - accuracy: 0.0250 - val_loss: 4.7733 - val_accuracy: 0.0297 - lr: 1.0000e-08\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 5.0990 - accuracy: 0.0256 - val_loss: 4.7747 - val_accuracy: 0.0264 - lr: 1.0000e-08\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 5.2783 - accuracy: 0.0513 - val_loss: 4.7762 - val_accuracy: 0.0264 - lr: 1.0000e-08\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 5.1201 - accuracy: 0.0500 - val_loss: 4.7778 - val_accuracy: 0.0264 - lr: 1.0000e-08\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 5.0888 - accuracy: 0.0000e+00 - val_loss: 4.7788 - val_accuracy: 0.0264 - lr: 1.0000e-09\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 4.8816 - accuracy: 0.1000 - val_loss: 4.7790 - val_accuracy: 0.0264 - lr: 1.0000e-09\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 5.2659 - accuracy: 0.0000e+00 - val_loss: 4.7804 - val_accuracy: 0.0231 - lr: 1.0000e-09\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 5.5817 - accuracy: 0.0000e+00 - val_loss: 4.7818 - val_accuracy: 0.0231 - lr: 1.0000e-09\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 5.2734 - accuracy: 0.0000e+00 - val_loss: 4.7844 - val_accuracy: 0.0231 - lr: 1.0000e-09\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 5.2668 - accuracy: 0.0250 - val_loss: 4.7863 - val_accuracy: 0.0231 - lr: 1.0000e-10\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 4.8826 - accuracy: 0.1000 - val_loss: 4.7880 - val_accuracy: 0.0231 - lr: 1.0000e-10\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.8442 - accuracy: 0.0750 - val_loss: 4.7895 - val_accuracy: 0.0231 - lr: 1.0000e-10\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 5.2424 - accuracy: 0.0500 - val_loss: 4.7925 - val_accuracy: 0.0264 - lr: 1.0000e-10\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 5.2353 - accuracy: 0.0000e+00 - val_loss: 4.7948 - val_accuracy: 0.0264 - lr: 1.0000e-10\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 5.0223 - accuracy: 0.0513 - val_loss: 4.7959 - val_accuracy: 0.0264 - lr: 5.0000e-11\n",
            "#2\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 634ms/step - loss: 6.5341 - accuracy: 0.0250 - val_loss: 5.0517 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 5.4909 - accuracy: 0.0250 - val_loss: 5.0378 - val_accuracy: 0.0033 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 6.2061 - accuracy: 0.0500 - val_loss: 4.9866 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 6.1299 - accuracy: 0.0250 - val_loss: 4.9255 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 5.8665 - accuracy: 0.0000e+00 - val_loss: 4.8784 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 5.1699 - accuracy: 0.0750 - val_loss: 4.8594 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 4.9956 - accuracy: 0.1000 - val_loss: 4.8172 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 5.4865 - accuracy: 0.0500 - val_loss: 4.7599 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 5.7894 - accuracy: 0.0500 - val_loss: 4.7226 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 5.2371 - accuracy: 0.0500 - val_loss: 4.6676 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 5.2109 - accuracy: 0.0500 - val_loss: 4.6451 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 5.4327 - accuracy: 0.0250 - val_loss: 4.6487 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 4.7168 - accuracy: 0.1000 - val_loss: 4.6734 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 4.6193 - accuracy: 0.1000 - val_loss: 4.6676 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 4.7170 - accuracy: 0.0750 - val_loss: 4.6129 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 4.2631 - accuracy: 0.0513 - val_loss: 4.6100 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 4.3014 - accuracy: 0.0769 - val_loss: 4.5773 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 4.7605 - accuracy: 0.1000 - val_loss: 4.5647 - val_accuracy: 0.0660 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 4.8702 - accuracy: 0.0250 - val_loss: 4.5333 - val_accuracy: 0.0759 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 4.0531 - accuracy: 0.1000 - val_loss: 4.4982 - val_accuracy: 0.0759 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 4.8785 - accuracy: 0.0250 - val_loss: 4.4719 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 4.4668 - accuracy: 0.1500 - val_loss: 4.4782 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 4.3127 - accuracy: 0.0500 - val_loss: 4.4554 - val_accuracy: 0.0726 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 4.1000 - accuracy: 0.1500 - val_loss: 4.4217 - val_accuracy: 0.0825 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.1641 - accuracy: 0.1500 - val_loss: 4.3953 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 3.7944 - accuracy: 0.1000 - val_loss: 4.3767 - val_accuracy: 0.0924 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 4.2587 - accuracy: 0.1000 - val_loss: 4.3770 - val_accuracy: 0.0759 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 4.0464 - accuracy: 0.1500 - val_loss: 4.3589 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 4.3213 - accuracy: 0.0750 - val_loss: 4.3664 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 3.7510 - accuracy: 0.1750 - val_loss: 4.3540 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 3.3160 - accuracy: 0.1500 - val_loss: 4.3510 - val_accuracy: 0.0825 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 4.0452 - accuracy: 0.1750 - val_loss: 4.3590 - val_accuracy: 0.0825 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 3.9404 - accuracy: 0.1750 - val_loss: 4.3674 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 3.6911 - accuracy: 0.1500 - val_loss: 4.3646 - val_accuracy: 0.0792 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 3.7098 - accuracy: 0.1500 - val_loss: 4.3599 - val_accuracy: 0.0792 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 3.9183 - accuracy: 0.1500 - val_loss: 4.3547 - val_accuracy: 0.0726 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 3.6469 - accuracy: 0.1750 - val_loss: 4.3471 - val_accuracy: 0.0792 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 3.6468 - accuracy: 0.1750 - val_loss: 4.3451 - val_accuracy: 0.0726 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 3.3424 - accuracy: 0.2250 - val_loss: 4.3423 - val_accuracy: 0.0726 - lr: 1.0000e-05\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 3.6272 - accuracy: 0.2000 - val_loss: 4.3393 - val_accuracy: 0.0759 - lr: 1.0000e-05\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 2.9934 - accuracy: 0.2500 - val_loss: 4.3383 - val_accuracy: 0.0792 - lr: 1.0000e-05\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 3.2198 - accuracy: 0.3250 - val_loss: 4.3363 - val_accuracy: 0.0792 - lr: 1.0000e-05\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 3.2917 - accuracy: 0.2000 - val_loss: 4.3343 - val_accuracy: 0.0858 - lr: 1.0000e-05\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 3.7169 - accuracy: 0.2500 - val_loss: 4.3333 - val_accuracy: 0.0825 - lr: 1.0000e-06\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 3.6634 - accuracy: 0.2250 - val_loss: 4.3313 - val_accuracy: 0.0825 - lr: 1.0000e-06\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 3.4785 - accuracy: 0.1500 - val_loss: 4.3296 - val_accuracy: 0.0825 - lr: 1.0000e-06\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 4.2871 - accuracy: 0.1500 - val_loss: 4.3297 - val_accuracy: 0.0792 - lr: 1.0000e-06\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 3.2583 - accuracy: 0.2500 - val_loss: 4.3298 - val_accuracy: 0.0792 - lr: 1.0000e-06\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 3.4900 - accuracy: 0.2750 - val_loss: 4.3304 - val_accuracy: 0.0726 - lr: 1.0000e-07\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 3.8943 - accuracy: 0.0750 - val_loss: 4.3316 - val_accuracy: 0.0759 - lr: 1.0000e-07\n",
            "#3\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 5s 631ms/step - loss: 8.2261 - accuracy: 0.0000e+00 - val_loss: 18.2330 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 7.9753 - accuracy: 0.0000e+00 - val_loss: 12.4432 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 6.9424 - accuracy: 0.0000e+00 - val_loss: 10.3832 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 7.1543 - accuracy: 0.0500 - val_loss: 8.6478 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 7.0872 - accuracy: 0.0000e+00 - val_loss: 7.9072 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 6.7645 - accuracy: 0.0250 - val_loss: 7.2033 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 6.6553 - accuracy: 0.0250 - val_loss: 6.6836 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 6.4399 - accuracy: 0.0250 - val_loss: 6.2376 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 6.3148 - accuracy: 0.0000e+00 - val_loss: 5.9259 - val_accuracy: 0.0231 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 5.8493 - accuracy: 0.0500 - val_loss: 5.6891 - val_accuracy: 0.0264 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 7.1345 - accuracy: 0.0000e+00 - val_loss: 5.5113 - val_accuracy: 0.0264 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 6.2400 - accuracy: 0.0250 - val_loss: 5.3867 - val_accuracy: 0.0330 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 6.4593 - accuracy: 0.0250 - val_loss: 5.2895 - val_accuracy: 0.0330 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 5.7332 - accuracy: 0.0750 - val_loss: 5.1982 - val_accuracy: 0.0363 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 6.9198 - accuracy: 0.0000e+00 - val_loss: 5.1319 - val_accuracy: 0.0330 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 6.7402 - accuracy: 0.0500 - val_loss: 5.0669 - val_accuracy: 0.0363 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 7.0095 - accuracy: 0.0250 - val_loss: 5.0120 - val_accuracy: 0.0264 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 6.1587 - accuracy: 0.0500 - val_loss: 4.9534 - val_accuracy: 0.0330 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 6.2488 - accuracy: 0.0000e+00 - val_loss: 4.9261 - val_accuracy: 0.0330 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 5.9642 - accuracy: 0.0750 - val_loss: 4.8904 - val_accuracy: 0.0330 - lr: 1.0000e-05\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 6.4261 - accuracy: 0.0256 - val_loss: 4.8677 - val_accuracy: 0.0330 - lr: 1.0000e-05\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 6.5415 - accuracy: 0.0000e+00 - val_loss: 4.8456 - val_accuracy: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 6.3232 - accuracy: 0.0250 - val_loss: 4.8203 - val_accuracy: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 5.9582 - accuracy: 0.0750 - val_loss: 4.7933 - val_accuracy: 0.0396 - lr: 1.0000e-05\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 6.6640 - accuracy: 0.0250 - val_loss: 4.7807 - val_accuracy: 0.0396 - lr: 1.0000e-05\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 6.6819 - accuracy: 0.0250 - val_loss: 4.7688 - val_accuracy: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 6.7034 - accuracy: 0.1000 - val_loss: 4.7609 - val_accuracy: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 5.6788 - accuracy: 0.0500 - val_loss: 4.7534 - val_accuracy: 0.0330 - lr: 1.0000e-05\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 6.5757 - accuracy: 0.0250 - val_loss: 4.7470 - val_accuracy: 0.0297 - lr: 1.0000e-05\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 6.5104 - accuracy: 0.0250 - val_loss: 4.7338 - val_accuracy: 0.0297 - lr: 1.0000e-06\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 6.2600 - accuracy: 0.0250 - val_loss: 4.7252 - val_accuracy: 0.0330 - lr: 1.0000e-06\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 6.2742 - accuracy: 0.0500 - val_loss: 4.7222 - val_accuracy: 0.0330 - lr: 1.0000e-06\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 6.4513 - accuracy: 0.0750 - val_loss: 4.7163 - val_accuracy: 0.0330 - lr: 1.0000e-06\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 6.2192 - accuracy: 0.0000e+00 - val_loss: 4.7142 - val_accuracy: 0.0330 - lr: 1.0000e-06\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 6.5200 - accuracy: 0.0000e+00 - val_loss: 4.7151 - val_accuracy: 0.0330 - lr: 1.0000e-07\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 6.7060 - accuracy: 0.0250 - val_loss: 4.7091 - val_accuracy: 0.0330 - lr: 1.0000e-07\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 6.0087 - accuracy: 0.0250 - val_loss: 4.7067 - val_accuracy: 0.0330 - lr: 1.0000e-07\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 6.4386 - accuracy: 0.0000e+00 - val_loss: 4.7046 - val_accuracy: 0.0330 - lr: 1.0000e-07\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 6.5603 - accuracy: 0.0000e+00 - val_loss: 4.7027 - val_accuracy: 0.0330 - lr: 1.0000e-07\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 6.5262 - accuracy: 0.0000e+00 - val_loss: 4.6988 - val_accuracy: 0.0330 - lr: 1.0000e-08\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 6.6308 - accuracy: 0.0250 - val_loss: 4.6997 - val_accuracy: 0.0330 - lr: 1.0000e-08\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 6.8042 - accuracy: 0.0000e+00 - val_loss: 4.6975 - val_accuracy: 0.0330 - lr: 1.0000e-08\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 5.9800 - accuracy: 0.0250 - val_loss: 4.6967 - val_accuracy: 0.0330 - lr: 1.0000e-08\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 6.6866 - accuracy: 0.0250 - val_loss: 4.6919 - val_accuracy: 0.0330 - lr: 1.0000e-08\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 6.9315 - accuracy: 0.0250 - val_loss: 4.6918 - val_accuracy: 0.0330 - lr: 1.0000e-09\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 6.9423 - accuracy: 0.0000e+00 - val_loss: 4.6914 - val_accuracy: 0.0330 - lr: 1.0000e-09\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 7.0354 - accuracy: 0.0750 - val_loss: 4.6924 - val_accuracy: 0.0330 - lr: 1.0000e-09\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 6.4013 - accuracy: 0.0256 - val_loss: 4.6909 - val_accuracy: 0.0330 - lr: 1.0000e-09\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 6.0165 - accuracy: 0.0250 - val_loss: 4.6927 - val_accuracy: 0.0330 - lr: 1.0000e-09\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 5.9303 - accuracy: 0.1000 - val_loss: 4.6924 - val_accuracy: 0.0330 - lr: 1.0000e-10\n",
            "#4\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 626ms/step - loss: 5.6221 - accuracy: 0.0000e+00 - val_loss: 18.3846 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 5.9763 - accuracy: 0.0500 - val_loss: 12.8423 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 5.2293 - accuracy: 0.0500 - val_loss: 9.9924 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 5.3446 - accuracy: 0.0500 - val_loss: 8.2944 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 5.6716 - accuracy: 0.0750 - val_loss: 7.1033 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 4.6843 - accuracy: 0.1000 - val_loss: 6.3311 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 4.4485 - accuracy: 0.0500 - val_loss: 5.7439 - val_accuracy: 0.0759 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 4.0045 - accuracy: 0.2250 - val_loss: 5.2540 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 3.0576 - accuracy: 0.2821 - val_loss: 4.8706 - val_accuracy: 0.1089 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 3.3036 - accuracy: 0.3077 - val_loss: 4.6137 - val_accuracy: 0.1353 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 3.6338 - accuracy: 0.2750 - val_loss: 4.3770 - val_accuracy: 0.1518 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 2.9844 - accuracy: 0.3250 - val_loss: 4.1450 - val_accuracy: 0.1815 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 3.6063 - accuracy: 0.2000 - val_loss: 3.9900 - val_accuracy: 0.1815 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 3.1603 - accuracy: 0.3000 - val_loss: 3.8399 - val_accuracy: 0.2112 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 2.4560 - accuracy: 0.4750 - val_loss: 3.7351 - val_accuracy: 0.2277 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 2.3784 - accuracy: 0.3750 - val_loss: 3.6176 - val_accuracy: 0.2376 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 2.7140 - accuracy: 0.4359 - val_loss: 3.5006 - val_accuracy: 0.2640 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 2.3435 - accuracy: 0.4500 - val_loss: 3.4198 - val_accuracy: 0.2772 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 1.6039 - accuracy: 0.6250 - val_loss: 3.3492 - val_accuracy: 0.2838 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 2.3433 - accuracy: 0.5500 - val_loss: 3.2813 - val_accuracy: 0.2805 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 2.3092 - accuracy: 0.4000 - val_loss: 3.2265 - val_accuracy: 0.2937 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 1.9007 - accuracy: 0.6000 - val_loss: 3.1957 - val_accuracy: 0.3135 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 1.4869 - accuracy: 0.6750 - val_loss: 3.1548 - val_accuracy: 0.3432 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 1.2543 - accuracy: 0.7250 - val_loss: 3.1260 - val_accuracy: 0.3564 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 1.5217 - accuracy: 0.7250 - val_loss: 3.0804 - val_accuracy: 0.3597 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 1.5962 - accuracy: 0.6750 - val_loss: 3.0503 - val_accuracy: 0.3630 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 1.4322 - accuracy: 0.7250 - val_loss: 3.0110 - val_accuracy: 0.3696 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 1.3818 - accuracy: 0.6500 - val_loss: 2.9908 - val_accuracy: 0.3696 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 1.4313 - accuracy: 0.7000 - val_loss: 2.9779 - val_accuracy: 0.3729 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 1.6074 - accuracy: 0.6500 - val_loss: 2.9440 - val_accuracy: 0.3828 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 1.3362 - accuracy: 0.7000 - val_loss: 2.9206 - val_accuracy: 0.3927 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 1.2434 - accuracy: 0.7500 - val_loss: 2.9023 - val_accuracy: 0.3927 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 1.1606 - accuracy: 0.8250 - val_loss: 2.8838 - val_accuracy: 0.3960 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.8892 - accuracy: 0.8718 - val_loss: 2.8696 - val_accuracy: 0.4026 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 1.2417 - accuracy: 0.7750 - val_loss: 2.8343 - val_accuracy: 0.4158 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 1.4641 - accuracy: 0.6750 - val_loss: 2.8252 - val_accuracy: 0.4290 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 1.3087 - accuracy: 0.7500 - val_loss: 2.8107 - val_accuracy: 0.4323 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 0.7135 - accuracy: 0.9000 - val_loss: 2.7975 - val_accuracy: 0.4323 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 1.3226 - accuracy: 0.6750 - val_loss: 2.7794 - val_accuracy: 0.4323 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 1.1745 - accuracy: 0.7692 - val_loss: 2.7648 - val_accuracy: 0.4224 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 1.1283 - accuracy: 0.6750 - val_loss: 2.7430 - val_accuracy: 0.4257 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 0.5997 - accuracy: 0.8974 - val_loss: 2.7296 - val_accuracy: 0.4389 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 0.8582 - accuracy: 0.8250 - val_loss: 2.7242 - val_accuracy: 0.4554 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.8531 - accuracy: 0.8462 - val_loss: 2.7065 - val_accuracy: 0.4587 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 0.6666 - accuracy: 0.9000 - val_loss: 2.7039 - val_accuracy: 0.4554 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 0.7654 - accuracy: 0.9000 - val_loss: 2.6925 - val_accuracy: 0.4686 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 0.7039 - accuracy: 0.9000 - val_loss: 2.6856 - val_accuracy: 0.4818 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 0.7814 - accuracy: 0.8500 - val_loss: 2.6753 - val_accuracy: 0.4818 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 0.6642 - accuracy: 0.9000 - val_loss: 2.6717 - val_accuracy: 0.4785 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 0.7823 - accuracy: 0.8750 - val_loss: 2.6578 - val_accuracy: 0.4785 - lr: 0.0010\n",
            "#5\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 634ms/step - loss: 9.3954 - accuracy: 0.0000e+00 - val_loss: 19.1170 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 9.0019 - accuracy: 0.0250 - val_loss: 12.7115 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 8.0105 - accuracy: 0.0250 - val_loss: 10.2495 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 9.1777 - accuracy: 0.0000e+00 - val_loss: 8.4288 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 8.4363 - accuracy: 0.0000e+00 - val_loss: 7.5774 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 8.5802 - accuracy: 0.0000e+00 - val_loss: 7.0161 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 9.2721 - accuracy: 0.0000e+00 - val_loss: 6.4082 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 8.6776 - accuracy: 0.0000e+00 - val_loss: 6.1178 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 8.7917 - accuracy: 0.0000e+00 - val_loss: 5.7903 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 8.0559 - accuracy: 0.0000e+00 - val_loss: 5.5377 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 8.9079 - accuracy: 0.0256 - val_loss: 5.3261 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 9.3145 - accuracy: 0.0000e+00 - val_loss: 5.1622 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 7.2190 - accuracy: 0.0000e+00 - val_loss: 5.0793 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 8.4443 - accuracy: 0.0000e+00 - val_loss: 5.0266 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 9.7133 - accuracy: 0.0000e+00 - val_loss: 4.9564 - val_accuracy: 0.0165 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 8.7273 - accuracy: 0.0000e+00 - val_loss: 4.9072 - val_accuracy: 0.0165 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 8.7890 - accuracy: 0.0000e+00 - val_loss: 4.8769 - val_accuracy: 0.0165 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 7.7411 - accuracy: 0.0000e+00 - val_loss: 4.8464 - val_accuracy: 0.0132 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 7.9270 - accuracy: 0.0500 - val_loss: 4.8210 - val_accuracy: 0.0132 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 8.7287 - accuracy: 0.0000e+00 - val_loss: 4.8001 - val_accuracy: 0.0132 - lr: 1.0000e-05\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 8.0544 - accuracy: 0.0250 - val_loss: 4.7849 - val_accuracy: 0.0132 - lr: 1.0000e-05\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 8.5278 - accuracy: 0.0000e+00 - val_loss: 4.7690 - val_accuracy: 0.0099 - lr: 1.0000e-05\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 8.5595 - accuracy: 0.0000e+00 - val_loss: 4.7555 - val_accuracy: 0.0099 - lr: 1.0000e-05\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 8.3274 - accuracy: 0.0000e+00 - val_loss: 4.7449 - val_accuracy: 0.0099 - lr: 1.0000e-05\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 8.8215 - accuracy: 0.0000e+00 - val_loss: 4.7385 - val_accuracy: 0.0099 - lr: 1.0000e-06\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 8.0697 - accuracy: 0.0000e+00 - val_loss: 4.7329 - val_accuracy: 0.0099 - lr: 1.0000e-06\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 8.1761 - accuracy: 0.0500 - val_loss: 4.7301 - val_accuracy: 0.0099 - lr: 1.0000e-06\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 7.9503 - accuracy: 0.0500 - val_loss: 4.7251 - val_accuracy: 0.0132 - lr: 1.0000e-06\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 8.0707 - accuracy: 0.0000e+00 - val_loss: 4.7233 - val_accuracy: 0.0132 - lr: 1.0000e-06\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 8.1813 - accuracy: 0.0000e+00 - val_loss: 4.7185 - val_accuracy: 0.0132 - lr: 1.0000e-07\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 8.2371 - accuracy: 0.0250 - val_loss: 4.7169 - val_accuracy: 0.0132 - lr: 1.0000e-07\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 9.0175 - accuracy: 0.0500 - val_loss: 4.7131 - val_accuracy: 0.0132 - lr: 1.0000e-07\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 8.5915 - accuracy: 0.0513 - val_loss: 4.7111 - val_accuracy: 0.0132 - lr: 1.0000e-07\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 8.4745 - accuracy: 0.0250 - val_loss: 4.7091 - val_accuracy: 0.0132 - lr: 1.0000e-07\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 7.9536 - accuracy: 0.0000e+00 - val_loss: 4.7075 - val_accuracy: 0.0132 - lr: 1.0000e-08\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 8.3625 - accuracy: 0.0000e+00 - val_loss: 4.7052 - val_accuracy: 0.0132 - lr: 1.0000e-08\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 9.6898 - accuracy: 0.0000e+00 - val_loss: 4.7066 - val_accuracy: 0.0165 - lr: 1.0000e-08\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 8.5137 - accuracy: 0.0250 - val_loss: 4.7058 - val_accuracy: 0.0165 - lr: 1.0000e-08\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 8.8415 - accuracy: 0.0250 - val_loss: 4.7053 - val_accuracy: 0.0132 - lr: 1.0000e-08\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 8.2560 - accuracy: 0.0500 - val_loss: 4.7053 - val_accuracy: 0.0132 - lr: 1.0000e-09\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 8.3760 - accuracy: 0.0250 - val_loss: 4.7065 - val_accuracy: 0.0165 - lr: 1.0000e-09\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 9.0273 - accuracy: 0.0250 - val_loss: 4.7050 - val_accuracy: 0.0132 - lr: 1.0000e-09\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 8.5638 - accuracy: 0.0000e+00 - val_loss: 4.7050 - val_accuracy: 0.0165 - lr: 1.0000e-09\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 8.4810 - accuracy: 0.0000e+00 - val_loss: 4.7054 - val_accuracy: 0.0165 - lr: 1.0000e-09\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 8.8653 - accuracy: 0.0000e+00 - val_loss: 4.7063 - val_accuracy: 0.0165 - lr: 1.0000e-10\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 8.4947 - accuracy: 0.0500 - val_loss: 4.7064 - val_accuracy: 0.0198 - lr: 1.0000e-10\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 8.2314 - accuracy: 0.0000e+00 - val_loss: 4.7069 - val_accuracy: 0.0198 - lr: 1.0000e-10\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 8.3921 - accuracy: 0.0000e+00 - val_loss: 4.7048 - val_accuracy: 0.0198 - lr: 1.0000e-10\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 7.9649 - accuracy: 0.0000e+00 - val_loss: 4.7041 - val_accuracy: 0.0198 - lr: 1.0000e-10\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 7.5804 - accuracy: 0.0000e+00 - val_loss: 4.7050 - val_accuracy: 0.0198 - lr: 5.0000e-11\n",
            "#6\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 628ms/step - loss: 7.8672 - accuracy: 0.0000e+00 - val_loss: 5.2243 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 7.8410 - accuracy: 0.0000e+00 - val_loss: 5.1635 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 6.5871 - accuracy: 0.0250 - val_loss: 5.0399 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 6.9471 - accuracy: 0.0250 - val_loss: 4.9769 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 7.1772 - accuracy: 0.0250 - val_loss: 4.9168 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 6.4929 - accuracy: 0.0000e+00 - val_loss: 4.8999 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 6.1316 - accuracy: 0.0000e+00 - val_loss: 4.8516 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 6.9221 - accuracy: 0.0250 - val_loss: 4.8071 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 6.8321 - accuracy: 0.0000e+00 - val_loss: 4.7951 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 6.2415 - accuracy: 0.0250 - val_loss: 4.7674 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 6.4268 - accuracy: 0.0250 - val_loss: 4.7125 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 7.3864 - accuracy: 0.0250 - val_loss: 4.6837 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 6.0850 - accuracy: 0.0750 - val_loss: 4.6291 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 6.2158 - accuracy: 0.0250 - val_loss: 4.5790 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 6.3413 - accuracy: 0.0250 - val_loss: 4.5159 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 5.2338 - accuracy: 0.1000 - val_loss: 4.4804 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 5.9521 - accuracy: 0.0256 - val_loss: 4.4315 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 5.9009 - accuracy: 0.0250 - val_loss: 4.3861 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 5.5439 - accuracy: 0.1000 - val_loss: 4.3644 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 5.6724 - accuracy: 0.0500 - val_loss: 4.3147 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 5.6400 - accuracy: 0.0250 - val_loss: 4.2715 - val_accuracy: 0.0924 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 5.7678 - accuracy: 0.0513 - val_loss: 4.2460 - val_accuracy: 0.1122 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 6.1162 - accuracy: 0.0250 - val_loss: 4.2166 - val_accuracy: 0.1221 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 5.8553 - accuracy: 0.0750 - val_loss: 4.1810 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 5.9122 - accuracy: 0.0256 - val_loss: 4.1311 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 5.9971 - accuracy: 0.0250 - val_loss: 4.0881 - val_accuracy: 0.1353 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 5.4577 - accuracy: 0.0500 - val_loss: 4.0482 - val_accuracy: 0.1386 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 5.0816 - accuracy: 0.1026 - val_loss: 4.0248 - val_accuracy: 0.1353 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 5.3596 - accuracy: 0.0500 - val_loss: 3.9825 - val_accuracy: 0.1386 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 5.7495 - accuracy: 0.0500 - val_loss: 3.9602 - val_accuracy: 0.1452 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 5.7257 - accuracy: 0.0250 - val_loss: 3.9383 - val_accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 5.2264 - accuracy: 0.0769 - val_loss: 3.9104 - val_accuracy: 0.1584 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 5.5373 - accuracy: 0.0750 - val_loss: 3.8647 - val_accuracy: 0.1617 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 4.9982 - accuracy: 0.0500 - val_loss: 3.8472 - val_accuracy: 0.1518 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 5.4081 - accuracy: 0.0250 - val_loss: 3.8179 - val_accuracy: 0.1617 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 5.3841 - accuracy: 0.0250 - val_loss: 3.7956 - val_accuracy: 0.1716 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 4.3720 - accuracy: 0.0750 - val_loss: 3.7762 - val_accuracy: 0.1716 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 4.8207 - accuracy: 0.0750 - val_loss: 3.7605 - val_accuracy: 0.1815 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 5.0320 - accuracy: 0.1000 - val_loss: 3.7270 - val_accuracy: 0.1947 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 5.3352 - accuracy: 0.0500 - val_loss: 3.7115 - val_accuracy: 0.1914 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 4.7936 - accuracy: 0.0750 - val_loss: 3.6889 - val_accuracy: 0.1980 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 4.9777 - accuracy: 0.1250 - val_loss: 3.6843 - val_accuracy: 0.2013 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 5.1069 - accuracy: 0.1250 - val_loss: 3.6603 - val_accuracy: 0.1947 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 4.8092 - accuracy: 0.1000 - val_loss: 3.6367 - val_accuracy: 0.2046 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 5.6861 - accuracy: 0.0256 - val_loss: 3.6248 - val_accuracy: 0.2013 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 4.5212 - accuracy: 0.1500 - val_loss: 3.6123 - val_accuracy: 0.2079 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 4.7117 - accuracy: 0.1750 - val_loss: 3.5841 - val_accuracy: 0.2046 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 4.5796 - accuracy: 0.1250 - val_loss: 3.5543 - val_accuracy: 0.2310 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 4.7396 - accuracy: 0.0500 - val_loss: 3.5415 - val_accuracy: 0.2310 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 4.5091 - accuracy: 0.1250 - val_loss: 3.5278 - val_accuracy: 0.2178 - lr: 0.0010\n",
            "#7\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 622ms/step - loss: 9.0927 - accuracy: 0.0500 - val_loss: 18.0032 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 7.8573 - accuracy: 0.0500 - val_loss: 13.6967 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 8.9483 - accuracy: 0.0000e+00 - val_loss: 10.9069 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 8.7945 - accuracy: 0.0250 - val_loss: 8.7652 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 7.7839 - accuracy: 0.0500 - val_loss: 7.7927 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 7.4815 - accuracy: 0.0000e+00 - val_loss: 7.1033 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 7.8043 - accuracy: 0.0000e+00 - val_loss: 6.4924 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 7.8674 - accuracy: 0.0000e+00 - val_loss: 6.1893 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 8.4265 - accuracy: 0.0000e+00 - val_loss: 5.9941 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 7.8940 - accuracy: 0.0000e+00 - val_loss: 5.7144 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 8.1874 - accuracy: 0.0000e+00 - val_loss: 5.4500 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 7.3097 - accuracy: 0.0513 - val_loss: 5.2191 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 7.0277 - accuracy: 0.0000e+00 - val_loss: 5.1168 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 6.2696 - accuracy: 0.0250 - val_loss: 5.0253 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 7.4113 - accuracy: 0.0000e+00 - val_loss: 4.9488 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 7.4510 - accuracy: 0.0256 - val_loss: 4.8401 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 7.3579 - accuracy: 0.0750 - val_loss: 4.7575 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 7.7963 - accuracy: 0.0000e+00 - val_loss: 4.6846 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 6.9926 - accuracy: 0.0513 - val_loss: 4.5903 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 8.2878 - accuracy: 0.0000e+00 - val_loss: 4.5235 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 7.1477 - accuracy: 0.0000e+00 - val_loss: 4.4480 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 6.8449 - accuracy: 0.0500 - val_loss: 4.4022 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 6.3676 - accuracy: 0.0750 - val_loss: 4.3504 - val_accuracy: 0.0594 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 6.9123 - accuracy: 0.0250 - val_loss: 4.3724 - val_accuracy: 0.0594 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 6.7135 - accuracy: 0.0250 - val_loss: 4.3199 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 7.2855 - accuracy: 0.0000e+00 - val_loss: 4.3142 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 6.4441 - accuracy: 0.0250 - val_loss: 4.3046 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 6.4817 - accuracy: 0.0000e+00 - val_loss: 4.2461 - val_accuracy: 0.0825 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 6.4232 - accuracy: 0.0500 - val_loss: 4.1923 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 7.0139 - accuracy: 0.0750 - val_loss: 4.1596 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 6.8587 - accuracy: 0.0256 - val_loss: 4.1342 - val_accuracy: 0.0957 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 6.4813 - accuracy: 0.0500 - val_loss: 4.1116 - val_accuracy: 0.1023 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 6.2789 - accuracy: 0.1026 - val_loss: 4.1048 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 6.5848 - accuracy: 0.0250 - val_loss: 4.0770 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 6.4686 - accuracy: 0.0250 - val_loss: 4.0630 - val_accuracy: 0.0924 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 6.9870 - accuracy: 0.0250 - val_loss: 4.0306 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 6.8119 - accuracy: 0.0250 - val_loss: 4.0281 - val_accuracy: 0.0957 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 5.4435 - accuracy: 0.0769 - val_loss: 4.0281 - val_accuracy: 0.0924 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 6.2606 - accuracy: 0.0750 - val_loss: 4.0280 - val_accuracy: 0.0924 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 6.3940 - accuracy: 0.0513 - val_loss: 4.0258 - val_accuracy: 0.0924 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 5.9868 - accuracy: 0.0750 - val_loss: 4.0241 - val_accuracy: 0.0924 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 5.8263 - accuracy: 0.0250 - val_loss: 4.0245 - val_accuracy: 0.0924 - lr: 1.0000e-04\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 6.1220 - accuracy: 0.0513 - val_loss: 4.0248 - val_accuracy: 0.0924 - lr: 1.0000e-05\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 6.8592 - accuracy: 0.0250 - val_loss: 4.0272 - val_accuracy: 0.0957 - lr: 1.0000e-05\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 6.2735 - accuracy: 0.0500 - val_loss: 4.0264 - val_accuracy: 0.1023 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 6.1484 - accuracy: 0.0500 - val_loss: 4.0277 - val_accuracy: 0.0990 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 5.9452 - accuracy: 0.1250 - val_loss: 4.0275 - val_accuracy: 0.0957 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 6.4439 - accuracy: 0.0250 - val_loss: 4.0270 - val_accuracy: 0.0924 - lr: 1.0000e-06\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 6.4999 - accuracy: 0.0500 - val_loss: 4.0295 - val_accuracy: 0.0924 - lr: 1.0000e-06\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 7.2890 - accuracy: 0.0000e+00 - val_loss: 4.0306 - val_accuracy: 0.0957 - lr: 1.0000e-06\n",
            "#8\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 618ms/step - loss: 5.4148 - accuracy: 0.0250 - val_loss: 4.9623 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 5.0796 - accuracy: 0.0250 - val_loss: 4.9219 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 5.8024 - accuracy: 0.0500 - val_loss: 4.8591 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 5.0997 - accuracy: 0.0250 - val_loss: 4.8317 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 5.3479 - accuracy: 0.0250 - val_loss: 4.8348 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 5.1567 - accuracy: 0.0500 - val_loss: 4.7955 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 5.1486 - accuracy: 0.0500 - val_loss: 4.7421 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 5.3689 - accuracy: 0.0000e+00 - val_loss: 4.7422 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 5.4501 - accuracy: 0.0000e+00 - val_loss: 4.7560 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 4.6875 - accuracy: 0.0500 - val_loss: 4.7493 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 4.9953 - accuracy: 0.1000 - val_loss: 4.7415 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 4.7017 - accuracy: 0.0500 - val_loss: 4.7196 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 4.9409 - accuracy: 0.0513 - val_loss: 4.7120 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 4.4278 - accuracy: 0.1250 - val_loss: 4.6825 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 4.4424 - accuracy: 0.1000 - val_loss: 4.6816 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 4.5608 - accuracy: 0.0250 - val_loss: 4.6605 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 4.7215 - accuracy: 0.0000e+00 - val_loss: 4.6700 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 4.7652 - accuracy: 0.0500 - val_loss: 4.6408 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 4.3593 - accuracy: 0.0750 - val_loss: 4.6433 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 4.6935 - accuracy: 0.0250 - val_loss: 4.6060 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 4.5319 - accuracy: 0.0750 - val_loss: 4.5790 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 4.7174 - accuracy: 0.0000e+00 - val_loss: 4.5335 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 4.2795 - accuracy: 0.1000 - val_loss: 4.5253 - val_accuracy: 0.0396 - lr: 1.0000e-04\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 4.2313 - accuracy: 0.1282 - val_loss: 4.5191 - val_accuracy: 0.0429 - lr: 1.0000e-04\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 4.4026 - accuracy: 0.0500 - val_loss: 4.5153 - val_accuracy: 0.0396 - lr: 1.0000e-04\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.3273 - accuracy: 0.0750 - val_loss: 4.5121 - val_accuracy: 0.0396 - lr: 1.0000e-04\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 4.1177 - accuracy: 0.1000 - val_loss: 4.5069 - val_accuracy: 0.0429 - lr: 1.0000e-04\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.5449 - accuracy: 0.0500 - val_loss: 4.5050 - val_accuracy: 0.0429 - lr: 1.0000e-05\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 4.4378 - accuracy: 0.0250 - val_loss: 4.5023 - val_accuracy: 0.0429 - lr: 1.0000e-05\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 4.3405 - accuracy: 0.1000 - val_loss: 4.5004 - val_accuracy: 0.0462 - lr: 1.0000e-05\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 4.7081 - accuracy: 0.0256 - val_loss: 4.4983 - val_accuracy: 0.0462 - lr: 1.0000e-05\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 4.6072 - accuracy: 0.0250 - val_loss: 4.4962 - val_accuracy: 0.0462 - lr: 1.0000e-05\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.1021 - accuracy: 0.1282 - val_loss: 4.4948 - val_accuracy: 0.0462 - lr: 1.0000e-06\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 4.4600 - accuracy: 0.1000 - val_loss: 4.4953 - val_accuracy: 0.0495 - lr: 1.0000e-06\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.5700 - accuracy: 0.0750 - val_loss: 4.4948 - val_accuracy: 0.0495 - lr: 1.0000e-06\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 4.8958 - accuracy: 0.1000 - val_loss: 4.4943 - val_accuracy: 0.0495 - lr: 1.0000e-06\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 4.6523 - accuracy: 0.0500 - val_loss: 4.4943 - val_accuracy: 0.0495 - lr: 1.0000e-06\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 4.3437 - accuracy: 0.1250 - val_loss: 4.4937 - val_accuracy: 0.0528 - lr: 1.0000e-07\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 3.9194 - accuracy: 0.1500 - val_loss: 4.4958 - val_accuracy: 0.0528 - lr: 1.0000e-07\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 4.5490 - accuracy: 0.0500 - val_loss: 4.4969 - val_accuracy: 0.0495 - lr: 1.0000e-07\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 4.2538 - accuracy: 0.1000 - val_loss: 4.4984 - val_accuracy: 0.0495 - lr: 1.0000e-07\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 4.4585 - accuracy: 0.1250 - val_loss: 4.4995 - val_accuracy: 0.0462 - lr: 1.0000e-07\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.6238 - accuracy: 0.1000 - val_loss: 4.5010 - val_accuracy: 0.0462 - lr: 1.0000e-08\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 4.2759 - accuracy: 0.0750 - val_loss: 4.5025 - val_accuracy: 0.0462 - lr: 1.0000e-08\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 4.3739 - accuracy: 0.1000 - val_loss: 4.5039 - val_accuracy: 0.0462 - lr: 1.0000e-08\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 4.2065 - accuracy: 0.0750 - val_loss: 4.5049 - val_accuracy: 0.0495 - lr: 1.0000e-08\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 4.6638 - accuracy: 0.0000e+00 - val_loss: 4.5061 - val_accuracy: 0.0462 - lr: 1.0000e-08\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.6787 - accuracy: 0.0500 - val_loss: 4.5085 - val_accuracy: 0.0462 - lr: 1.0000e-09\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 4.1644 - accuracy: 0.1500 - val_loss: 4.5094 - val_accuracy: 0.0462 - lr: 1.0000e-09\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 4.5166 - accuracy: 0.0250 - val_loss: 4.5122 - val_accuracy: 0.0462 - lr: 1.0000e-09\n",
            "#9\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 619ms/step - loss: 5.0540 - accuracy: 0.0250 - val_loss: 16.2675 - val_accuracy: 0.0033 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 6.0313 - accuracy: 0.0000e+00 - val_loss: 12.0158 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 5.8427 - accuracy: 0.0250 - val_loss: 9.5327 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 5.4322 - accuracy: 0.0250 - val_loss: 8.1585 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 5.2496 - accuracy: 0.0250 - val_loss: 7.2239 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 5.2986 - accuracy: 0.0250 - val_loss: 6.5889 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 4.7054 - accuracy: 0.0250 - val_loss: 5.9934 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 5.2132 - accuracy: 0.0000e+00 - val_loss: 5.8640 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 4.9021 - accuracy: 0.0000e+00 - val_loss: 5.5593 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 4.3512 - accuracy: 0.0750 - val_loss: 5.2840 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 4.8727 - accuracy: 0.0500 - val_loss: 5.0007 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 4.7404 - accuracy: 0.0500 - val_loss: 4.8874 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 4.1627 - accuracy: 0.1000 - val_loss: 4.7567 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 4.5299 - accuracy: 0.1000 - val_loss: 4.6877 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 4.7040 - accuracy: 0.0500 - val_loss: 4.5782 - val_accuracy: 0.0726 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 4.7285 - accuracy: 0.0500 - val_loss: 4.4992 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 3.8497 - accuracy: 0.0500 - val_loss: 4.4434 - val_accuracy: 0.0759 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 4.6386 - accuracy: 0.0750 - val_loss: 4.4043 - val_accuracy: 0.0759 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 4.7078 - accuracy: 0.0250 - val_loss: 4.3526 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 4.2316 - accuracy: 0.0513 - val_loss: 4.3187 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 4.4183 - accuracy: 0.0500 - val_loss: 4.2717 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 4.2030 - accuracy: 0.0750 - val_loss: 4.2203 - val_accuracy: 0.1221 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 4.1181 - accuracy: 0.0750 - val_loss: 4.2009 - val_accuracy: 0.1089 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 4.6913 - accuracy: 0.0750 - val_loss: 4.1629 - val_accuracy: 0.1221 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 3.7902 - accuracy: 0.1250 - val_loss: 4.1298 - val_accuracy: 0.1353 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 3.7522 - accuracy: 0.1250 - val_loss: 4.0926 - val_accuracy: 0.1287 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 3.7418 - accuracy: 0.2000 - val_loss: 4.0859 - val_accuracy: 0.1320 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 3.8335 - accuracy: 0.1000 - val_loss: 4.0728 - val_accuracy: 0.1353 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 3.7074 - accuracy: 0.1282 - val_loss: 4.0426 - val_accuracy: 0.1320 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 3.5825 - accuracy: 0.1500 - val_loss: 4.0260 - val_accuracy: 0.1419 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 3.9227 - accuracy: 0.1000 - val_loss: 4.0231 - val_accuracy: 0.1452 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 3.9536 - accuracy: 0.0250 - val_loss: 4.0227 - val_accuracy: 0.1386 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 3.7704 - accuracy: 0.1500 - val_loss: 4.0109 - val_accuracy: 0.1518 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 3.8471 - accuracy: 0.1000 - val_loss: 4.0055 - val_accuracy: 0.1419 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 3.8043 - accuracy: 0.1250 - val_loss: 3.9902 - val_accuracy: 0.1518 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 3.3834 - accuracy: 0.1500 - val_loss: 3.9855 - val_accuracy: 0.1452 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 3.0208 - accuracy: 0.2500 - val_loss: 3.9835 - val_accuracy: 0.1353 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 3.3184 - accuracy: 0.2000 - val_loss: 3.9763 - val_accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 3.5607 - accuracy: 0.1000 - val_loss: 3.9787 - val_accuracy: 0.1419 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 2.9588 - accuracy: 0.2250 - val_loss: 3.9823 - val_accuracy: 0.1419 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 3.4964 - accuracy: 0.1250 - val_loss: 3.9829 - val_accuracy: 0.1485 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 3.5593 - accuracy: 0.1500 - val_loss: 3.9833 - val_accuracy: 0.1452 - lr: 1.0000e-04\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 3.5776 - accuracy: 0.2500 - val_loss: 3.9881 - val_accuracy: 0.1419 - lr: 1.0000e-04\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 3.3843 - accuracy: 0.1750 - val_loss: 3.9960 - val_accuracy: 0.1419 - lr: 1.0000e-05\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 3.4403 - accuracy: 0.2250 - val_loss: 3.9968 - val_accuracy: 0.1419 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 3.8383 - accuracy: 0.0750 - val_loss: 4.0014 - val_accuracy: 0.1353 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 3.5734 - accuracy: 0.2000 - val_loss: 4.0029 - val_accuracy: 0.1320 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 3.3051 - accuracy: 0.3000 - val_loss: 4.0047 - val_accuracy: 0.1386 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 3.7693 - accuracy: 0.1750 - val_loss: 4.0058 - val_accuracy: 0.1320 - lr: 1.0000e-06\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 3.7145 - accuracy: 0.1250 - val_loss: 4.0074 - val_accuracy: 0.1386 - lr: 1.0000e-06\n",
            "#10\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 623ms/step - loss: 5.5102 - accuracy: 0.0000e+00 - val_loss: 4.9557 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 5.4680 - accuracy: 0.0000e+00 - val_loss: 4.9001 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 5.6337 - accuracy: 0.0250 - val_loss: 4.8585 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 5.5008 - accuracy: 0.0250 - val_loss: 4.8226 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 5.8039 - accuracy: 0.0000e+00 - val_loss: 4.7928 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 5.5506 - accuracy: 0.0000e+00 - val_loss: 4.7541 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 5.2570 - accuracy: 0.0500 - val_loss: 4.7091 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 4.6942 - accuracy: 0.0250 - val_loss: 4.6651 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 5.0210 - accuracy: 0.0000e+00 - val_loss: 4.6367 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 5.1669 - accuracy: 0.0000e+00 - val_loss: 4.6085 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 5.1909 - accuracy: 0.0250 - val_loss: 4.5728 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 4.9548 - accuracy: 0.0500 - val_loss: 4.5527 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 5.3847 - accuracy: 0.0250 - val_loss: 4.5141 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 5.1443 - accuracy: 0.0250 - val_loss: 4.4842 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 5.2055 - accuracy: 0.0250 - val_loss: 4.4514 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 5.0094 - accuracy: 0.0000e+00 - val_loss: 4.4183 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 5.0228 - accuracy: 0.0250 - val_loss: 4.3914 - val_accuracy: 0.0528 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 4.9952 - accuracy: 0.0250 - val_loss: 4.3753 - val_accuracy: 0.0528 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 5.0229 - accuracy: 0.0513 - val_loss: 4.3513 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 4.4556 - accuracy: 0.0250 - val_loss: 4.3212 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 5.0858 - accuracy: 0.0250 - val_loss: 4.2918 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 4.5284 - accuracy: 0.1000 - val_loss: 4.2636 - val_accuracy: 0.0825 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 4.4527 - accuracy: 0.0750 - val_loss: 4.2335 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 4.7512 - accuracy: 0.0250 - val_loss: 4.2182 - val_accuracy: 0.0924 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 4.6509 - accuracy: 0.0750 - val_loss: 4.1934 - val_accuracy: 0.1056 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.4006 - accuracy: 0.0750 - val_loss: 4.1579 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.3562 - accuracy: 0.1750 - val_loss: 4.1283 - val_accuracy: 0.1056 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 4.6977 - accuracy: 0.0250 - val_loss: 4.0983 - val_accuracy: 0.1122 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 4.6607 - accuracy: 0.0500 - val_loss: 4.0726 - val_accuracy: 0.1122 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 4.4000 - accuracy: 0.0750 - val_loss: 4.0503 - val_accuracy: 0.1089 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 4.6093 - accuracy: 0.0750 - val_loss: 4.0311 - val_accuracy: 0.1287 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.4275 - accuracy: 0.0513 - val_loss: 4.0125 - val_accuracy: 0.1254 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 3.9752 - accuracy: 0.0750 - val_loss: 3.9871 - val_accuracy: 0.1221 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 5.2148 - accuracy: 0.0250 - val_loss: 3.9523 - val_accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 4.0792 - accuracy: 0.0250 - val_loss: 3.9179 - val_accuracy: 0.1551 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 4.2049 - accuracy: 0.0250 - val_loss: 3.8906 - val_accuracy: 0.1584 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 4.5205 - accuracy: 0.0000e+00 - val_loss: 3.8655 - val_accuracy: 0.1782 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.0263 - accuracy: 0.0500 - val_loss: 3.8492 - val_accuracy: 0.1749 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 4.5150 - accuracy: 0.0000e+00 - val_loss: 3.8280 - val_accuracy: 0.1881 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 3.8414 - accuracy: 0.1000 - val_loss: 3.8080 - val_accuracy: 0.1848 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 4.5676 - accuracy: 0.0500 - val_loss: 3.7860 - val_accuracy: 0.1881 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.2335 - accuracy: 0.0750 - val_loss: 3.7606 - val_accuracy: 0.2145 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.2634 - accuracy: 0.1000 - val_loss: 3.7342 - val_accuracy: 0.2244 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 4.1135 - accuracy: 0.0500 - val_loss: 3.7182 - val_accuracy: 0.2343 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 4.1226 - accuracy: 0.0769 - val_loss: 3.6973 - val_accuracy: 0.2475 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 4.0699 - accuracy: 0.1500 - val_loss: 3.6844 - val_accuracy: 0.2409 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 3.9987 - accuracy: 0.1000 - val_loss: 3.6622 - val_accuracy: 0.2310 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 3.7910 - accuracy: 0.0769 - val_loss: 3.6439 - val_accuracy: 0.2442 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 4.5665 - accuracy: 0.0500 - val_loss: 3.6207 - val_accuracy: 0.2343 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 3.8654 - accuracy: 0.0750 - val_loss: 3.6048 - val_accuracy: 0.2409 - lr: 0.0010\n",
            "#11\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 626ms/step - loss: 6.9015 - accuracy: 0.0000e+00 - val_loss: 5.1576 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 6.6359 - accuracy: 0.0000e+00 - val_loss: 5.1467 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 7.2006 - accuracy: 0.0250 - val_loss: 5.0903 - val_accuracy: 0.0033 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 6.3706 - accuracy: 0.0000e+00 - val_loss: 5.0890 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 6.9579 - accuracy: 0.0000e+00 - val_loss: 5.0871 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 6.9849 - accuracy: 0.0000e+00 - val_loss: 5.0323 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 6.7923 - accuracy: 0.0256 - val_loss: 5.0702 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 6.8687 - accuracy: 0.0000e+00 - val_loss: 5.0771 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 6.8034 - accuracy: 0.0500 - val_loss: 5.0832 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 7.2097 - accuracy: 0.0000e+00 - val_loss: 5.0739 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 6.8164 - accuracy: 0.0000e+00 - val_loss: 5.0582 - val_accuracy: 0.0033 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 6.0530 - accuracy: 0.0250 - val_loss: 5.0292 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 7.0454 - accuracy: 0.0000e+00 - val_loss: 5.0261 - val_accuracy: 0.0165 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 6.7888 - accuracy: 0.0000e+00 - val_loss: 5.0317 - val_accuracy: 0.0165 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 6.9291 - accuracy: 0.0000e+00 - val_loss: 5.0254 - val_accuracy: 0.0198 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 7.0634 - accuracy: 0.0000e+00 - val_loss: 5.0310 - val_accuracy: 0.0198 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 7.1088 - accuracy: 0.0000e+00 - val_loss: 5.0348 - val_accuracy: 0.0165 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 6.9395 - accuracy: 0.0000e+00 - val_loss: 5.0358 - val_accuracy: 0.0165 - lr: 1.0000e-05\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 6.6580 - accuracy: 0.0250 - val_loss: 5.0368 - val_accuracy: 0.0165 - lr: 1.0000e-05\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 5.8988 - accuracy: 0.0500 - val_loss: 5.0380 - val_accuracy: 0.0165 - lr: 1.0000e-05\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 7.2853 - accuracy: 0.0000e+00 - val_loss: 5.0395 - val_accuracy: 0.0165 - lr: 1.0000e-05\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 6.7581 - accuracy: 0.0250 - val_loss: 5.0413 - val_accuracy: 0.0165 - lr: 1.0000e-05\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 6.9287 - accuracy: 0.0000e+00 - val_loss: 5.0442 - val_accuracy: 0.0165 - lr: 1.0000e-06\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 7.2286 - accuracy: 0.0250 - val_loss: 5.0453 - val_accuracy: 0.0165 - lr: 1.0000e-06\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 7.1387 - accuracy: 0.0000e+00 - val_loss: 5.0465 - val_accuracy: 0.0165 - lr: 1.0000e-06\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 6.9775 - accuracy: 0.0000e+00 - val_loss: 5.0483 - val_accuracy: 0.0165 - lr: 1.0000e-06\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 6.3129 - accuracy: 0.0000e+00 - val_loss: 5.0508 - val_accuracy: 0.0165 - lr: 1.0000e-06\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 6.9108 - accuracy: 0.0000e+00 - val_loss: 5.0530 - val_accuracy: 0.0165 - lr: 1.0000e-07\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 6.4369 - accuracy: 0.0000e+00 - val_loss: 5.0551 - val_accuracy: 0.0165 - lr: 1.0000e-07\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 6.5649 - accuracy: 0.0000e+00 - val_loss: 5.0571 - val_accuracy: 0.0132 - lr: 1.0000e-07\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 6.7015 - accuracy: 0.0250 - val_loss: 5.0601 - val_accuracy: 0.0099 - lr: 1.0000e-07\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 6.3552 - accuracy: 0.0000e+00 - val_loss: 5.0631 - val_accuracy: 0.0132 - lr: 1.0000e-07\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 7.1008 - accuracy: 0.0000e+00 - val_loss: 5.0644 - val_accuracy: 0.0165 - lr: 1.0000e-08\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 6.8720 - accuracy: 0.0000e+00 - val_loss: 5.0669 - val_accuracy: 0.0165 - lr: 1.0000e-08\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 6.9982 - accuracy: 0.0000e+00 - val_loss: 5.0673 - val_accuracy: 0.0165 - lr: 1.0000e-08\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 7.4064 - accuracy: 0.0000e+00 - val_loss: 5.0684 - val_accuracy: 0.0165 - lr: 1.0000e-08\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 6.9251 - accuracy: 0.0000e+00 - val_loss: 5.0715 - val_accuracy: 0.0132 - lr: 1.0000e-08\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 6.4732 - accuracy: 0.0000e+00 - val_loss: 5.0720 - val_accuracy: 0.0132 - lr: 1.0000e-09\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 6.2824 - accuracy: 0.0000e+00 - val_loss: 5.0738 - val_accuracy: 0.0132 - lr: 1.0000e-09\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 7.2581 - accuracy: 0.0000e+00 - val_loss: 5.0755 - val_accuracy: 0.0132 - lr: 1.0000e-09\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 6.4528 - accuracy: 0.0250 - val_loss: 5.0780 - val_accuracy: 0.0132 - lr: 1.0000e-09\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 6.6604 - accuracy: 0.0000e+00 - val_loss: 5.0798 - val_accuracy: 0.0132 - lr: 1.0000e-09\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 6.7378 - accuracy: 0.0000e+00 - val_loss: 5.0824 - val_accuracy: 0.0132 - lr: 1.0000e-10\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 6.3857 - accuracy: 0.0000e+00 - val_loss: 5.0851 - val_accuracy: 0.0132 - lr: 1.0000e-10\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 6.7683 - accuracy: 0.0250 - val_loss: 5.0862 - val_accuracy: 0.0132 - lr: 1.0000e-10\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 6.7259 - accuracy: 0.0000e+00 - val_loss: 5.0885 - val_accuracy: 0.0165 - lr: 1.0000e-10\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 6.4679 - accuracy: 0.0500 - val_loss: 5.0900 - val_accuracy: 0.0132 - lr: 1.0000e-10\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 6.3720 - accuracy: 0.0500 - val_loss: 5.0928 - val_accuracy: 0.0165 - lr: 5.0000e-11\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 6.8735 - accuracy: 0.0000e+00 - val_loss: 5.0952 - val_accuracy: 0.0132 - lr: 5.0000e-11\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 6.5966 - accuracy: 0.0250 - val_loss: 5.0956 - val_accuracy: 0.0132 - lr: 5.0000e-11\n",
            "#12\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 5s 632ms/step - loss: 4.9476 - accuracy: 0.0256 - val_loss: 4.9132 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 5.3579 - accuracy: 0.1000 - val_loss: 4.7687 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.1742 - accuracy: 0.2000 - val_loss: 4.6706 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 3.6271 - accuracy: 0.2750 - val_loss: 4.5794 - val_accuracy: 0.0528 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 3.6183 - accuracy: 0.2750 - val_loss: 4.4716 - val_accuracy: 0.0660 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 2.7489 - accuracy: 0.5128 - val_loss: 4.3943 - val_accuracy: 0.0759 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 2.4624 - accuracy: 0.5750 - val_loss: 4.3280 - val_accuracy: 0.0891 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 2.1452 - accuracy: 0.5641 - val_loss: 4.2698 - val_accuracy: 0.1023 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 1.7366 - accuracy: 0.7500 - val_loss: 4.2141 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 1.8121 - accuracy: 0.7000 - val_loss: 4.1443 - val_accuracy: 0.1386 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 2.1545 - accuracy: 0.5750 - val_loss: 4.0794 - val_accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 1.3347 - accuracy: 0.8000 - val_loss: 4.0432 - val_accuracy: 0.1716 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 1.9063 - accuracy: 0.6250 - val_loss: 3.9760 - val_accuracy: 0.1881 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 1.5594 - accuracy: 0.7750 - val_loss: 3.9296 - val_accuracy: 0.2013 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 1.4362 - accuracy: 0.7750 - val_loss: 3.8788 - val_accuracy: 0.2343 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 0.8646 - accuracy: 0.8750 - val_loss: 3.8384 - val_accuracy: 0.2343 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 0.9126 - accuracy: 0.8718 - val_loss: 3.8006 - val_accuracy: 0.2409 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 1.1420 - accuracy: 0.8000 - val_loss: 3.7624 - val_accuracy: 0.2442 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 1.0690 - accuracy: 0.8750 - val_loss: 3.7192 - val_accuracy: 0.2442 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 0.7796 - accuracy: 0.8750 - val_loss: 3.6829 - val_accuracy: 0.2574 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 0.4562 - accuracy: 0.9500 - val_loss: 3.6504 - val_accuracy: 0.2574 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 0.8052 - accuracy: 0.8718 - val_loss: 3.6221 - val_accuracy: 0.2706 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 0.5641 - accuracy: 0.9500 - val_loss: 3.5972 - val_accuracy: 0.2739 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 0.4954 - accuracy: 0.9500 - val_loss: 3.5682 - val_accuracy: 0.2970 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 0.6389 - accuracy: 0.9000 - val_loss: 3.5330 - val_accuracy: 0.3102 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.4012 - accuracy: 0.9750 - val_loss: 3.5033 - val_accuracy: 0.3168 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 0.3010 - accuracy: 1.0000 - val_loss: 3.4804 - val_accuracy: 0.3234 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.3740 - accuracy: 0.9500 - val_loss: 3.4570 - val_accuracy: 0.3267 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 0.2385 - accuracy: 1.0000 - val_loss: 3.4311 - val_accuracy: 0.3300 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.3515 - accuracy: 1.0000 - val_loss: 3.4036 - val_accuracy: 0.3432 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.3663 - accuracy: 0.9750 - val_loss: 3.3805 - val_accuracy: 0.3465 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.3740 - accuracy: 0.9250 - val_loss: 3.3484 - val_accuracy: 0.3465 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 0.1385 - accuracy: 1.0000 - val_loss: 3.3275 - val_accuracy: 0.3432 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 0.2937 - accuracy: 0.9750 - val_loss: 3.3030 - val_accuracy: 0.3498 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 0.3173 - accuracy: 0.9750 - val_loss: 3.2785 - val_accuracy: 0.3465 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.2380 - accuracy: 0.9750 - val_loss: 3.2567 - val_accuracy: 0.3630 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 0.2276 - accuracy: 1.0000 - val_loss: 3.2312 - val_accuracy: 0.3564 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.2494 - accuracy: 1.0000 - val_loss: 3.2144 - val_accuracy: 0.3663 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 0.1174 - accuracy: 1.0000 - val_loss: 3.1951 - val_accuracy: 0.3663 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 0.1241 - accuracy: 1.0000 - val_loss: 3.1752 - val_accuracy: 0.3663 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 0.2607 - accuracy: 0.9750 - val_loss: 3.1547 - val_accuracy: 0.3729 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.1213 - accuracy: 1.0000 - val_loss: 3.1347 - val_accuracy: 0.3729 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.1084 - accuracy: 1.0000 - val_loss: 3.1180 - val_accuracy: 0.3795 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 0.1722 - accuracy: 1.0000 - val_loss: 3.0959 - val_accuracy: 0.3828 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 0.1895 - accuracy: 1.0000 - val_loss: 3.0741 - val_accuracy: 0.3828 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 0.2194 - accuracy: 0.9750 - val_loss: 3.0582 - val_accuracy: 0.3960 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 0.1274 - accuracy: 1.0000 - val_loss: 3.0394 - val_accuracy: 0.3927 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 0.1134 - accuracy: 1.0000 - val_loss: 3.0213 - val_accuracy: 0.3993 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 0.2168 - accuracy: 1.0000 - val_loss: 3.0045 - val_accuracy: 0.3861 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 0.0986 - accuracy: 1.0000 - val_loss: 2.9900 - val_accuracy: 0.3828 - lr: 0.0010\n",
            "#13\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 628ms/step - loss: 6.3263 - accuracy: 0.0000e+00 - val_loss: 17.6759 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 6.4605 - accuracy: 0.0000e+00 - val_loss: 12.4076 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 5.6822 - accuracy: 0.0250 - val_loss: 9.9166 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 5.6131 - accuracy: 0.0250 - val_loss: 8.5883 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 5.3678 - accuracy: 0.0250 - val_loss: 7.5800 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.9600 - accuracy: 0.0750 - val_loss: 6.8923 - val_accuracy: 0.0528 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 5.2865 - accuracy: 0.0500 - val_loss: 6.2957 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 5.2695 - accuracy: 0.0256 - val_loss: 5.8660 - val_accuracy: 0.0528 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 4.6668 - accuracy: 0.1750 - val_loss: 5.5191 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 4.3714 - accuracy: 0.1750 - val_loss: 5.2810 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 4.0485 - accuracy: 0.1750 - val_loss: 4.9782 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 4.5763 - accuracy: 0.0750 - val_loss: 4.8086 - val_accuracy: 0.0957 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 4.4662 - accuracy: 0.1500 - val_loss: 4.6105 - val_accuracy: 0.1023 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 4.1051 - accuracy: 0.1000 - val_loss: 4.4695 - val_accuracy: 0.1056 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 4.4574 - accuracy: 0.0750 - val_loss: 4.3389 - val_accuracy: 0.1056 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 3.9151 - accuracy: 0.1750 - val_loss: 4.2632 - val_accuracy: 0.1155 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 3.7503 - accuracy: 0.2000 - val_loss: 4.1826 - val_accuracy: 0.1221 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 4.1721 - accuracy: 0.1000 - val_loss: 4.1062 - val_accuracy: 0.1287 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 3.6334 - accuracy: 0.2000 - val_loss: 4.0328 - val_accuracy: 0.1353 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 3.6607 - accuracy: 0.1750 - val_loss: 3.9709 - val_accuracy: 0.1419 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 3.5932 - accuracy: 0.1500 - val_loss: 3.9134 - val_accuracy: 0.1518 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 3.6781 - accuracy: 0.2000 - val_loss: 3.8366 - val_accuracy: 0.1617 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 3.4984 - accuracy: 0.2750 - val_loss: 3.8034 - val_accuracy: 0.1716 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 3.3273 - accuracy: 0.1500 - val_loss: 3.7524 - val_accuracy: 0.1716 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 3.2102 - accuracy: 0.3077 - val_loss: 3.7345 - val_accuracy: 0.1914 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 3.1597 - accuracy: 0.3500 - val_loss: 3.7119 - val_accuracy: 0.1848 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 3.8713 - accuracy: 0.1750 - val_loss: 3.6612 - val_accuracy: 0.2145 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 3.3111 - accuracy: 0.2500 - val_loss: 3.6226 - val_accuracy: 0.2145 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 2.7371 - accuracy: 0.2750 - val_loss: 3.5822 - val_accuracy: 0.2211 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 3.4174 - accuracy: 0.2000 - val_loss: 3.5562 - val_accuracy: 0.2277 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 3.5192 - accuracy: 0.1750 - val_loss: 3.5393 - val_accuracy: 0.2244 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 2.9640 - accuracy: 0.3250 - val_loss: 3.5330 - val_accuracy: 0.2409 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 3.0493 - accuracy: 0.2051 - val_loss: 3.5256 - val_accuracy: 0.2343 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 2.5700 - accuracy: 0.3750 - val_loss: 3.5181 - val_accuracy: 0.2244 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 3.0398 - accuracy: 0.2500 - val_loss: 3.4976 - val_accuracy: 0.2211 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 2.8745 - accuracy: 0.3750 - val_loss: 3.4784 - val_accuracy: 0.2310 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 2.6344 - accuracy: 0.3500 - val_loss: 3.4606 - val_accuracy: 0.2376 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 2.5719 - accuracy: 0.3750 - val_loss: 3.4595 - val_accuracy: 0.2376 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 2.7794 - accuracy: 0.3250 - val_loss: 3.4601 - val_accuracy: 0.2343 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 2.8085 - accuracy: 0.2750 - val_loss: 3.4621 - val_accuracy: 0.2343 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 2.5405 - accuracy: 0.3250 - val_loss: 3.4609 - val_accuracy: 0.2409 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 3.0877 - accuracy: 0.2750 - val_loss: 3.4573 - val_accuracy: 0.2376 - lr: 1.0000e-04\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 2.5711 - accuracy: 0.3000 - val_loss: 3.4596 - val_accuracy: 0.2244 - lr: 1.0000e-05\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 2.6328 - accuracy: 0.4000 - val_loss: 3.4632 - val_accuracy: 0.2277 - lr: 1.0000e-05\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 2.7317 - accuracy: 0.3250 - val_loss: 3.4645 - val_accuracy: 0.2310 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 2.7770 - accuracy: 0.4000 - val_loss: 3.4660 - val_accuracy: 0.2310 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 2.7639 - accuracy: 0.2500 - val_loss: 3.4692 - val_accuracy: 0.2343 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 3.0340 - accuracy: 0.2250 - val_loss: 3.4695 - val_accuracy: 0.2376 - lr: 1.0000e-06\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 2.5675 - accuracy: 0.3750 - val_loss: 3.4734 - val_accuracy: 0.2409 - lr: 1.0000e-06\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 3.0351 - accuracy: 0.2250 - val_loss: 3.4787 - val_accuracy: 0.2475 - lr: 1.0000e-06\n",
            "#14\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 625ms/step - loss: 7.3993 - accuracy: 0.0000e+00 - val_loss: 5.0199 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 7.3156 - accuracy: 0.0000e+00 - val_loss: 5.0191 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 7.3834 - accuracy: 0.0000e+00 - val_loss: 4.9740 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 6.8717 - accuracy: 0.0000e+00 - val_loss: 4.9110 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 7.4958 - accuracy: 0.0000e+00 - val_loss: 4.8856 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 7.1816 - accuracy: 0.0000e+00 - val_loss: 4.8389 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 7.4531 - accuracy: 0.0000e+00 - val_loss: 4.8246 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 7.1466 - accuracy: 0.0250 - val_loss: 4.7856 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 7.3865 - accuracy: 0.0000e+00 - val_loss: 4.7549 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 6.7130 - accuracy: 0.0000e+00 - val_loss: 4.7424 - val_accuracy: 0.0165 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 6.6481 - accuracy: 0.0250 - val_loss: 4.7309 - val_accuracy: 0.0198 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 7.9579 - accuracy: 0.0000e+00 - val_loss: 4.7187 - val_accuracy: 0.0165 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 6.8757 - accuracy: 0.0000e+00 - val_loss: 4.7066 - val_accuracy: 0.0165 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 7.5653 - accuracy: 0.0000e+00 - val_loss: 4.6966 - val_accuracy: 0.0231 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 7.3964 - accuracy: 0.0250 - val_loss: 4.6887 - val_accuracy: 0.0198 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 6.5442 - accuracy: 0.0000e+00 - val_loss: 4.6788 - val_accuracy: 0.0198 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 6.8249 - accuracy: 0.0250 - val_loss: 4.6694 - val_accuracy: 0.0198 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 6.6225 - accuracy: 0.0000e+00 - val_loss: 4.6609 - val_accuracy: 0.0231 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 7.0893 - accuracy: 0.0000e+00 - val_loss: 4.6534 - val_accuracy: 0.0264 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 6.7369 - accuracy: 0.0513 - val_loss: 4.6459 - val_accuracy: 0.0297 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 7.6040 - accuracy: 0.0000e+00 - val_loss: 4.6390 - val_accuracy: 0.0264 - lr: 1.0000e-04\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 6.9575 - accuracy: 0.0000e+00 - val_loss: 4.6329 - val_accuracy: 0.0231 - lr: 1.0000e-04\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 6.9403 - accuracy: 0.0500 - val_loss: 4.6273 - val_accuracy: 0.0231 - lr: 1.0000e-04\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 7.2277 - accuracy: 0.0000e+00 - val_loss: 4.6222 - val_accuracy: 0.0231 - lr: 1.0000e-04\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 7.2130 - accuracy: 0.0250 - val_loss: 4.6179 - val_accuracy: 0.0231 - lr: 1.0000e-04\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 6.7622 - accuracy: 0.0250 - val_loss: 4.6149 - val_accuracy: 0.0231 - lr: 1.0000e-05\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 7.4147 - accuracy: 0.0250 - val_loss: 4.6124 - val_accuracy: 0.0231 - lr: 1.0000e-05\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 7.0246 - accuracy: 0.0000e+00 - val_loss: 4.6087 - val_accuracy: 0.0231 - lr: 1.0000e-05\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 6.9855 - accuracy: 0.0000e+00 - val_loss: 4.6063 - val_accuracy: 0.0198 - lr: 1.0000e-05\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 6.1635 - accuracy: 0.0769 - val_loss: 4.6027 - val_accuracy: 0.0198 - lr: 1.0000e-05\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 6.6941 - accuracy: 0.0000e+00 - val_loss: 4.6015 - val_accuracy: 0.0198 - lr: 1.0000e-06\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 6.3622 - accuracy: 0.0250 - val_loss: 4.6002 - val_accuracy: 0.0198 - lr: 1.0000e-06\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 6.9288 - accuracy: 0.0000e+00 - val_loss: 4.5981 - val_accuracy: 0.0198 - lr: 1.0000e-06\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 6.8641 - accuracy: 0.0000e+00 - val_loss: 4.5987 - val_accuracy: 0.0165 - lr: 1.0000e-06\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 6.4428 - accuracy: 0.0000e+00 - val_loss: 4.5987 - val_accuracy: 0.0165 - lr: 1.0000e-06\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 6.8044 - accuracy: 0.0000e+00 - val_loss: 4.5983 - val_accuracy: 0.0165 - lr: 1.0000e-07\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 6.7364 - accuracy: 0.0000e+00 - val_loss: 4.5972 - val_accuracy: 0.0165 - lr: 1.0000e-07\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 6.7043 - accuracy: 0.0000e+00 - val_loss: 4.5973 - val_accuracy: 0.0198 - lr: 1.0000e-07\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 6.9796 - accuracy: 0.0256 - val_loss: 4.5953 - val_accuracy: 0.0198 - lr: 1.0000e-07\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 6.8795 - accuracy: 0.0250 - val_loss: 4.5942 - val_accuracy: 0.0198 - lr: 1.0000e-07\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 7.0823 - accuracy: 0.0000e+00 - val_loss: 4.5946 - val_accuracy: 0.0231 - lr: 1.0000e-08\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 6.9803 - accuracy: 0.0000e+00 - val_loss: 4.5959 - val_accuracy: 0.0231 - lr: 1.0000e-08\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 6.8046 - accuracy: 0.0250 - val_loss: 4.5966 - val_accuracy: 0.0264 - lr: 1.0000e-08\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 6.6280 - accuracy: 0.0500 - val_loss: 4.5976 - val_accuracy: 0.0363 - lr: 1.0000e-08\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 6.8346 - accuracy: 0.0000e+00 - val_loss: 4.5974 - val_accuracy: 0.0363 - lr: 1.0000e-08\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 7.1274 - accuracy: 0.0256 - val_loss: 4.5978 - val_accuracy: 0.0330 - lr: 1.0000e-08\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 6.8492 - accuracy: 0.0000e+00 - val_loss: 4.5976 - val_accuracy: 0.0330 - lr: 1.0000e-08\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 7.6627 - accuracy: 0.0250 - val_loss: 4.5995 - val_accuracy: 0.0297 - lr: 1.0000e-08\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 6.7178 - accuracy: 0.0500 - val_loss: 4.6006 - val_accuracy: 0.0297 - lr: 1.0000e-08\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 7.4859 - accuracy: 0.0000e+00 - val_loss: 4.6033 - val_accuracy: 0.0297 - lr: 1.0000e-09\n",
            "#15\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 635ms/step - loss: 5.5818 - accuracy: 0.0250 - val_loss: 4.8533 - val_accuracy: 0.0033 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 5.1887 - accuracy: 0.0500 - val_loss: 4.7807 - val_accuracy: 0.0033 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 4.6417 - accuracy: 0.0250 - val_loss: 4.7366 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 4.6414 - accuracy: 0.1250 - val_loss: 4.6717 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 4.3552 - accuracy: 0.1250 - val_loss: 4.6267 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 3.6330 - accuracy: 0.2564 - val_loss: 4.5764 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 3.5462 - accuracy: 0.2750 - val_loss: 4.5328 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 3.6073 - accuracy: 0.2000 - val_loss: 4.4873 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 3.4376 - accuracy: 0.2308 - val_loss: 4.4598 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 3.1204 - accuracy: 0.3750 - val_loss: 4.4192 - val_accuracy: 0.0528 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 2.9285 - accuracy: 0.3750 - val_loss: 4.3775 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 2.5316 - accuracy: 0.5250 - val_loss: 4.3531 - val_accuracy: 0.0594 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 3.1075 - accuracy: 0.4000 - val_loss: 4.3113 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 2.2103 - accuracy: 0.4872 - val_loss: 4.2804 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 2.1965 - accuracy: 0.4500 - val_loss: 4.2305 - val_accuracy: 0.0660 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 2.4626 - accuracy: 0.5000 - val_loss: 4.2184 - val_accuracy: 0.0759 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 2.3332 - accuracy: 0.5250 - val_loss: 4.1888 - val_accuracy: 0.0924 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 1.8707 - accuracy: 0.5750 - val_loss: 4.1508 - val_accuracy: 0.1122 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 1.5687 - accuracy: 0.7000 - val_loss: 4.1052 - val_accuracy: 0.1221 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 1.9851 - accuracy: 0.5250 - val_loss: 4.0730 - val_accuracy: 0.1452 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 1.4986 - accuracy: 0.7500 - val_loss: 4.0376 - val_accuracy: 0.1584 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 1.7648 - accuracy: 0.6000 - val_loss: 3.9923 - val_accuracy: 0.1452 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 1.4565 - accuracy: 0.8250 - val_loss: 3.9699 - val_accuracy: 0.1452 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 1.7452 - accuracy: 0.7000 - val_loss: 3.9450 - val_accuracy: 0.1683 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 1.7261 - accuracy: 0.6500 - val_loss: 3.9070 - val_accuracy: 0.1782 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 1.6519 - accuracy: 0.7250 - val_loss: 3.8778 - val_accuracy: 0.1716 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 1.5595 - accuracy: 0.7500 - val_loss: 3.8495 - val_accuracy: 0.2013 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 0.9550 - accuracy: 0.9000 - val_loss: 3.8173 - val_accuracy: 0.1980 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 1.3017 - accuracy: 0.7750 - val_loss: 3.7878 - val_accuracy: 0.1848 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 1.2194 - accuracy: 0.8250 - val_loss: 3.7634 - val_accuracy: 0.2178 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.9472 - accuracy: 0.8462 - val_loss: 3.7200 - val_accuracy: 0.2145 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 1.3425 - accuracy: 0.7500 - val_loss: 3.6905 - val_accuracy: 0.2508 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 1.0744 - accuracy: 0.8250 - val_loss: 3.6563 - val_accuracy: 0.2541 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 0.9929 - accuracy: 0.8500 - val_loss: 3.6156 - val_accuracy: 0.2508 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 0.9448 - accuracy: 0.8750 - val_loss: 3.5914 - val_accuracy: 0.2673 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 0.7440 - accuracy: 0.9487 - val_loss: 3.5725 - val_accuracy: 0.2772 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 1.0914 - accuracy: 0.8500 - val_loss: 3.5490 - val_accuracy: 0.2937 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 0.9473 - accuracy: 0.8974 - val_loss: 3.5372 - val_accuracy: 0.2937 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.8734 - accuracy: 0.8205 - val_loss: 3.5221 - val_accuracy: 0.2838 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 0.7361 - accuracy: 0.9500 - val_loss: 3.5083 - val_accuracy: 0.2739 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.8296 - accuracy: 0.9000 - val_loss: 3.4698 - val_accuracy: 0.2739 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 0.6483 - accuracy: 0.9750 - val_loss: 3.4408 - val_accuracy: 0.2772 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 0.4970 - accuracy: 0.9750 - val_loss: 3.4234 - val_accuracy: 0.2805 - lr: 1.0000e-04\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 0.6836 - accuracy: 0.9500 - val_loss: 3.4075 - val_accuracy: 0.2838 - lr: 1.0000e-04\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 0.4912 - accuracy: 0.9750 - val_loss: 3.3921 - val_accuracy: 0.2838 - lr: 1.0000e-04\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 0.5736 - accuracy: 0.9750 - val_loss: 3.3765 - val_accuracy: 0.2871 - lr: 1.0000e-04\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 0.6067 - accuracy: 0.9250 - val_loss: 3.3594 - val_accuracy: 0.2871 - lr: 1.0000e-04\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.7793 - accuracy: 0.9250 - val_loss: 3.3462 - val_accuracy: 0.3036 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.5819 - accuracy: 0.9500 - val_loss: 3.3340 - val_accuracy: 0.3003 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 0.9395 - accuracy: 0.8974 - val_loss: 3.3224 - val_accuracy: 0.3069 - lr: 1.0000e-05\n",
            "#16\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 616ms/step - loss: 6.2411 - accuracy: 0.0000e+00 - val_loss: 5.2797 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 5.8361 - accuracy: 0.0000e+00 - val_loss: 5.1765 - val_accuracy: 0.0033 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 6.4097 - accuracy: 0.0000e+00 - val_loss: 5.0930 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 5.0876 - accuracy: 0.0250 - val_loss: 5.0199 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 5.5511 - accuracy: 0.0000e+00 - val_loss: 4.9709 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 5.5563 - accuracy: 0.0000e+00 - val_loss: 4.8507 - val_accuracy: 0.0264 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 5.2523 - accuracy: 0.0250 - val_loss: 4.7894 - val_accuracy: 0.0363 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 5.9913 - accuracy: 0.0000e+00 - val_loss: 4.7101 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 5.4745 - accuracy: 0.0000e+00 - val_loss: 4.6380 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 5.0534 - accuracy: 0.0500 - val_loss: 4.5801 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 5.2367 - accuracy: 0.0500 - val_loss: 4.5434 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 5.0195 - accuracy: 0.0256 - val_loss: 4.5199 - val_accuracy: 0.0528 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 4.8584 - accuracy: 0.0750 - val_loss: 4.5060 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 4.9656 - accuracy: 0.0256 - val_loss: 4.4457 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 4.5838 - accuracy: 0.1000 - val_loss: 4.3987 - val_accuracy: 0.0660 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 4.1538 - accuracy: 0.1026 - val_loss: 4.3732 - val_accuracy: 0.0759 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 4.6128 - accuracy: 0.0750 - val_loss: 4.3556 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 4.5325 - accuracy: 0.0750 - val_loss: 4.3401 - val_accuracy: 0.0726 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 4.8003 - accuracy: 0.0250 - val_loss: 4.2880 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 4.2366 - accuracy: 0.0500 - val_loss: 4.2351 - val_accuracy: 0.1023 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 4.1917 - accuracy: 0.0500 - val_loss: 4.2217 - val_accuracy: 0.0924 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 4.6244 - accuracy: 0.0500 - val_loss: 4.1777 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 4.1413 - accuracy: 0.2000 - val_loss: 4.1591 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 4.1329 - accuracy: 0.1250 - val_loss: 4.1262 - val_accuracy: 0.1089 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 4.3791 - accuracy: 0.0256 - val_loss: 4.0843 - val_accuracy: 0.1254 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 4.0047 - accuracy: 0.0250 - val_loss: 4.0517 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 4.1592 - accuracy: 0.0750 - val_loss: 4.0106 - val_accuracy: 0.1386 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 3.8597 - accuracy: 0.1250 - val_loss: 4.0004 - val_accuracy: 0.1320 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 4.2039 - accuracy: 0.1750 - val_loss: 3.9844 - val_accuracy: 0.1452 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 3.7456 - accuracy: 0.1000 - val_loss: 3.9669 - val_accuracy: 0.1518 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 3.8403 - accuracy: 0.1750 - val_loss: 3.9310 - val_accuracy: 0.1386 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 4.0736 - accuracy: 0.1250 - val_loss: 3.8908 - val_accuracy: 0.1584 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 4.0977 - accuracy: 0.0250 - val_loss: 3.8624 - val_accuracy: 0.1584 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 4.1564 - accuracy: 0.1000 - val_loss: 3.8456 - val_accuracy: 0.1683 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 3.6681 - accuracy: 0.1750 - val_loss: 3.8523 - val_accuracy: 0.1584 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 3.6569 - accuracy: 0.2000 - val_loss: 3.8477 - val_accuracy: 0.1551 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 3.9674 - accuracy: 0.1500 - val_loss: 3.8413 - val_accuracy: 0.1683 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 3.8577 - accuracy: 0.1500 - val_loss: 3.8277 - val_accuracy: 0.1683 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 3.5870 - accuracy: 0.1250 - val_loss: 3.8116 - val_accuracy: 0.1749 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 4.0615 - accuracy: 0.1500 - val_loss: 3.7875 - val_accuracy: 0.1815 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 3.6463 - accuracy: 0.1500 - val_loss: 3.7668 - val_accuracy: 0.1749 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 3.9029 - accuracy: 0.0513 - val_loss: 3.7628 - val_accuracy: 0.1947 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 3.4564 - accuracy: 0.2500 - val_loss: 3.7612 - val_accuracy: 0.1881 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 3.4317 - accuracy: 0.1750 - val_loss: 3.7330 - val_accuracy: 0.1815 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 3.9228 - accuracy: 0.1000 - val_loss: 3.7178 - val_accuracy: 0.2079 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 3.5230 - accuracy: 0.1250 - val_loss: 3.7067 - val_accuracy: 0.2013 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 3.1973 - accuracy: 0.2750 - val_loss: 3.6990 - val_accuracy: 0.2013 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 3.6966 - accuracy: 0.1500 - val_loss: 3.6872 - val_accuracy: 0.1914 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 3.3023 - accuracy: 0.3000 - val_loss: 3.6738 - val_accuracy: 0.2112 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 3.4906 - accuracy: 0.1500 - val_loss: 3.6572 - val_accuracy: 0.2046 - lr: 0.0010\n",
            "#17\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 627ms/step - loss: 5.8362 - accuracy: 0.0000e+00 - val_loss: 18.9937 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 5.6641 - accuracy: 0.0750 - val_loss: 13.3412 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 4.8452 - accuracy: 0.0250 - val_loss: 10.4458 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 4.0643 - accuracy: 0.1750 - val_loss: 8.8408 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.5496 - accuracy: 0.1000 - val_loss: 7.9717 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 3.6640 - accuracy: 0.2750 - val_loss: 6.9894 - val_accuracy: 0.0759 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.4367 - accuracy: 0.2051 - val_loss: 6.3518 - val_accuracy: 0.0825 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 3.1601 - accuracy: 0.2750 - val_loss: 5.8601 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 3.3428 - accuracy: 0.3077 - val_loss: 5.4437 - val_accuracy: 0.0957 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 2.5978 - accuracy: 0.4750 - val_loss: 5.1638 - val_accuracy: 0.0990 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 3.6586 - accuracy: 0.2308 - val_loss: 4.8111 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 3.0364 - accuracy: 0.3000 - val_loss: 4.6024 - val_accuracy: 0.1287 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 2.5956 - accuracy: 0.4359 - val_loss: 4.4922 - val_accuracy: 0.1353 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 2.7440 - accuracy: 0.3750 - val_loss: 4.3471 - val_accuracy: 0.1419 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 2.2508 - accuracy: 0.5000 - val_loss: 4.2479 - val_accuracy: 0.1353 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 3.0178 - accuracy: 0.3250 - val_loss: 4.1312 - val_accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 2.3369 - accuracy: 0.4250 - val_loss: 4.0424 - val_accuracy: 0.1584 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 2.1300 - accuracy: 0.5250 - val_loss: 3.9584 - val_accuracy: 0.1650 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 2.0426 - accuracy: 0.5500 - val_loss: 3.9055 - val_accuracy: 0.1584 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 2.0340 - accuracy: 0.5500 - val_loss: 3.8485 - val_accuracy: 0.1881 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 1.8458 - accuracy: 0.5750 - val_loss: 3.7730 - val_accuracy: 0.1914 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 1.6428 - accuracy: 0.6250 - val_loss: 3.7165 - val_accuracy: 0.2046 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 2.0735 - accuracy: 0.5500 - val_loss: 3.6637 - val_accuracy: 0.2145 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 1.9792 - accuracy: 0.5750 - val_loss: 3.6090 - val_accuracy: 0.2079 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 1.2609 - accuracy: 0.7500 - val_loss: 3.5648 - val_accuracy: 0.2277 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 1.6404 - accuracy: 0.6250 - val_loss: 3.5413 - val_accuracy: 0.2211 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 1.7156 - accuracy: 0.7000 - val_loss: 3.5171 - val_accuracy: 0.2244 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 1.5630 - accuracy: 0.7250 - val_loss: 3.4800 - val_accuracy: 0.2277 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 1.2565 - accuracy: 0.7750 - val_loss: 3.4548 - val_accuracy: 0.2376 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 1.2224 - accuracy: 0.8000 - val_loss: 3.4279 - val_accuracy: 0.2442 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 1.3843 - accuracy: 0.6750 - val_loss: 3.4100 - val_accuracy: 0.2409 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 1.1780 - accuracy: 0.7949 - val_loss: 3.4010 - val_accuracy: 0.2508 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 1.7447 - accuracy: 0.6500 - val_loss: 3.3882 - val_accuracy: 0.2640 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 0.9944 - accuracy: 0.8718 - val_loss: 3.3841 - val_accuracy: 0.2640 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 1.5551 - accuracy: 0.6750 - val_loss: 3.3750 - val_accuracy: 0.2640 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 1.3864 - accuracy: 0.7750 - val_loss: 3.3573 - val_accuracy: 0.2673 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 1.3280 - accuracy: 0.6750 - val_loss: 3.3086 - val_accuracy: 0.2640 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 1.3081 - accuracy: 0.8000 - val_loss: 3.2946 - val_accuracy: 0.2607 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 1.1864 - accuracy: 0.7250 - val_loss: 3.2825 - val_accuracy: 0.2640 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 0.7819 - accuracy: 0.9000 - val_loss: 3.2661 - val_accuracy: 0.2508 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 1.0395 - accuracy: 0.8250 - val_loss: 3.2583 - val_accuracy: 0.2640 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 1.2088 - accuracy: 0.7949 - val_loss: 3.2554 - val_accuracy: 0.2673 - lr: 1.0000e-04\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 1.1298 - accuracy: 0.7500 - val_loss: 3.2535 - val_accuracy: 0.2640 - lr: 1.0000e-04\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.8688 - accuracy: 0.9000 - val_loss: 3.2510 - val_accuracy: 0.2640 - lr: 1.0000e-04\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.9015 - accuracy: 0.8750 - val_loss: 3.2491 - val_accuracy: 0.2640 - lr: 1.0000e-04\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 1.0792 - accuracy: 0.8000 - val_loss: 3.2473 - val_accuracy: 0.2607 - lr: 1.0000e-04\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.8609 - accuracy: 0.9000 - val_loss: 3.2465 - val_accuracy: 0.2607 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 0.9480 - accuracy: 0.8462 - val_loss: 3.2477 - val_accuracy: 0.2607 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.8758 - accuracy: 0.9250 - val_loss: 3.2483 - val_accuracy: 0.2607 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 0.9813 - accuracy: 0.8500 - val_loss: 3.2496 - val_accuracy: 0.2607 - lr: 1.0000e-05\n",
            "#18\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 617ms/step - loss: 5.2994 - accuracy: 0.0000e+00 - val_loss: 16.9399 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 5.5952 - accuracy: 0.0000e+00 - val_loss: 12.6007 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 4.8919 - accuracy: 0.0256 - val_loss: 10.3865 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.1867 - accuracy: 0.2250 - val_loss: 8.7037 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 4.2393 - accuracy: 0.1500 - val_loss: 7.6254 - val_accuracy: 0.0330 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 3.1420 - accuracy: 0.4500 - val_loss: 6.8313 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 3.7010 - accuracy: 0.2564 - val_loss: 6.4259 - val_accuracy: 0.0462 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 3.4198 - accuracy: 0.3250 - val_loss: 5.8959 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 2.6238 - accuracy: 0.4250 - val_loss: 5.4894 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 2.7656 - accuracy: 0.4750 - val_loss: 5.2679 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 3.1344 - accuracy: 0.4000 - val_loss: 5.0087 - val_accuracy: 0.0891 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 2.5299 - accuracy: 0.5000 - val_loss: 4.7548 - val_accuracy: 0.1056 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 2.6953 - accuracy: 0.4250 - val_loss: 4.5746 - val_accuracy: 0.1122 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 2.2660 - accuracy: 0.6000 - val_loss: 4.3980 - val_accuracy: 0.1221 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 2.6753 - accuracy: 0.3750 - val_loss: 4.2357 - val_accuracy: 0.1320 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 2.4302 - accuracy: 0.4000 - val_loss: 4.1069 - val_accuracy: 0.1320 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 1.9143 - accuracy: 0.6250 - val_loss: 3.9983 - val_accuracy: 0.1584 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 1.8959 - accuracy: 0.6750 - val_loss: 3.9074 - val_accuracy: 0.1617 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 1.7750 - accuracy: 0.6667 - val_loss: 3.8242 - val_accuracy: 0.1683 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 1.8756 - accuracy: 0.6000 - val_loss: 3.7799 - val_accuracy: 0.1914 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 2.0022 - accuracy: 0.5500 - val_loss: 3.7478 - val_accuracy: 0.1914 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 1.6556 - accuracy: 0.6500 - val_loss: 3.6915 - val_accuracy: 0.2079 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 1.5031 - accuracy: 0.7250 - val_loss: 3.6600 - val_accuracy: 0.2178 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 1.5502 - accuracy: 0.7436 - val_loss: 3.6290 - val_accuracy: 0.2178 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 1.2329 - accuracy: 0.8500 - val_loss: 3.5853 - val_accuracy: 0.2310 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 1.3956 - accuracy: 0.7500 - val_loss: 3.5592 - val_accuracy: 0.2244 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 1.4991 - accuracy: 0.7436 - val_loss: 3.5216 - val_accuracy: 0.2409 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 1.2803 - accuracy: 0.8250 - val_loss: 3.4929 - val_accuracy: 0.2541 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 1.0516 - accuracy: 0.9000 - val_loss: 3.4605 - val_accuracy: 0.2541 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 0.8723 - accuracy: 0.9250 - val_loss: 3.4423 - val_accuracy: 0.2541 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 1.0745 - accuracy: 0.8250 - val_loss: 3.4300 - val_accuracy: 0.2475 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.9286 - accuracy: 0.9250 - val_loss: 3.4152 - val_accuracy: 0.2574 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 1.0150 - accuracy: 0.9250 - val_loss: 3.3950 - val_accuracy: 0.2574 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 0.9268 - accuracy: 0.9231 - val_loss: 3.3806 - val_accuracy: 0.2607 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 0.8237 - accuracy: 0.9500 - val_loss: 3.3701 - val_accuracy: 0.2640 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.9850 - accuracy: 0.9250 - val_loss: 3.3580 - val_accuracy: 0.2640 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.8960 - accuracy: 0.9000 - val_loss: 3.3427 - val_accuracy: 0.2640 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.8426 - accuracy: 0.9000 - val_loss: 3.3411 - val_accuracy: 0.2706 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 0.7617 - accuracy: 0.9250 - val_loss: 3.3284 - val_accuracy: 0.2772 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 0.9032 - accuracy: 0.8974 - val_loss: 3.3102 - val_accuracy: 0.2871 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.5927 - accuracy: 0.9500 - val_loss: 3.3123 - val_accuracy: 0.2904 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 0.7019 - accuracy: 0.9750 - val_loss: 3.3061 - val_accuracy: 0.2838 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.6578 - accuracy: 0.9500 - val_loss: 3.3042 - val_accuracy: 0.2871 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 0.7443 - accuracy: 0.9250 - val_loss: 3.2968 - val_accuracy: 0.2871 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 0.6992 - accuracy: 0.9250 - val_loss: 3.2827 - val_accuracy: 0.2970 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 0.6333 - accuracy: 0.9750 - val_loss: 3.2834 - val_accuracy: 0.3102 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 0.6275 - accuracy: 0.9500 - val_loss: 3.2749 - val_accuracy: 0.3036 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 0.7831 - accuracy: 0.9250 - val_loss: 3.2717 - val_accuracy: 0.3135 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 0.9255 - accuracy: 0.9250 - val_loss: 3.2586 - val_accuracy: 0.3234 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 0.6498 - accuracy: 0.9250 - val_loss: 3.2567 - val_accuracy: 0.3168 - lr: 0.0010\n",
            "#19\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 622ms/step - loss: 6.0845 - accuracy: 0.0000e+00 - val_loss: 4.9010 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 5.0641 - accuracy: 0.1282 - val_loss: 4.7717 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 4.8719 - accuracy: 0.1250 - val_loss: 4.6522 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 3.4293 - accuracy: 0.3500 - val_loss: 4.5531 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 2.9671 - accuracy: 0.5000 - val_loss: 4.4661 - val_accuracy: 0.0627 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 3.7912 - accuracy: 0.3250 - val_loss: 4.3824 - val_accuracy: 0.0660 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 2.3868 - accuracy: 0.6000 - val_loss: 4.3123 - val_accuracy: 0.0759 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 2.1330 - accuracy: 0.5500 - val_loss: 4.2488 - val_accuracy: 0.0858 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 2.0614 - accuracy: 0.6250 - val_loss: 4.1895 - val_accuracy: 0.0957 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 1.9841 - accuracy: 0.5750 - val_loss: 4.1233 - val_accuracy: 0.1188 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 1.7726 - accuracy: 0.6750 - val_loss: 4.0663 - val_accuracy: 0.1320 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 1.4931 - accuracy: 0.7250 - val_loss: 4.0070 - val_accuracy: 0.1551 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 1.0971 - accuracy: 0.8500 - val_loss: 3.9660 - val_accuracy: 0.1749 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 1.6072 - accuracy: 0.6750 - val_loss: 3.9174 - val_accuracy: 0.1848 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 1.1992 - accuracy: 0.8000 - val_loss: 3.8720 - val_accuracy: 0.2079 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 1.3105 - accuracy: 0.7692 - val_loss: 3.8226 - val_accuracy: 0.2145 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 0.9315 - accuracy: 0.8500 - val_loss: 3.7823 - val_accuracy: 0.2211 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 1.1016 - accuracy: 0.8500 - val_loss: 3.7374 - val_accuracy: 0.2376 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.9744 - accuracy: 0.8250 - val_loss: 3.6896 - val_accuracy: 0.2475 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.8605 - accuracy: 0.8000 - val_loss: 3.6526 - val_accuracy: 0.2607 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 1.1409 - accuracy: 0.8000 - val_loss: 3.6072 - val_accuracy: 0.2739 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 0.6533 - accuracy: 0.9250 - val_loss: 3.5756 - val_accuracy: 0.2937 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 0.6535 - accuracy: 0.8750 - val_loss: 3.5372 - val_accuracy: 0.3036 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 0.8874 - accuracy: 0.8250 - val_loss: 3.4832 - val_accuracy: 0.3135 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 0.7214 - accuracy: 0.8750 - val_loss: 3.4579 - val_accuracy: 0.3135 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 0.4312 - accuracy: 0.9250 - val_loss: 3.4355 - val_accuracy: 0.3201 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 0.9014 - accuracy: 0.9000 - val_loss: 3.3955 - val_accuracy: 0.3399 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 0.2405 - accuracy: 1.0000 - val_loss: 3.3702 - val_accuracy: 0.3498 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 0.5964 - accuracy: 0.9000 - val_loss: 3.3424 - val_accuracy: 0.3564 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.2167 - accuracy: 0.9750 - val_loss: 3.3148 - val_accuracy: 0.3663 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 0.4448 - accuracy: 0.9250 - val_loss: 3.2892 - val_accuracy: 0.3795 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.5883 - accuracy: 0.9000 - val_loss: 3.2528 - val_accuracy: 0.4026 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.2420 - accuracy: 1.0000 - val_loss: 3.2277 - val_accuracy: 0.4092 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 0.3664 - accuracy: 0.9250 - val_loss: 3.1969 - val_accuracy: 0.4125 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 0.1173 - accuracy: 1.0000 - val_loss: 3.1742 - val_accuracy: 0.4158 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.4097 - accuracy: 0.9250 - val_loss: 3.1519 - val_accuracy: 0.4224 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 0.2138 - accuracy: 1.0000 - val_loss: 3.1287 - val_accuracy: 0.4290 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 0.2105 - accuracy: 0.9750 - val_loss: 3.1104 - val_accuracy: 0.4323 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 0.1538 - accuracy: 1.0000 - val_loss: 3.0872 - val_accuracy: 0.4323 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 0.2166 - accuracy: 1.0000 - val_loss: 3.0643 - val_accuracy: 0.4257 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 0.1844 - accuracy: 1.0000 - val_loss: 3.0411 - val_accuracy: 0.4257 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 0.2146 - accuracy: 0.9750 - val_loss: 3.0190 - val_accuracy: 0.4323 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.1026 - accuracy: 1.0000 - val_loss: 2.9979 - val_accuracy: 0.4389 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 0.2169 - accuracy: 0.9750 - val_loss: 2.9719 - val_accuracy: 0.4455 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 0.2264 - accuracy: 0.9750 - val_loss: 2.9496 - val_accuracy: 0.4323 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.2024 - accuracy: 1.0000 - val_loss: 2.9266 - val_accuracy: 0.4455 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.1472 - accuracy: 1.0000 - val_loss: 2.9083 - val_accuracy: 0.4521 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.0868 - accuracy: 1.0000 - val_loss: 2.8923 - val_accuracy: 0.4488 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 0.1204 - accuracy: 1.0000 - val_loss: 2.8750 - val_accuracy: 0.4521 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 0.1360 - accuracy: 1.0000 - val_loss: 2.8564 - val_accuracy: 0.4455 - lr: 0.0010\n",
            "Tuning last 3 layers.\n",
            "Tuning last 4 layers.\n",
            "#0\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 628ms/step - loss: 5.8035 - accuracy: 0.0000e+00 - val_loss: 5.5342 - val_accuracy: 0.0033 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 6.0933 - accuracy: 0.0256 - val_loss: 5.4775 - val_accuracy: 0.0033 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 5.4958 - accuracy: 0.0000e+00 - val_loss: 5.4382 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 5.4667 - accuracy: 0.0000e+00 - val_loss: 5.3947 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 5.7941 - accuracy: 0.0000e+00 - val_loss: 5.3360 - val_accuracy: 0.0231 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 5.5846 - accuracy: 0.0500 - val_loss: 5.3119 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 5.3254 - accuracy: 0.0000e+00 - val_loss: 5.2635 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 5.3961 - accuracy: 0.0000e+00 - val_loss: 5.2499 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 5.3552 - accuracy: 0.0000e+00 - val_loss: 5.2176 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 5.7237 - accuracy: 0.0000e+00 - val_loss: 5.2119 - val_accuracy: 0.0165 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 5.5118 - accuracy: 0.0250 - val_loss: 5.1947 - val_accuracy: 0.0132 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 4.7330 - accuracy: 0.0500 - val_loss: 5.1810 - val_accuracy: 0.0132 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 4.9754 - accuracy: 0.0250 - val_loss: 5.1618 - val_accuracy: 0.0099 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 5.5083 - accuracy: 0.0000e+00 - val_loss: 5.1519 - val_accuracy: 0.0099 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 5.3054 - accuracy: 0.0000e+00 - val_loss: 5.1452 - val_accuracy: 0.0132 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 5.4026 - accuracy: 0.0000e+00 - val_loss: 5.1367 - val_accuracy: 0.0132 - lr: 1.0000e-05\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 5.2328 - accuracy: 0.0000e+00 - val_loss: 5.1251 - val_accuracy: 0.0132 - lr: 1.0000e-05\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 5.2770 - accuracy: 0.0000e+00 - val_loss: 5.1125 - val_accuracy: 0.0132 - lr: 1.0000e-05\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 5.5526 - accuracy: 0.0000e+00 - val_loss: 5.1140 - val_accuracy: 0.0132 - lr: 1.0000e-05\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 5.5914 - accuracy: 0.0000e+00 - val_loss: 5.1073 - val_accuracy: 0.0132 - lr: 1.0000e-05\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 5.6807 - accuracy: 0.0000e+00 - val_loss: 5.1071 - val_accuracy: 0.0165 - lr: 1.0000e-06\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 5.7517 - accuracy: 0.0250 - val_loss: 5.1002 - val_accuracy: 0.0132 - lr: 1.0000e-06\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 5.3652 - accuracy: 0.0250 - val_loss: 5.0977 - val_accuracy: 0.0132 - lr: 1.0000e-06\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 5.2905 - accuracy: 0.0500 - val_loss: 5.0955 - val_accuracy: 0.0165 - lr: 1.0000e-06\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 5.8540 - accuracy: 0.0000e+00 - val_loss: 5.0933 - val_accuracy: 0.0165 - lr: 1.0000e-06\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 5.5984 - accuracy: 0.0250 - val_loss: 5.0930 - val_accuracy: 0.0165 - lr: 1.0000e-07\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 4.9463 - accuracy: 0.0000e+00 - val_loss: 5.0918 - val_accuracy: 0.0165 - lr: 1.0000e-07\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 5.6619 - accuracy: 0.0000e+00 - val_loss: 5.0869 - val_accuracy: 0.0165 - lr: 1.0000e-07\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 5.3283 - accuracy: 0.0250 - val_loss: 5.0827 - val_accuracy: 0.0132 - lr: 1.0000e-07\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 5.4588 - accuracy: 0.0256 - val_loss: 5.0792 - val_accuracy: 0.0132 - lr: 1.0000e-07\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 5.2927 - accuracy: 0.0000e+00 - val_loss: 5.0784 - val_accuracy: 0.0132 - lr: 1.0000e-08\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 5.5563 - accuracy: 0.0000e+00 - val_loss: 5.0793 - val_accuracy: 0.0132 - lr: 1.0000e-08\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 5.7138 - accuracy: 0.0500 - val_loss: 5.0783 - val_accuracy: 0.0132 - lr: 1.0000e-08\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 5.3234 - accuracy: 0.0000e+00 - val_loss: 5.0723 - val_accuracy: 0.0132 - lr: 1.0000e-08\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 5.0893 - accuracy: 0.0250 - val_loss: 5.0700 - val_accuracy: 0.0165 - lr: 1.0000e-08\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 5.0982 - accuracy: 0.0500 - val_loss: 5.0656 - val_accuracy: 0.0132 - lr: 1.0000e-09\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 5.0423 - accuracy: 0.0000e+00 - val_loss: 5.0669 - val_accuracy: 0.0132 - lr: 1.0000e-09\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 5.2264 - accuracy: 0.0000e+00 - val_loss: 5.0617 - val_accuracy: 0.0132 - lr: 1.0000e-09\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 5.3339 - accuracy: 0.0000e+00 - val_loss: 5.0610 - val_accuracy: 0.0132 - lr: 1.0000e-09\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 5.6470 - accuracy: 0.0000e+00 - val_loss: 5.0597 - val_accuracy: 0.0132 - lr: 1.0000e-09\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 5.4488 - accuracy: 0.0000e+00 - val_loss: 5.0589 - val_accuracy: 0.0099 - lr: 1.0000e-10\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 5.4850 - accuracy: 0.0000e+00 - val_loss: 5.0551 - val_accuracy: 0.0099 - lr: 1.0000e-10\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 5.1322 - accuracy: 0.0000e+00 - val_loss: 5.0542 - val_accuracy: 0.0132 - lr: 1.0000e-10\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 5.3086 - accuracy: 0.0250 - val_loss: 5.0504 - val_accuracy: 0.0099 - lr: 1.0000e-10\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 5.5700 - accuracy: 0.0000e+00 - val_loss: 5.0503 - val_accuracy: 0.0099 - lr: 1.0000e-10\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 5.1034 - accuracy: 0.0000e+00 - val_loss: 5.0514 - val_accuracy: 0.0132 - lr: 5.0000e-11\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 5.6672 - accuracy: 0.0250 - val_loss: 5.0534 - val_accuracy: 0.0132 - lr: 5.0000e-11\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 5.8953 - accuracy: 0.0000e+00 - val_loss: 5.0568 - val_accuracy: 0.0132 - lr: 5.0000e-11\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 5.5052 - accuracy: 0.0250 - val_loss: 5.0569 - val_accuracy: 0.0132 - lr: 5.0000e-11\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 5.6175 - accuracy: 0.0250 - val_loss: 5.0585 - val_accuracy: 0.0099 - lr: 5.0000e-11\n",
            "#1\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 5s 626ms/step - loss: 5.7174 - accuracy: 0.0250 - val_loss: 5.0651 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 5.5341 - accuracy: 0.0250 - val_loss: 4.9446 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 5.2844 - accuracy: 0.0250 - val_loss: 4.8521 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 4.9887 - accuracy: 0.0500 - val_loss: 4.7649 - val_accuracy: 0.0297 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 4.7121 - accuracy: 0.1000 - val_loss: 4.7139 - val_accuracy: 0.0396 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 3.9069 - accuracy: 0.2000 - val_loss: 4.6750 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 4.6479 - accuracy: 0.1026 - val_loss: 4.5997 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 3.7447 - accuracy: 0.2051 - val_loss: 4.5465 - val_accuracy: 0.0495 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 3.7847 - accuracy: 0.2500 - val_loss: 4.4896 - val_accuracy: 0.0594 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 3.8491 - accuracy: 0.2000 - val_loss: 4.4438 - val_accuracy: 0.0561 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 3.5254 - accuracy: 0.2000 - val_loss: 4.3919 - val_accuracy: 0.0693 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 3.3617 - accuracy: 0.2000 - val_loss: 4.3547 - val_accuracy: 0.0792 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 2.8397 - accuracy: 0.2750 - val_loss: 4.3062 - val_accuracy: 0.1122 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 3.3629 - accuracy: 0.2250 - val_loss: 4.2643 - val_accuracy: 0.1155 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 3.3084 - accuracy: 0.3500 - val_loss: 4.2120 - val_accuracy: 0.1221 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 2.8291 - accuracy: 0.4000 - val_loss: 4.1774 - val_accuracy: 0.1287 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 3.3442 - accuracy: 0.2250 - val_loss: 4.1265 - val_accuracy: 0.1353 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 3.1268 - accuracy: 0.3500 - val_loss: 4.0832 - val_accuracy: 0.1320 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 2.8387 - accuracy: 0.4250 - val_loss: 4.0495 - val_accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 2.4330 - accuracy: 0.5250 - val_loss: 4.0234 - val_accuracy: 0.1617 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 2.2976 - accuracy: 0.4000 - val_loss: 3.9987 - val_accuracy: 0.1518 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 2.7091 - accuracy: 0.4500 - val_loss: 3.9772 - val_accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 2.2296 - accuracy: 0.5250 - val_loss: 3.9470 - val_accuracy: 0.1584 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 2.2051 - accuracy: 0.4750 - val_loss: 3.9113 - val_accuracy: 0.1716 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 2.4911 - accuracy: 0.4500 - val_loss: 3.8820 - val_accuracy: 0.1716 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 2.2291 - accuracy: 0.4250 - val_loss: 3.8589 - val_accuracy: 0.2013 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 2.3418 - accuracy: 0.4000 - val_loss: 3.8387 - val_accuracy: 0.2046 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 1.8664 - accuracy: 0.6500 - val_loss: 3.8106 - val_accuracy: 0.2244 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 2.2121 - accuracy: 0.4500 - val_loss: 3.7869 - val_accuracy: 0.2244 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 2.0456 - accuracy: 0.5250 - val_loss: 3.7586 - val_accuracy: 0.2343 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 2.0777 - accuracy: 0.5000 - val_loss: 3.7401 - val_accuracy: 0.2442 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 1.9477 - accuracy: 0.5750 - val_loss: 3.7133 - val_accuracy: 0.2409 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 2.3015 - accuracy: 0.5250 - val_loss: 3.6877 - val_accuracy: 0.2475 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 1.9144 - accuracy: 0.5750 - val_loss: 3.6591 - val_accuracy: 0.2508 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 2.0311 - accuracy: 0.4000 - val_loss: 3.6335 - val_accuracy: 0.2541 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 2.1535 - accuracy: 0.5128 - val_loss: 3.6062 - val_accuracy: 0.2772 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 1.4686 - accuracy: 0.8000 - val_loss: 3.5815 - val_accuracy: 0.2673 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 1.7145 - accuracy: 0.6750 - val_loss: 3.5617 - val_accuracy: 0.2904 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 1.7526 - accuracy: 0.7000 - val_loss: 3.5420 - val_accuracy: 0.2838 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 1.9991 - accuracy: 0.5500 - val_loss: 3.5177 - val_accuracy: 0.2970 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 1.5808 - accuracy: 0.7000 - val_loss: 3.4969 - val_accuracy: 0.3102 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 1.6761 - accuracy: 0.6500 - val_loss: 3.4778 - val_accuracy: 0.3135 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 1.5803 - accuracy: 0.6750 - val_loss: 3.4523 - val_accuracy: 0.3267 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 1.5355 - accuracy: 0.7250 - val_loss: 3.4385 - val_accuracy: 0.3168 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 1.4294 - accuracy: 0.7250 - val_loss: 3.4236 - val_accuracy: 0.3168 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 1.4814 - accuracy: 0.7500 - val_loss: 3.4060 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 1.3864 - accuracy: 0.7500 - val_loss: 3.3942 - val_accuracy: 0.3267 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 1.4940 - accuracy: 0.7000 - val_loss: 3.3774 - val_accuracy: 0.3300 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 1.5132 - accuracy: 0.6750 - val_loss: 3.3602 - val_accuracy: 0.3366 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 1.2000 - accuracy: 0.8250 - val_loss: 3.3458 - val_accuracy: 0.3399 - lr: 0.0010\n",
            "#2\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 627ms/step - loss: 7.1195 - accuracy: 0.0000e+00 - val_loss: 5.0424 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 6.7106 - accuracy: 0.0000e+00 - val_loss: 5.0210 - val_accuracy: 0.0066 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 6.7430 - accuracy: 0.0000e+00 - val_loss: 4.9777 - val_accuracy: 0.0132 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 6.6458 - accuracy: 0.0000e+00 - val_loss: 4.9305 - val_accuracy: 0.0033 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 6.8994 - accuracy: 0.0000e+00 - val_loss: 4.8995 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 6.2640 - accuracy: 0.0000e+00 - val_loss: 4.8601 - val_accuracy: 0.0099 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 6.6401 - accuracy: 0.0000e+00 - val_loss: 4.8957 - val_accuracy: 0.0066 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M4fdEhivfVLr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPVxFdHnCUupsU0fCaoCW69",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}